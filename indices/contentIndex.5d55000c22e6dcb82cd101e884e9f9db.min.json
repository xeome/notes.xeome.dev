{"/":{"title":"xeome.github.io","content":"\n### About me\n\nI have a strong interest in Linux and other Unix-like operating systems, with a particular focus on optimization, efficiency, and low-level system programming. I enjoy reading kernel documentation and learning about low-level optimizations and the clever tricks that have been used to make the most of limited hardware. I am currently working on creating my own Linux distribution and writing documentation on various topics related to the Linux internals and other low-level systems programming topics, such as network programming(XDP) and the use of languages like C and x86 assembly. Overall, I have a passion for exploring and learning about the inner workings of low-level systems and finding ways to optimize and improve their performance.\n\nGithub: \u003chttps://github.com/xeome\u003e\n\n### Highlights\n\n#### CachyOS\n\nArch Linux based distribution with heavy optimizations and multi architecture support for ultimate desktop experience.\n\nLink: \u003chttps://github.com/CachyOS\u003e\n\n#### JomOS\n\nJomOS is a meta Linux distribution which allows users to mix-and-match well tested configurations and optimizations with little to no effort. JomOS integrates these configurations into one largely cohesive system.\n\nLink: \u003chttps://github.com/xeome/jomOS\u003e\n\nDocument: [[notes/JomOS]]\n\n#### xeome.github.io\n\nThis site contains all the documents i write about Linux and other topics.\n\nTo access all my notes, click here \u003chttps://xeome.github.io/notes/\u003e.\n","lastmodified":"2023-01-19T21:24:47.891094111Z","tags":null},"/notes/Btrfs-Maintenance":{"title":"Btrfs Maintenance","content":"\n## Btrfs Scrub\n\nThe Btrfs scrub operation reads all data and metadata from devices and verifies their checksums. This can help to detect problems with faulty hardware early, as it touches data that may not be in use and may be vulnerable to bit rot. If there is data/metadata redundancy in the file system, such as DUP or RAID1/5/6 profiles, scrub can automatically repair the data if a good copy is available.\n\nTo start a scrub operation, use the following command:\n\n```bash\nsudo btrfs scrub start /\n```\n\nTo check the status of a scrub operation, use the following command:\n\n```bash\nsudo btrfs scrub status /\n```\n\n## Btrfs balance\n\nThe balance command can do a lot of things, but it primarily moves data in large chunks. It is used here to reclaim the space of the underutilized chunks so that it can be allocated again based on current needs.\n\nThe goal is to avoid situations in which it is impossible to allocate new metadata chunks, for example, because the entire device space is reserved for all the chunks, even though the total space occupied is smaller and the allocation should succeed.\n\nThe balance operation requires enough space to shuffle data around. By workspace, we mean device space with no filesystem chunks on it, not free space as reported by df, for example.\n\nThe balance command may fail due to a lack of space, but this is considered a minor error because the internal filesystem layout may prevent the command from finding enough workspace. This could be a good time to inspect the space manually.\n\nRunning `btrfs balance start` without any filters, would re-write every Data and Metadata chunk on the disk. Usually, this is not what we want. Instead use the `usage` filter to limit what blocks should be balanced.\n\nUsing `-dusage=5` we can limit balance to compact data blocks that are less than 5% full. This is a good start, and we can increase it to 10-15% or more if needed. A small (less than 100GiB) filesystem may need a higher number.\n\nSimilarly using `-musage=5` we can limit balance to compact metadata chunks.\n\n### Examples\n\nTo start balance on data chunks:\n\n`sudo btrfs balance start --bg -dusage=5 /path`\n\nTo start balance on metadata chunks:\n\n`sudo btrfs balance start --bg -musage=5 /path`\n\nto check status of balance operation:\n\n`sudo btrfs balance status /path`\n\n**Expected outcome:** If all underutilized chunks are removed, the total value in the output of `btrfs fi df /path` should be lower than before. Examine the logs.\n\n## Manual deduplication using duperemove\n\n\u003e Duperemove is a simple tool for finding duplicated extents and submitting them for deduplication. When given a list of files it will hash their contents on a block by block basis and compare those hashes to each other, finding and categorizing blocks that match each other. When given the -d option, duperemove will submit those extents for deduplication using the Linux kernel extent-same ioctl.\n\u003e Duperemove can store the hashes it computes in a 'hashfile'. If given an existing hashfile, duperemove will only compute hashes for those files which have changed since the last run. Thus you can run duperemove repeatedly on your data as it changes, without having to re-checksum unchanged data.\n\nAs the above explanation from project's github readme states, you can use this tool for checking and reporting duplicate extents to kernel.\n\nI saved an estimate of around 17G on 180GiB of mixed data, photos, videos, games, documents etc.\n![[notes/assets/img/O_Pasted image 20230119010141.png]]\nHere is how I use this tool:\n\n```bash\nsudo duperemove --hashfile=/home/$USERNAME/.hashfile -dhr /\n```\n\nParameter explanations:\n\n- `--hashfile=location` can be used to specify location of hashfile to be reused later.\n\n\u003e Hashfiles are essentially sqlite3 database files with 3 tables, `config`, `files` and `hashes`. Hashfiles are meant to be reused - duperemove will store the results of the scan and dedupe stages to speed up subsequent runs.\n\n- `-d` De-dupe the results - only works on btrfs and xfs.\n- `-h` Print numbers in human-readable format.\n- `-r` Enable recursive dir traversal.\n\nand lastly `/` which is the location we want to dedupe.\n\nNotice: The hash file format in Duperemove master branch is under development and may change. If the changes are not backwards compatible, you will have to re-create your hash file.\n\n## Trimming\n\nAlthough trimming is not exclusive to btrfs, I felt like still needs to be mentioned.\n\nThe TRIM (aka discard) operation can instruct the underlying device to optimize blocks that are not being used by the filesystem. The fstrim utility performs this task on demand.\n\nThis makes sense for SSDs or other types of storage that can translate TRIM actions into useful data (eg. thin-provisioned storage).\n\nYou can use `sudo fstrim --fstab --verbose` to run fstrim on all mounted filesystems mentioned in /etc/fstab on devices that support the discard operation.\n\n`--fstab`:\n\nOn devices that support the discard operation, trim all mounted filesystems listed in /etc/fstab. If the root filesystem is missing from the file, it is determined from the kernel command line. Other provided options, such as `--offset`, `--length`, and `--minimum`, are applied to all of these devices. Errors originating from filesystems that do not support the discard operation, as well as read-only devices, autofs, and read-only filesystems, are silently ignored. Filesystems with the mount option `X-fstrim.notrim` are skipped.\n\n`--verbose`:\n\nVerbose execution. With this option fstrim will output the number of bytes passed from the filesystem down the block stack to the device for potential discard. This number is a maximum discard amount from the storage device’s perspective, because FITRIM ioctl called repeated will keep sending the same sectors for discard repeatedly.\n\n## Sources\n\n\u003chttps://github.com/kdave/btrfsmaintenance\u003e\n\n\u003chttps://github.com/markfasheh/duperemove#duperemove\u003e\n\n\u003chttps://github.com/markfasheh/duperemove/wiki/Duperemove-Design#hashfiles\u003e\n\n\u003chttps://man.archlinux.org/man/fstrim.8.en\u003e\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/C++-multithreading":{"title":"C++ multithreading","content":"\n# Overview\n\nMultithreading is a programming technique that allows a single process to execute multiple threads concurrently. This allows a program to perform multiple tasks simultaneously, improving the performance and responsiveness of the program. In C++, the `std::thread` class, part of the C++11 standard library, is used to implement multithreading.\n\nTo use concurrency in C++, you will need to use the `\u003cthread\u003e` header, which provides the `std::thread` class and other related types and functions for creating and managing threads. Here's a simple example of how to create and start a new thread:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo() { std::cout \u003c\u003c \"Hello from a new thread!\" \u003c\u003c std::endl; }  \n  \nint main() {  \n    std::thread t(foo);  \n    t.join();  \n    return 0;  \n}\n```\n\nThis program creates a new `std::thread` object, passing the function `foo` as the argument to the thread's constructor. The `join` member function blocks the calling thread (in this case, the main thread) until the new thread has completed execution.\n\nYou can also use the `std::async` function to run a function asynchronously and get a `std::future` object that can be used to retrieve the result of the function when it becomes available. For example:\n\n```cpp\n#include \u003cfuture\u003e  \n#include \u003ciostream\u003e  \n  \nint foo() { return 10; }  \n  \nint main() {  \n    std::future\u003cint\u003e f = std::async(foo);  \n    int x = f.get();  \n    std::cout \u003c\u003c \"x = \" \u003c\u003c x \u003c\u003c std::endl;  \n    return 0;  \n}\n```\n\nThis program creates a new asynchronous task that executes the `foo` function and returns a `std::future` object that can be used to retrieve the result of the function when it becomes available. The `get` member function of the `std::future` object blocks the calling thread until the result is available, and then returns the result.\n\n# Basic examples\n\n##### Example 1: Passing arguments to a thread function\n\nIn this example, we pass two arguments to the thread function:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo(int x, std::string str) {  \n    std::cout \u003c\u003c \"x = \" \u003c\u003c x \u003c\u003c \", str = \" \u003c\u003c str \u003c\u003c std::endl;  \n}  \n  \nint main() {  \n    std::thread t(foo, 10, \"Hello\");  \n    t.join();  \n    return 0;  \n}\n\n```\n\nWhen the `foo` function is executed by the new thread, it will receive the arguments `10` and `\"Hello\"`.\n\n##### Example 2: Using std::move to transfer ownership of a thread\n\nIn this example, we use `std::move` to transfer ownership of a thread object to a new thread:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo() { std::cout \u003c\u003c \"Hello from a new thread!\" \u003c\u003c std::endl; }  \n  \nint main() {  \n    std::thread t1(foo);  \n    std::thread t2 = std::move(t1);  \n    t2.join();  \n    return 0;  \n}\n```\n\nThe `t1` thread object is created and starts executing the `foo` function. The `t2` thread object is then created by moving the `t1` object using `std::move`. This transfers ownership of the thread to the `t2` object, and the `t1` object is left in a moved-from state and is no longer associated with any thread. The `t2` object can then be used to manage the thread.\n\n##### Example 3: Detaching a thread\n\nIn this example, we create a thread and detach it from the main thread of execution:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo() { std::cout \u003c\u003c \"Hello from a new thread!\" \u003c\u003c std::endl; }  \n  \nint main() {  \n    std::thread t(foo);  \n    t.detach();  \n    return 0;  \n}\n\n```\n\nThe `detach` member function of the `std::thread` object detaches the thread from the main thread of execution, allowing it to run independently. The main thread can then continue execution without waiting for the detached thread to complete.\n\n##### Example 4: Passing arguments by reference to std::thread\n\nIn this example, we pass an argument by reference to thread function:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo(int x, std::string \u0026str) {  \n    std::cout \u003c\u003c \"x = \" \u003c\u003c x \u003c\u003c \", str = \" \u003c\u003c str \u003c\u003c std::endl;  \n}  \n  \nint main() {  \n    std::string str = \"Hello\";  \n    std::thread t(foo, 10, std::ref(str));  \n    t.join();  \n    return 0;  \n}\n```\n\n# More algorithmic examples\n\nThere are many other algorithms that can be implemented as multithreaded versions to take advantage of concurrency, including the following:\n\n- Sorting algorithms: Many sorting algorithms, such as merge sort and quick sort, can be implemented as multithreaded versions to improve performance on multi-core systems.\n\n- Matrix multiplication: Matrix multiplication can be implemented as a multithreaded algorithm to take advantage of parallelism, particularly for large matrices.\n\n- Graph algorithms: Many graph algorithms, such as breadth-first search and depth-first search, can be implemented as multithreaded versions to improve performance on multi-core systems.\n\n- Search algorithms: Some search algorithms, such as binary search and linear search, can be implemented as multithreaded versions to improve performance on multi-core systems.\n\n### Example 1: Merge sort\n\n```cpp\n#include \u003ciostream\u003e\n#include \u003cthread\u003e\n\nvoid merge(int arr[], int l, int m, int r) {\n\n    // Find sizes of two sub arrays to be merged\n    int i, j, k;\n    int n1 = m - l + 1;\n    int n2 = r - m;\n\n    // create temp arrays\n    int L[n1], R[n2];\n\n    // Copy data to temp arrays L[] and R[]\n    std::copy(arr + l, arr + l + n1, L);\n    std::copy(arr + m + 1, arr + m + 1 + n2, R);\n\n    // Merge the temp arrays back into arr[l..r]\n    i = 0; // Initial index of first subarray\n    j = 0; // Initial index of second subarray\n    k = l; // Initial index of merged subarray\n    while (i \u003c n1 \u0026\u0026 j \u003c n2) {\n        // if left subarray is smaller than right subarray then put left\n        // subarray element into arr and increment i and k by 1 otherwise put\n        // right subarray element into arr and increment j and k by 1\n        if (L[i] \u003c= R[j]) {\n            arr[k] = L[i];\n            i++;\n        } else {\n            arr[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n\n    // Copy the remaining elements of L[], if there are any \n    std::copy(L + i, L + n1, arr + k);\n\n    // Copy the remaining elements of R[], if there are any \n    std::copy(R + j, R + n2, arr + k);\n}\n\n// Parallel version of the merge sort algorithm\nvoid mergeSort(int *arr, int l, int r) {\n    if (l \u003c r) {\n        // Same as (l+r)/2, but avoids overflow for large l and h\n        int m = l + (r - l) / 2;\n        // Sort first and second halves\n        std::thread t1(mergeSort, arr, l, m);\n        std::thread t2(mergeSort, arr, m + 1, r);\n        t1.join();\n        t2.join();\n        // Merge the sorted halves\n        merge(arr, l, m, r);\n    }\n}\n\nint main() {\n    // Test the merge sort algorithm\n    int arr[] = {12, 11, 13, 5, 6, 7};\n    int arr_size = std::size(arr);\n\n    std::cout \u003c\u003c \"Given array is \\n\";\n    for (int i = 0; i \u003c arr_size; i++)\n        std::cout \u003c\u003c arr[i] \u003c\u003c \" \";\n\n    mergeSort(arr, 0, arr_size - 1);\n\n    std::cout \u003c\u003c \"\\nSorted array is \\n\";\n    for (int i = 0; i \u003c arr_size; i++)\n        std::cout \u003c\u003c arr[i] \u003c\u003c \" \";\n    return 0;\n}\n```\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Computer-Science":{"title":"Computer Science","content":"\n# Index\n\n- [[notes/Linux]]\n- [[notes/Networking]]\n- [[notes/Misc]]\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Data-Structures":{"title":"Data Structures","content":"\n# Overview\n\nThere are numerous data structures used in computer science and software engineering, each with their own set of characteristics and trade-offs. Here's a quick rundown of some of the most common data structures, as well as their use cases and time complexities for common operations:\n\n1. Arrays: Arrays are simple data structures that store a fixed-size sequence of elements. They perform well when accessing individual elements but poorly when inserting or deleting elements. Time complexity for common operations:\n\n- Access: O(1)\n- Insertion/Deletion: O(n)\n\n2. Vectors: Vectors are similar to arrays, but they are mutable and have automatic resizing. Time complexity for common operations:\n\n- Access: O(1)\n- Insertion/Deletion: O(n)\n\n3. Linked Lists: Linked lists are data structures that store a list of elements, each of which contains a reference to the next element in the list. They perform well when inserting and deleting elements but poorly when accessing individual elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(1)\n\n4. Stacks: Stacks are data structures that store a sequence of elements and allow only the most recently added element to be accessed (last in, first out). They perform well when adding and removing elements from the top of the stack, but poorly when accessing other elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(1)\n\n5. Queues: Queues are data structures that store a sequence of elements and allow only the oldest element to be accessed (first in, first out). They perform well when adding and removing elements from the front and back of the queue, but poorly when accessing other elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(1)\n\n6. Trees: Trees are hierarchical data structures made up of nodes connected by a parent-child relationship. They are good at searching, inserting, and deleting elements, but not so good at accessing individual elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(log n)\n\n7. Hash Tables: Hash tables are data structures that map keys to array indices using a hash function. They are good at searching, inserting, and deleting elements, but not so good at accessing individual elements. Time complexity for common operations:\n\n- Access: O(1) average case, O(n) worst case\n- Insertion/Deletion: O(1) average case, O(n) worst case\n\n8. Heaps: Heaps are data structures that store a complete binary tree in which the parent node is always greater than or equal to its children (max heap) or less than or equal to its children (min heap). They are good at finding the maximum or minimum element, but not so good at inserting or deleting elements. Time complexity for common operations:\n\n- Access: O(1)\n- Insertion/Deletion: O(log n)\n\n# Implementations\n\n## Vector\n\nMethods available:\n\n- size() - the number of items it can hold\n- capacity() - the number of items it can hold\n- is_empty()\n- at(index) - returns the item at the given index, but fails if the index is out of bounds.\n- push(item)\n- insert(index, item) - inserts item at index, shifts that index's value and trailing elements to the right\n- prepend(item) - inserts item at index 0\n- pop() - remove from the end and return the value\n- delete(index) - Remove the item at index by shifting all trailing elements to the left.\n- remove(item) - searches for value and removes the index that holds it (even if in multiple places)\n- find(item) - searches for a value and returns the first index containing that value. If not found, return -1\n- resize(new capacity) - When you reach capacity, when popping an item, resize to double the size; if size is 1/4 of capacity, resize to half.\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/vector.c\u003e\n\n## Linked List\n\nMethods available:\n\n- size() - returns number of data elements in list\n- empty() - bool returns true if empty\n- value_at(index) - returns the value of the nth item (starting at 0 for first)\n- push_front(value) - adds an item to the front of the list\n- pop_front() - remove front item and return its value\n- push_back(value) - adds an item at the end\n- pop_back() - removes end item and returns its value\n- front() - get value of front item\n- back() - get value of end item\n- insert(index, value) - insert value at index, so current item at that index is pointed to by new item at index\n- erase(index) - removes node at given index\n- value_n_from_end(n) - returns the value of the node at nth position from the end of the list\n- reverse() - reverses the list\n- remove_value(value) - removes the first item in the list with this value\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/linked_list.c\u003e\n\n## Queue\n\nMethods available:\n\n- enqueue(value) - adds item at end of available storage\n- dequeue() - returns value and removes least recently added element\n- empty()\n- full()\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/queue.c\u003e\n\n## Hashmap\n\nMethods available:\n\n- hash_map_init\n- hash_map_destroy\n- hash_siphash\n- hash_map_insert\n- hash_map_lookup\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/hashmap.c\u003e\n\nExplanation:\n[[notes/Hashmap]]\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Emulating-Cortex-A72":{"title":"Emulating Cortex A72","content":"\n# Starting out (Preparing for emulation)\n\n- Create a Project directory.\n\n```sh\n$ mkdir rpi_image\n$ cd rpi_image\n```\n\n- Download and decompress the Debian RasPi4 image.\n\n```sh\n$ wget https://raspi.debian.net/tested/20220808_raspi_4_bookworm.img.xz\n$ xz --decompress 20220808_raspi_4_bookworm.img.xz\n```\n\n- Using `fdisk`, determine the starting sector number.\n\n```sh\n$ fdisk -l 20220808_raspi_4_bookworm.img\n```\n\n```\nDisk 20220808_raspi_4_bookworm.img: 1,95 GiB, 2097152000 bytes, 4096000 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0xf7e489e2\n\nDevice         Boot  Start     End Sectors  Size Id Type\n20220808_raspi_4_bookworm.img1        8192  819199  811008  396M  c W95 FAT32\n20220808_raspi_4_bookworm.img2      819200 4095999 3276800  1,6G 83 Linux\n```\n\n- Before we mount the image to do some stuff, we need to get an offset in order to correctly mount.\u003cbr\u003eFind the `Start` number in the second partition `$something.img2`. It's `819200` in my case. Multiply it by 512, which equals `419430400` in my case.\n\n- Create a mount directory:\n\n```sh\n$ mkdir /mnt/raspi4\n```\n\n- We can now mount image:\n\n```sh\n$ sudo mount -o offset=419430400 20220808_raspi_4_bookworm.img /mnt/raspi4\n```\n\n- Now we can extract kernel and initrd from image:\u003cbr\u003e(NOTE: We are cd'd into rpi_image directory)\n\n```sh\n$ cp /mnt/raspi4/vmlinuz .\n$ cp /mnt/raspi4/initrd.img .\n```\n\n- Finally, we need to edit `fstab` for slicker(?) mounting via QEMU\n\n```\n$ nano /mnt/raspi4/etc/fstab\n```\n\n```sh\n# The root file system has fs_passno=1 as per fstab(5) for automatic fsck.\nLABEL=RASPIROOT / ext4 rw 0 1\n# All other file systems have fs_passno=2 as per fstab(5) for automatic fsck.\nLABEL=RASPIFIRM /boot/firmware vfat rw 0 2\n```\n\n- Replace `LABEL=RASPIROOT` with `/dev/vda2`\n\n- Replace `LABEL=RASPIFIRM` with `/dev/vda1`\n\n- The file should look something like this.\n\n```sh\n# The root file system has fs_passno=1 as per fstab(5) for automatic fsck.\n/dev/vda2 / ext4 rw 0 1\n# All other file systems have fs_passno=2 as per fstab(5) for automatic fsck.\n/dev/vda1 /boot/firmware vfat rw 0 2\n```\n\n- We can now convert the image to qcow2.\n\n```sh\nqemu-img convert -f raw -O qcow2 20220808_raspi_4_bookworm.img rpi.qcow2\n```\n\n# Emulation Time!\n\n- We can finally start making our launch script.\n\n```sh\n$ nano rpistart.sh\n```\n\n**rpistart.sh**\n\n```sh\n#!/bin/bash\nscreen -mS raspberry-pi-4 \\\nsudo qemu-system-aarch64 \\\n-M virt \\\n-m 4096 -smp 4 \\\n-cpu cortex-a72 \\\n-kernel vmlinuz \\\n-initrd initrd.img \\\n-append \"root=/dev/vda2 panic=1 rootfstype=ext4 rw\" \\\n-hda rpi.qcow2 \\\n-no-reboot \\\n-nographic\n```\n\n- Paste the above into the script and save.\n\n### Some info about script\n\n- Since QEMU doesn't natively support Raspberry Pi 4(b), our only option is to virtualize Cortex A72 (Which is CPU used in Raspberry Pi 4(b)).\n- `-nographic` because _who needs graphics._\n- `screen` is used 'cuz _why not_.\n\n- Make script executable\n\n```sh\n$ chmod +x rpistart.sh\n```\n\n- __And you should_ be able to run QEMU instance._*\n- LAUNCH!\n\n```sh\n$ ./rpistart.sh\n```\n\n# Some wacky reality.\n\nYou have booted into nice Debian. Oh, btw, username is passwordless `root`.\u003cbr\u003eBut there are two problems:\n\n- Not enough space!\n- No internet!\n\n## Not enough space!\n\nVery simple. Just:\n\n- poweroff the VM.\n\n```sh\nVM$ poweroff\n```\n\n- In our `rpi_image` directory, we can resize `qcow2` image via:\n\n```sh\n$ qemu-img resize rpi.qcow2 +4G\n```\n\n```sh\n# Side note: You can also set exact size by getting rid of that + sign.\n```\n\n- Now we need to boot into VM once again:\n\n```sh\n$ ./rpistart.sh\n```\n\n- We have resized the image capacity, but not partition size. We can do that with:\n\n```sh\nVM$ resize2fs /dev/vda2\n```\n\n- You can check final result via\n\n```sh\nVM$ df -H\n```\n\n## No internet!\n\nNow we are going to configure our ethernet network interface.\n\n- You can check available network interfaces via:\n\n```sh\nVM$ ip addr\n```\n\n```\n1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp0s1: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 52:54:00:12:34:56 brd ff:ff:ff:ff:ff:ff\n```\n\n- Notice, that `enp0s1` has zero IP addresses. We gotta fix that! _By creating another file._\n\n```sh\nVM$ nano /etc/network/interfaces.d/enp0s1\n```\n\nand paste this in:\u003cbr\u003e\u003cbr\u003e\n**enp0s1**\n\n```sh\nauto enp0s1\n\niface enp0s1 inet dhcp\n```\n\n- And delete eth0 interface\n- Reboot (Although config won't actually let you reboot.)\n\n```sh\nVM$ poweroff\n```\n\n```sh\n$ ./rpistart.sh\n```\n\n- You may still receive a networking service error, but you should be able to access the internet.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Hashmap":{"title":"Hashmap","content":"\nFollowing text is explanation for this code:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/hashmap.c\u003e\n\nA hash map is a data structure that allows you to store key-value pairs and quickly retrieve the value associated with a given key.\n\nThe HashMap data structure consists of a size field, which represents the number of key-value pairs stored in the hash map, a `capacity` field, which represents the maximum number of key-value pairs the hash map can hold, and a `buckets` field, which is an array of pointers to Nodes. Each Node represents a key-value pair, and the buckets array is used to store linked lists of Nodes that have the same hash value.\n\n# hash_map_init\n\nThe `hash_map_init` function initializes a hash map by allocating memory for the buckets array and setting the `capacity` and `size` fields to the specified values.\n\n# hash_map_destroy\n\nThe `hash_map_destroy` function frees the memory allocated for the buckets array and the Nodes stored in the hash map.\n\n# hash_siphash and hash_djb2\n\nThe `hash_siphash` function is a SipHash implementation, which is a cryptographic hash function that can be used to compute a hash value for a given string. The `hash_djb2` function is an alternative, simpler hash function called DJB2.\n\ndjb2 is a simple, fast hashing function created by Dan Bernstein. It is designed to be easy to implement and produce good hash values with a minimum of collisions.\n\nThe function works by iterating over the characters in a string and performing a series of operations on each character to generate a numerical hash value. The basic structure of the function is as follows:\n\n```C\nunsigned long djb2_hash(unsigned char *str) {\n    unsigned long hash = 5381;\n    int c;\n\n    while (c = *str++)\n        hash = ((hash \u003c\u003c 5) + hash) + c; /* hash * 33 + c */\n\n    return hash;\n}\n```\n\nThe first line initializes the hash value to 5381. This is a magic number that has been found to work well with djb2. The second line declares an integer c that will be used to store the current character being processed. The third line is a while loop that iterates over the characters in the string. The loop terminates when all characters have been processed or when a null character is encountered.\n\nInside the loop, the current character is fetched from the string and stored in c. Then, the hash value is updated using the following expression:\n\nhash = ((hash \u003c\u003c 5) + hash) + c;\n\nThis expression first shifts the current value of hash left by 5 bits. This has the effect of multiplying the hash value by 32. Then, the original value of hash is added to the result, effectively multiplying the hash value by 33. Finally, the character value c is added to the hash value.\n\nThe result of this operation is that each character in the string is used to update the hash value in a way that is dependent on all of the previous characters. This helps to ensure that the hash value is spread evenly over the range of possible values and minimizes the likelihood of collisions.\n\nOnce all characters have been processed, the final value of hash is returned as the hash value for the string.\n\nOverall, djb2 is a simple, fast, and effective hashing function that is widely used in a variety of applications. Its simplicity makes it easy to implement and its good performance makes it well-suited for use in a wide range of situations.\n\n# hash_map_insert\n\nThe `hash_map_insert` function inserts a key-value pair into the hash map. It first computes the hash value for the key using either `hash_siphash` or `hash_djb2`, and then inserts the key-value pair into the linked list at the corresponding index in the buckets array.\n\n# hash_map_lookup\n\nThe `hash_map_lookup` function looks up the value associated with a given key in the hash map. It first computes the hash value for the key using either `hash_siphash` or `hash_djb2`, and then searches the linked list at the corresponding index in the buckets array for a Node with the matching key. If a match is found, the function returns the value associated with the key. If no match is found, the function returns -1.\n\n# ROTL\n\nThe `ROTL` macro stands for \"rotate left\" and is used to rotate the bits in the first argument by the number of positions specified in the second argument.\n\n# SIPROUND\n\nThe `SIPROUND` macro is used in the implementation of SipHash. It performs a series of operations on the variables v0, v1, v2, and v3 that are intended to scramble the input data in a way that makes it difficult to predict the output hash value based on the input data.\n\nThe do { ... } while (0) construct is used in the SIPROUND macro to create a loop that is guaranteed to execute only once. This is a common pattern in C macros, and it is used to ensure that the macro can be used as a single statement without causing syntax errors.\n\nFor example, consider the following code:\n\n```C\nif (x \u003e 0)\n    MACRO;\n```\n\nIf MACRO is a simple macro that does not contain any control statements, it will be expanded as follows:\n\n```C\nif (x \u003e 0)\n    statement1;\n    statement2;\n    ...\n\n```\n\nThis will cause a syntax error, because the `if` statement is not properly terminated. To fix this, we can use the `do { ... } while (0)` construct in the macro to ensure that it is always treated as a single statement:\n\n```C\n#define MACRO                                                                 \\\n    do {                                                                     \\\n        statement1;                                                           \\\n        statement2;                                                           \\\n        ...                                                                   \\\n    } while (0)\n\n```\n\nNow, the macro will be expanded as follows:\n\n```C\nif (x \u003e 0)\n    do {\n        statement1;\n        statement2;\n        ...\n    } while (0);\n\n```\n\nThis ensures that the macro can be used as a single statement without causing syntax errors.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/JomOS":{"title":"JomOS","content":"\n## About\n\nJomOS is an aggressively optimized meta Linux distribution designed for people who wants to get most out of their hardware. It allows users to mix-and-match well tested configurations and optimizations with little to no effort.\n\nJomOS integrates these configurations \u0026 optimizations into one largely cohesive system.\n\n## How does JomOS improve performance\n\nWe use tuned systctl values, udev rules and other configurations. We also provide a optimized repo with march=x86-64-v3 support (CachyOS repos) which comes with a notable performance boost. It depends on your cpu if it does support that, but you dont need to worry about it - the installer will detect the correct µarch and adjust to your system. Custom tuned kernel is also planned.\nFor more information refer to [[notes/JomOS Optimizations]].\n\n\n## Screenshots\n\n![[notes/assets/img/O_distro.png]]\n\n## Credits\n\nHuge thanks to Linux community and CachyOS team for some of the optimizations and general help.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/JomOS-Optimizations":{"title":"JomOS Optimizations","content":"\n## Optimized repositories\n\nJomOS adds optimized repositories automatically to improve performance and system responsiveness. These repositories also include custom kernels with various CPU schedulers and other goodies.\n\nThe optimizations used in the repositories are listed below.\n\n### Compiler optimizations\n\n-march is the first and most important option. This instructs GCC(or other compilers) to generate code for a specific type of CPU. Different CPUs have different capabilities, support different instruction sets, and execute code in different ways. The -march flag instructs the compiler to generate specific code for the selected architecture, including all of its capabilities, features, instruction sets, quirks, and so on.\n\nIf the CPU type is unknown, or if the user is unsure which setting to use, the -march=native option can be used. When this flag is set, GCC will attempt to detect the processor and set appropriate flags for it automatically. This should not be used if you want to compile packages for different CPUs!\n\nWhen compiling packages on one computer to run on another (for example, when using a fast computer to build for an older, slower machine), do not use -march=native. The term \"native\" indicates that the code produced will only run on that type of CPU. Applications developed with -march=native on an Intel Core CPU will not run on an old Intel Atom CPU.\n\nThese are the four x86-64 microarchitecture levels on top of the x86-64 baseline:\n\n- x86-64: CMOV, CMPXCHG8B, FPU, FXSR, MMX, FXSR, SCE, SSE, SSE2\n- x86-64-v2: (close to Nehalem) CMPXCHG16B, LAHF-SAHF, POPCNT, SSE3, SSE4.1, SSE4.2, SSSE3\n- x86-64-v3: (close to Haswell) AVX, AVX2, BMI1, BMI2, F16C, FMA, LZCNT, MOVBE, XSAVE\n- x86-64-v4: AVX512F, AVX512BW, AVX512CD, AVX512DQ, AVX512VL\n\nMost Linux distributions use x86-64-v2 for compatibility with older hardware, but this may limit performance on newer hardware. We detect whether your CPU supports x86-64-v3 and add repositories accordingly. The performance improvement could range from 10% to 35% depending on the processor and software used.\n\n![[notes/assets/img/O_benchmarks.png]]\n\n![[notes/assets/img/O3_generic_O3_march_haswell_Comparison.png]]\n\nTo check if your cpu supports x86-64-v3, you can use the following command:\n`/lib/ld-linux-x86-64.so.2 --help | grep \"x86-64-v3 (supported, searched)\"`\n\nIf you get an output saying `x86-64-v3 (supported, searched)` then congratulations, your cpu supports x86-64-v3.\n\nThis repository is provided by CachyOS. As theres no reason to create our own v3 repositories. Many thanks to the CachyOS team for creating and maintaining this repository.\n\n## Default browser Thorium\n\nAs far as I am aware, Thorium is the fastest browser available. It also makes use of some of the compiler optimizations we use, as well as others; for more information, see [[notes/Thorium]].\n\n## Tuned sysctl values and other configurations\n\n### /etc/sysctl.d/99-JomOS-settings.conf\n\nThis file contains JomOS sysctl tweaks.\n\n#### vm.swappiness\n\nThe swappiness sysctl parameter represents the kernel's preference (or avoidance) of swap space. Swappiness can have a value between 0 and 100, the default value is 60.\n\nA low value causes the kernel to avoid swapping, a higher value causes the kernel to try to use swap space. Using a low value on sufficient memory is known to improve responsiveness on many systems.\n\nThis value is automatically calculated using your ram amount\n\n#### vm.vfs_cache_pressure\n\nThe value controls the tendency of the kernel to reclaim the memory which is used for caching of directory and inode objects (VFS cache).\n\nLowering it from the default value of 100 makes the kernel less inclined to reclaim VFS cache (do not set it to 0, this may produce out-of-memory conditions)\n\nThis value is automatically calculated using your ram amount\n\n#### vm.page-cluster\n\nrefer to \u003chttps://xeome.github.io/notes/Zram#page-cluster-values-latency-difference\u003e\n\n#### vm.dirty_ratio\n\nContains, as a percentage of total available memory that contains free pages and reclaimable pages, the number of pages at which a process which is generating disk writes will itself start writing out dirty data (Default is 20).\n\n#### vm.dirty_background_ratio\n\nContains, as a percentage of total available memory that contains free pages and reclaimable pages, the number of pages at which the background kernel flusher threads will start writing out dirty data (Default is 10).\n\n#### Network tweaks (only for CachyOS kernels)\n\nThe BBR congestion control algorithm can help achieve higher bandwidths and lower latencies for internet traffic\n\nTCP Fast Open is an extension to the transmission control protocol (TCP) that helps reduce network latency by enabling data to be exchanged during the sender’s initial TCP SYN. Using the value 3 instead of the default 1 allows TCP Fast Open for both incoming and outgoing connections\n\n#### kernel.nmi_watchdog\n\nDisabling NMI watchdog will speed up your boot and shutdown, because one less module is loaded. Additionally disabling watchdog timers increases performance and lowers power consumption\n\n### /etc/udev/rules.d/ioscheduler.rules\n\nThe kernel component that determines the order in which block I/O operations are submitted to storage devices is the input/output (I/O) scheduler.The goal of the I/O scheduler is to optimize how these can deal with read requests, it is useful to review some specifications of the two main drive types:\n\n- An HDD has spinning disks and a physical head that moves to the required location. As a result, random latency is quite high, ranging between 3 and 12ms (depending on whether it is a high-end server drive or a laptop drive bypassing the disk controller write buffer), whereas sequential access provides significantly higher throughput. The average HDD throughput is approximately 200 I/O operations per second (IOPS).\n\n- An SSD does not have moving parts, random access is as fast as sequential one, typically under 0.1ms, and it can handle multiple concurrent requests. The typical SSD throughput is greater than 10,000 IOPS, which is more than needed in common workload situations.\n\nThousands of IOPS can be generated if multiple processes make I/O requests to different storage parts, whereas a typical HDD can only handle about 200 IOPS. There is a queue of requests that must wait for storage access. This is where I/O schedulers can help with optimization.\n\nThe best scheduler to use is determined by both the device and the specific nature of the workload. Furthermore, throughput in MB/s is not the only measure of performance: deadlines or fairness reduce overall throughput while improving system responsiveness.\n\n```ini\n# set scheduler for NVMe\nACTION==\"add|change\", KERNEL==\"nvme[0-9]n[0-9]\", ATTR{queue/scheduler}=\"none\"\n# set scheduler for SSD and eMMC\nACTION==\"add|change\", KERNEL==\"sd[a-z]*|mmcblk[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"mq-deadline\"\n# set scheduler for rotating disks\nACTION==\"add|change\", KERNEL==\"sd[a-z]*\", ATTR{queue/rotational}==\"1\", ATTR{queue/scheduler}=\"bfq\"\n```\n\nFor example the [udev](https://wiki.archlinux.org/title/Udev \"Udev\") rule above sets the scheduler to _none_ for [NVMe](https://wiki.archlinux.org/title/NVMe \"NVMe\"), _mq-deadline_ for [SSD](https://wiki.archlinux.org/title/SSD \"SSD\")/eMMC, and _bfq_ for rotational drives:\n\n### /etc/mkinitcpio.conf\n\nBase and udev replaced with systemd for faster boots and set compression algorithm to zstd and compression level to 2 because compression ratio increase isn't worth the increased boot time.\n\n### /etc/systemd/zram-generator.conf\n\nUse zstd compression by default, for more information visit [[notes/Zram]]\n\n# Sources\n\n## Benchmarks\n\n\u003chttps://lists.archlinux.org/pipermail/arch-general/2021-March/048739.html\u003e\n\n\u003chttps://openbenchmarking.org/result/2103142-HA-UARCHLEVE55\u0026rmm=O1_generic%2CO3_march_nehalem\u003e\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Linux":{"title":"Linux","content":"\n- [[notes/Btrfs Maintenance]]\n- [[notes/Emulating Cortex A72]]\n- [[notes/JomOS]]\n- [[notes/JomOS Optimizations]]\n- [[notes/Linux Memory Management]]\n- [[notes/Post install optimizations]]\n- [[notes/Transparent Huge Pages]]\n- [[notes/XDP-Tutorial]]\n- [[notes/Zram]]\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Linux-Memory-Management":{"title":"Linux Memory Management","content":"\n## Memory Management Concepts\n\n### Virtual Memory\n\nVirtual memory is a feature of an operating system (OS) that enables a computer to be able to compensate for shortages of physical memory by temporarily transferring pages of data from random access memory (RAM) to disk storage. This allows a computer to run larger applications or multiple applications concurrently.\n\nIn the Linux operating system, data is organized into blocks called pages, which are typically 4 kilobytes (KB) in size. When a process in a computer attempts to access a specific piece of data in memory, the CPU translates the virtual address (used by the process) into a physical address (where the data is actually stored). This translation process requires multiple memory accesses and can be time-consuming.\n\nTo reduce the number of memory accesses required for address translation and improve the performance of the system, CPUs utilize a cache called the Translation Lookaside Buffer (TLB). The TLB stores recently used virtual-to-physical address translations, allowing the CPU to access the physical address more quickly. However, the TLB is typically a limited resource and applications with large memory working sets may suffer performance degradation if they are unable to utilize the TLB effectively.\n\n### Transparent Huge Pages\n\nWhen assigning memory to processes, CPUs typically use blocks of memory called pages, which are typically 4 kilobytes (KB) in size. The CPU's Memory Management Unit (MMU) is responsible for translating virtual memory addresses into physical memory addresses when processing incoming input/output (I/O) requests. This process can be time-consuming, especially when dealing with a large number of 4 KB pages. Fortunately, it has its own TLB cache (translation lookaside buffer), which reduces the potential time required to access a given memory address by caching the most recently used memory. The fact that the TLB cache size is usually very limited can cause a large potential bottleneck for applications with high memory entropy.\n\nMany modern CPU architectures support direct memory page mapping via higher levels in the page table. On x86, for example, entries in the second and third level page tables can be used to map 2M and even 1G pages. In Linux, such pages are referred to as huge. The use of huge pages relieves TLB pressure, improves TLB hit-rate, and thus improves overall system performance.\n\n### LRU list\n\nA pair of least recently used (LRU) lists are used by the Linux kernel to track pages. Pages that have been recently accessed are kept in the \"active\" list, and newly accessed pages are at the top of the list. If a page has not been accessed recently, it is removed from the list's queue and moved to the top of the \"inactive\" list. When a process accesses a page in the inactive list, it is returned to the active list.\n\n### Unevictable LRU Infrastructure\n\nAn x86 64 platform with 128 GB main memory, for example, will have more than 32 million 4k pages in a single region. If the majority of these pages are unevictable, vmscan will scan the LRU lists for evictable parts, which will consume a significant amount of CPU. The system's performance will deteriorate.\n\nThe unevictable list addresses the following classes of unevictable pages:\n\n- Those owned by ramfs.\n- Those in the SHM_LOCK shared memory zones of ramfs\n- VMAs marked as VM_LOCKED (mlock()ed) (virtual memory area)\n\nFor each zone, the Unevictable LRU engine generates a separate list of LRUs. The unevictable list is referred to as such, and the PG_unevictable flag is used to indicate that pages are unevictable.\n\nThe Unevictable LRU infrastructure maintains unevictable pages on an additional LRU list for a few reasons:\n\n1. We get to “treat unevictable pages just like we treat other pages in the system - which means we get to use the same code to manipulate them, the same code to isolate them (for migrate, etc.), the same code to keep track of the statistics, etc...” - Rik van Riel\n2. We want to be able to migrate unevictable pages between nodes for memory defragmentation, workload management and memory hotplug. The linux kernel can only migrate pages that it can successfully isolate from the LRU lists. If we were to maintain pages elsewhere than on an LRU-like list, where they can be found by isolate_lru_page(), we would prevent their migration, unless we reworked migration code to find the unevictable pages itself.\n\nThe unevictable list does not differentiate between files and anonymous, swap pages. This distinction only applies when pages are evictable.\n\n# What is MGLRU\n\nThe Linux kernel has developed mechanisms designed to increase the chances of predicting which memory pages will be accessed in the near future. Yu Zhao's MGLRU (multi generational least recently used) patch set is an attempt to improve the situation. It aims to make it easier for the system to discard unused data pages in order to make room in memory for new data.\n\nA pair of least recently used (LRU) lists are used by the kernel to track pages. Pages that have been recently accessed are kept in the \"active\" list, and newly accessed pages are at the top of the list. Some pages end up in the inactive list, which means they will be reclaimed relatively quickly once they are no longer required. For various reasons, the kernel has a long history of dumping file-backed pages. This issue is especially effective on cloud systems.\n\nThe MGLRU patches attempt to address these issues with two key changes:\n\n- Add more LRU lists to cover the range of page ages between the current active and inactive lists; these lists are called \"generations\".\n- Reduce overhead by changing the way pages are scanned (the old system uses a complex reverse mapping algorithm)\n\nOnly the oldest generation should be considered when reclaiming pages. The \"oldest generation\" may differ for anonymous and file-backed pages; anonymous pages may be more difficult to reclaim in general (they must always be written to swap), and the new code retains some of the bias toward aggressively reclaiming file-backed pages. As a result, file-backed pages may not survive reclaim for as many generations as anonymous pages. However, the current patch only allows reclaiming of file-backed pages to get one generation ahead of anonymous pages.\n\n# Sources\n\n- \u003chttps://lwn.net/Articles/851184/\u003e\n- \u003chttps://www.kernel.org/doc/html/v5.0/vm/unevictable-lru.html\u003e\n- \u003chttps://docs.kernel.org/admin-guide/mm/concepts.html#mm-concepts\u003e\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Misc":{"title":"Misc","content":"\n# Index\n\n- [[notes/ZeroTier]]\n- [[notes/VS Code Server]]\n- [[notes/Recommended Tools]]\n- [[notes/Thorium]]\n- [[notes/Trim]]\n- [[notes/Data Structures]]\n- [[notes/Valgrind]]\n- [[notes/C++ multithreading]]\n- [[notes/Hashmap]]\n- [[notes/Optimizing images]]","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Networking":{"title":"Networking","content":"\nWIP\n\nWelcome to the networking section of my digital garden. In this section, you will find a collection of notes and articles related to networking and network technologies. The following is an index of the various topics that you will find in this section:\n\n# Index\n\n- [[notes/OSPF]]\n- [[notes/VLAN]]\n- [[notes/STP]]\n- [[notes/XDP-Tutorial]]\n- [[notes/Socket programming]]\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/OSPF":{"title":"OSPF","content":"\nWIP\n\n# Link-state routing protocols\n\nRouters in a link-state routing protocol exchange information about the state of their own links via a process known as link-state advertising. Each router broadcasts to all other routers in the network a link-state advertisement (LSA) containing information about the state of its own links.\n\nThe LSA includes the following information:\n\n- The router's ID: This is a unique identifier for the router.\n- The links or neighbors the router is connected to: This includes the destination of the link, the cost or metric of the link, and the status of the link (up or down).\n- The sequence number: This is a number that indicates the age of the LSA. The router increments the sequence number each time it sends an updated LSA.\n\nWhen a router receives an LSA from another router, it stores the information in its own link-state database and sends a copy to all of its neighbors. This procedure is repeated until all routers in the network have received the LSA and updated their link-state databases.\n\nThe topological map of the entire network is stored in the link-state database, which the router uses to calculate the shortest path to a destination using a routing algorithm. The topological map is used to calculate the shortest path between any two points in the network using a routing algorithm, such as Dijkstra's algorithm. This allows the router to determine the best path to send data packets to their destination.\n\nAlthough link-state routing protocols are more complex and resource-intensive than distance-vector routing protocols, they have several advantages. They provide more accurate and up-to-date network information, allowing for more efficient routing. They also enable the creation of hierarchical networks, in which the network is divided into smaller sections and only the links between these sections are exchanged between routers, reducing the amount of information exchanged and increasing efficiency.\n\nOne example of a link-state routing protocol is Open Shortest Path First (OSPF).\n\n# Open Shortest Path First (OSPF)\n\n## OSPF Packet Types\n\nOpen Shortest Path First (OSPF) is a link-state routing protocol that exchanges information between routers using five different types of protocol packets or messages. These packets are:\n\n1. Hello: The Hello packet is used by routers to establish and maintain neighbor relationships. It is sent on a regular basis to all of a router's neighbors to confirm that the link is still active and to negotiate OSPF connection parameters such as the router's ID and the area it belongs to.\n\n2. Database Description (DD): The DD packet is used by routers to exchange link-state information. A router sends it to its neighbors in order to describe the contents of its link-state database. This information is then used by the neighbors to update their own link-state databases.\n\n3. Link-State Request (LSR): The LSR packet is used to ask a neighbor for specific pieces of link-state information. If a router's link-state database is missing some information, it can send an LSR to request the missing data.\n\n4. Link-State Update (LSU): The LSU packet is used to send link-state information to a neighbor. It is sent in response to an LSR or as part of the routers' regular exchange of link-state information.\n\n5. Link-State Acknowledgment (LSAck): The LSAck packet is used to acknowledge the receipt of an LSU. A router sends it to the LSU sender to confirm that the link-state information was received and processed correctly.\n\nThese five types of OSPF packets are used to establish and maintain neighbor relationships, exchange link-state information, and ensure the link-state database's accuracy and reliability.\n\n## OSPF Entries\n\nIn Open Shortest Path First (OSPF), there are three types of entries or tables that are used to store information about the network. These tables are:\n\n1. Router table: The router table, also known as the forwarding table, stores information about all known network destinations' routes. It is used by the router to determine the next hop for a forwarded packet. The router table is filled with data from the link-state database.![[notes/assets/img/O_Pasted image 20221224185350.png]]\n\n2. Link-state database: The link-state database stores a detailed representation of the entire network, including information about the links and neighbors of each router, as well as the cost or metric of each link. The link-state database is populated using link-state advertisements (LSAs) received from other routers. `display ospf lsdb` command to view lsdb information.![[notes/assets/img/O_Pasted image 20221224185330.png]]\n\n3. Neighbor table: The neighbor table stores data about the routers that are directly connected to the local router. It contains the router's ID, the link to the neighbor, and the neighbor's status (up or down). The neighbor table is used to keep track of neighbors and exchange link-state information with other routers. `display ospf peer` command to view status information.![[notes/assets/img/O_Pasted image 20221224185301.png]]\n\nThese three tables are used by OSPF routers to exchange information about the network and determine the best route for forwarding packets to their destination.\n\n## Establishing OSPF adjacency\n\nRouters discover each other by exchanging Hello packets. When a router receives a Hello packet from a neighbor, it adds the neighbor to its neighbor table and replies with another Hello packet. This establishes the two routers' neighbor relationship. They negotiate which router will be the master and which will be the slave. The master router initiates the exchange of link-state information, while the slave router responds to information requests.\n\nThe role of master or slave is determined based on the following criteria:\n\n1. Router ID: The router with the highest Router ID becomes the master. The Router ID is a unique identifier for each router, and it is determined by the highest IP address of the router's active interfaces.\n\n2. Priority: If the Router IDs are the same, the router with the highest priority becomes the master. The priority is a value between 0 and 255 that can be manually configured on each router. If the priorities are also the same, both routers become masters.\n\nAfter establishing a neighbor relationship, the routers begin exchanging link-state information. A Database Description (DD) packet is sent from one router to the other, describing the **summary** of contents of its link-state database. The other router then sends a Link-State Request (LSR) packet to inquire about any missing data. The first router responds with the requested information in the form of a Link-State Update (LSU) packet. After that, the other router sends LSAck to confirm receipt of the LSU. This process is repeated until each router has a complete copy of the other's link-state database.\n\nBoth routers are considered fully adjacent once they have a complete copy of each other's link-state database. They can then exchange routing information and forward packets to one another.\n\n![[notes/assets/img/O_Pasted image 20221224191057.png]]\n\n## DR and BDR\n\nIn Open Shortest Path First (OSPF), the Designated Router (DR) and the Backup Designated Router (BDR) are special roles that are used to reduce the amount of link-state information that is exchanged between routers in a multi-access network, such as a LAN.\n\nA multi-access network is a type of network where multiple devices are connected to the same physical link, such as a Ethernet switch. In a multi-access network, all the routers are connected to the same broadcast domain, and they can all send and receive packets to and from any other device on the network.\n\nIn OSPF, the DR and BDR are responsible for exchanging link-state information with the other routers in the network. This reduces the amount of link-state information that needs to be exchanged, as the other routers only need to exchange information with the DR and BDR, rather than with every other router on the network.\n\nThe DR is the primary router responsible for exchanging link-state information, while the BDR is a backup router that takes over if the DR fails. The DR and BDR are elected by the routers in the network based on their Router IDs and priorities. The router with the highest Router ID becomes the DR, and the router with the next highest Router ID becomes the BDR. If the Router IDs are the same, the router with the highest priority becomes the DR. If the priorities are also the same, both routers become DRs.\n\nIn summary, the DR and BDR are special roles in OSPF that are used to reduce the amount of link-state information exchanged in a multi-access network. The DR is the primary router responsible for exchanging link-state information, while the BDR is a backup router that takes over if the DR fails. The DR and BDR are elected by the routers in the network based on their Router IDs and priorities.\n\n## Multi Area OSPF\n\nIn Open Shortest Path First (OSPF), a multi-area network is a network that is divided into multiple areas, with each area containing a collection of networks and routers that are connected by a common **area border router (ABR)**. This allows for more efficient routing within the OSPF network, as routers within the same area exchange information about the state of their own links and do not need to exchange information about links in other areas.\n\nEach area in a multi-area OSPF network is given a unique area ID, which is used to identify the area in the link-state database. The ABR is in charge of connecting the area to the rest of the network and exchanging link-state information with other areas.\n\nIn the form of a summary LSA, the ABR sends a summary of the link-state information for the area to the other areas. This allows the other areas to get a high-level view of the networks in the area without having to keep detailed information about every link and router.\n\nThe ABR also maintains a link-state database for the entire network, which includes information about the links and routers in all the areas. This allows the ABR to route packets between areas and to calculate the shortest path between any two points in the network.\n\nMulti-area OSPF provides several benefits, including improved scalability and reduced network traffic. It also allows for the creation of a hierarchical network structure, which can make it easier to manage and troubleshoot the network.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Optimizing-images":{"title":"Optimizing images","content":"\n# Overview\n\nImage optimization is the process of reducing the file size of an image without compromising its visual quality. Optimizing images can improve the speed and performance of a website or application, as well as reduce data usage and improve the user experience. This documentation will provide an in-depth look at the various techniques and tools available for optimizing images as well as best practices for implementing image optimization in your projects.\n\nLossy and lossless compression are 2 types of compression. Lossy compression algorithms discards some of the data in order to achieve a smaller file size. This can result in visible artifacts and a degradation of image quality (although with good settings it can be very hard to notice), but the compression ratio is usually much higher than lossless compression. Lossless compression algorithms do not discard any image data as the name suggests. This results in a lower compression ratio. The most common lossless image compression formats include PNG and GIF while JPEG is the most widely used lossy image compression format. It's important to consider the purpose of the image and the intended audience when choosing between lossy and lossless compression. If the image will be used for professional or critical applications lossless compression is recommended, while lossy compression may be more suitable for casual or web-based applications.\n\nThere are a lot of different image formats out there, and some aren't as good at compression as others, but they might work better with certain things. I personally like WEBP because it has both lossless and lossy compression options and it's pretty popular. This guide will also show you how to get the best compression with each format. If you don't care about compatibility and just want to shrink the file size as much as possible you can try using less mainstream formats like AVIF or JPEG XL (not to be confused with regular JPEG).\n\n# Optimizing PNG files\n\nI personally optimize with oxipng, a multithreaded lossless PNG compression optimizer. Because it is a command line tool, it may not be appropriate for non-power users.\n\n## Examples:\n\n#### Optimizing every .png file in a directory\n\n```C\noxipng -o max --strip safe *.png\n```\n\nThis command will optimize all png files in the current directory. This command provides nearly maximum optimization; further optimization can be obtained by including the -Z flag, which enables a slower but better compressing Zopfli algorithm; I did not include it because it significantly lengthens the optimization process.\n\n`-o max` sets optimization level to maximum, its a stable alias for maximum compression.\n\n## Optimization levels for oxipng\n\nOptimization levels:\n\n```C\n-o 0   =\u003e --zc 5  --fast             (1 trial, determined heuristically)\n-o 1   =\u003e --zc 10 --fast             (1 trial, determined heuristically)\n-o 2   =\u003e --zc 11 -f 0,1,6,7 --fast  (1 trial, determined by fast evaluation)\n-o 3   =\u003e --zc 11 -f 0,7,8,9         (4 trials)\n-o 4   =\u003e --zc 12 -f 0,7,8,9         (4 trials; same as `-o 3` for zopfli)\n-o 5   =\u003e --zc 12 -f 0,1,2,5,6,7,8,9 (8 trials)\n-o 6   =\u003e --zc 12 -f 0-9             (10 trials)\n-o max =\u003e                            (stable alias for the max compression)\n```\n\n# Optimizing WEBP\n\n### Lossless\n\nFollowing command can be used to losslessly compress a png file to webp with highest compression settings:\n\n```C\ncwebp -quiet -v -mt -lossless -z 9 input.png -o output.webp\n```\n\n`-mt` Use multi-threading for encoding, if possible.\n\n`-lossless`  Enable lossless compression.\n\n`-m 6` This parameter controls the trade off between encoding speed and the compressed file size and quality.  Possible\nvalues range from 0 to 6. Default value is 4.  When higher values are used, the encoder will spend more time inspecting additional encoding  possibilities  and  decide on the quality gain.  Lower value can result in faster processing time at the expense of larger file size and lower compression quality.\n\n### Lossy\n\nFollowing command can be used to lossy compress a png file to webp with highest compression settings:\n\n```C\ncwebp -quiet -v -mt -af -m 6 -q 97 input.png -o output.webp\n```\n\n`-mt` Use multi-threading for encoding, if possible.\n\n`-af` Turns auto-filter on. This algorithm will spend additional time optimizing the filtering strength to reach a well-balanced quality.\n\n`-m 6` This parameter controls the trade off between encoding speed and the compressed file size and quality.  Possible\nvalues range from 0 to 6. Default value is 4.  When higher values are used, the encoder will spend more time inspecting additional encoding  possibilities  and  decide on the quality gain.  Lower value can result in faster processing time at the expense of larger file size and lower compression quality.\n\n`-q 97` Controls quality level.\n\nAdditionally, `-hint` can be used to specify a hint about the type of input image. The following values are possible: photo, picture or graph. By knowing what type of data is being compressed, webp can potentially achieve higher compression.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Post-install-optimizations":{"title":"Post install Optimizations","content":"\n### Editing mkinitcpio.conf for faster boot times\n\nReplace udev with systemd for faster boots and set compression algorithm to zstd and compression level to 2 because compression ratio increase isn't worth the increased boot time.\n\n(bellow isnt the whole file, just the parts that needs changes)\n\n```ini\nHOOKS=\"base systemd autodetect...\n\nCOMPRESSION=\"zstd\"\nCOMPRESSION_OPTIONS=(-2)\n```\n\nNote: You can replace base AND udev with systemd but you will lose access to recovery shell.\n\n### Changing io schedulers\n\nThe process to change I/O scheduler, depending on whether the disk is rotating or not can be automated and persist across reboots. For example the udev rule below sets the scheduler to none for NVMe, mq-deadline for SSD/eMMC, and bfq for rotational drives:\n\n```ini\n# /etc/udev/rules.d/60-ioschedulers.rules\n\n# set scheduler for NVMe\nACTION==\"add|change\", KERNEL==\"nvme[0-9]n[0-9]\", ATTR{queue/scheduler}=\"none\"\n# set scheduler for SSD and eMMC\nACTION==\"add|change\", KERNEL==\"sd[a-z]*|mmcblk[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"mq-deadline\"\n# set scheduler for rotating disks\nACTION==\"add|change\", KERNEL==\"sd[a-z]*\", ATTR{queue/rotational}==\"1\", ATTR{queue/scheduler}=\"bfq\"\n```\n\n### Editing /etc/makepkg.conf (in Arch linux or derivatives)\n\nEdit makepkg config file for it to utilize all threads on your cpu\nExample for 12 threads:\n\n```ini\nMAKEFLAGS=\"-j12\"\n```\n\n### Auto nice daemons and irq balance\n\nAnanicy-cpp can be installed to automatically set [nice](https://en.wikipedia.org/wiki/Nice_(Unix)) levels.\n\n[Irq balance](https://wiki.archlinux.org/title/Improving_performance#irqbalance) distributes [hardware interrupts](https://en.wikipedia.org/wiki/Interrupt_request_(PC_architecture)) across available processors to improve system performance.\n\n### Zram or Zswap\n\nZswap is a kernel feature that provides a compressed RAM cache for swap pages. Pages which would otherwise be swapped out to disk are instead compressed and stored into a memory pool in RAM. Once the pool is full or the RAM is exhausted, the least recently used (LRU) page is decompressed and written to disk, as if it had not been intercepted. After the page has been decompressed into the swap cache, the compressed version in the pool can be freed.\n\nThe difference compared to ZRAM is that zswap works in conjunction with a swap device while zram is a swap device in RAM that does not require a backing swap device.\n\nSince it is enabled by default, [disable zswap](https://wiki.archlinux.org/title/Zswap#Toggling_zswap \"Zswap\") when you use zram to avoid it acting as a swap cache in front of zram. Having both enabled also results in incorrect [zramctl](https://man.archlinux.org/man/zramctl.8) statistics as zram remains mostly unused; this is because zswap intercepts and compresses memory pages being swapped out before they can reach zram.\n\n##### Recommended configurations for zswap\n\n```C\n# echo zstd \u003e /sys/module/zswap/parameters/compressor\n\n# echo 10 \u003e /sys/module/zswap/parameters/max_pool_percent\n```\n\nAbove will change zswap settings only for current session, to make the setting changes persist add `zswap.compressor=zstd zswap.max_pool_percent=10` to your bootloader's config file for the kernel command line.\n\n`/etc/sysctl.d/99-swap-tune.conf:`\nfor ssd:\n\n```ini\nvm.page-cluster = 1 \n```\n\nfor hdd:\n\n```ini\nvm.page-cluster = 2\n```\n\n##### Recommended configurations for zram\n\n`/etc/systemd/zram-generator.conf:`\n\n```ini\n[zram0]\nzram-size = ram * 1\ncompression-algorithm = zstd\n```\n\nAbove config file is for [systemd zram generator](https://github.com/systemd/zram-generator)\n\nYou can increase `zram-size` further if you find compression ratio to be high enough.\n\n`/etc/sysctl.d/99-swap-tune.conf:`\n\n```ini\nvm.page-cluster = 0\n```\n\nA more detailed explanation can about why these values were chosen can be found in [[notes/Zram]].\n\n### Transparent Huge Pages\n\nTo summarize, transparent hugepages are a framework within the Linux kernel that allows it to automatically facilitate and allocate large memory page block sizes to processes (such as games) with sizes averaging around 2 MB per page and occasionally 1 GB (the kernel will automatically adjust the size to what the process needs).\n\n```bash\n[user@host ~]$ cat /sys/kernel/mm/transparent_hugepage/enabled\n[always] madvise never\n```\n\nThere are 3 values you can choose You should try each value yourself to see if it improves your workflow, for more information click here: [[notes/Transparent Huge Pages]].\nTo change the value for current session:\n\n```bash\necho 'always' | sudo tee /sys/kernel/mm/transparent_hugepage/enabled\n```\n\nTo make changes persist:\\\nInstall sysfsutils and then add `kernel/mm/transparent hugepage/enabled=always` to `/etc/sysfs.conf` or add `transparent_hugepage=always` to your bootloader's config file for the kernel command line.\n\n# Additional sources\n\n#### initramfs\n\n\u003chttps://wiki.archlinux.org/title/Mkinitcpio/Minimal_initramfs\u003e\n\n#### Zram\n\n\u003chttps://linuxreviews.org/Zram\u003e\n\n\u003chttps://docs.kernel.org/admin-guide/sysctl/vm.html\u003e\n\n\u003chttps://www.reddit.com/r/Fedora/comments/mzun99/new_zram_tuning_benchmarks/\u003e\n\n#### Transparent Huge Pages\n\n\u003chttps://www.kernel.org/doc/html/latest/admin-guide/mm/transhuge.html\u003e\n\n\u003chttps://access.redhat.com/solutions/46111\u003e\n\n\u003chttps://www.reddit.com/r/linux_gaming/comments/uhfjyt/underrated_advice_for_improving_gaming/\u003e\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Recommended-Tools":{"title":"Recommended Tools","content":"\nThese are some of the tools and programs that I recommend and use. I'll keep adding more as I find them.\n\n## gping\n\nPing, but with graph and statistics. Works fine on tty.\n![[notes/assets/img/O_gping.png]]\n\n## Bat\n\nCat clone with syntax highlighting and git integration.\n![[notes/assets/img/O_bat.png]]\n\n\n## grc\n\nGeneric colorizer that works on many commands.\n\n![[notes/assets/img/O_Pasted image 20221229141033.png]]\n\n![[notes/assets/img/O_Pasted image 20221229141309.png]]","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/STP":{"title":"STP","content":"\n# Overview\n\nSpanning Tree Protocol (STP) is a network protocol that ensures an Ethernet network has a loop-free topology. STP is used to prevent network loops, which can occur when two devices on a network have multiple paths. Broadcast storms can be caused by network loops, which can severely degrade network performance and even bring the network down.\n\nSTP selects a single path between two devices and blocks all other paths. STP will unblock one of the blocked paths and use it as the active path if the primary path fails. This ensures that only one active path exists between two devices, preventing loops from forming.\n\nSTP uses a tree-based algorithm to determine the best path between two devices and is based on the IEEE 802.1D standard. It determines the best path using a set of parameters, including the cost of the link and the port identifier. STP is implemented in switches and is transparent to end devices, which means it operates behind the scenes and does not require any end-user configuration.\n\n# Root bridge selection\n\nSpanning Tree Protocol (STP) is a networking protocol that is used to prevent loops in a network by selecting a root bridge (also called a root switch) and blocking unnecessary links. The root bridge is the central reference point in the network, and all other switches in the network determine their position relative to the root bridge.\n\nThe root bridge is selected based on the bridge identifier (BID), which consists of a priority value and the MAC address of the switch. The priority value is a numerical value that can be manually configured on each switch, and the MAC address is a unique identifier that is assigned to each switch. By default, the switch with the lowest priority value becomes the root bridge. If multiple switches have the same priority, the switch with the lowest MAC address becomes the root bridge.\n\nOnce the root bridge is selected, the root path cost is calculated for each switch. The root path cost is the total cost of the path from the root bridge to the switch. The cost is determined based on the speed of the link and the type of network media being used. The switch with the lowest root path cost becomes the root port for each switch, which is the port that is used to forward traffic to the root bridge.\n\n# Root ports\n\nThe port identifier (PID) is a value that is used to identify and manage the ports on a switch. The PID consists of a priority value and the port number, and it is used by the switch to determine the root port and the designated port for each switch.\n\nThe priority value is a numerical value that can be manually configured on each port, and it is used to determine the root port and the designated port for each switch. The port with the lowest priority becomes the root port and the designated port for the switch. If multiple ports have the same priority, the port with the lowest port number becomes the root port and the designated port.\n\nThe root port is the port that is used to forward traffic to the root bridge, and the designated port is the port that is used to forward traffic from the switch to other parts of the network. The designated port is selected based on the lowest PID, and it is used to ensure that there is only one active path between any two points in the network, which prevents loops and improves network performance.\n\n# Bridge Protocol Data Unit (BPDU)\n\nA Bridge Protocol Data Unit (BPDU) is a message that is used to exchange information between switches and to establish the root bridge and root port for each switch. BPDUs are sent between switches on a regular basis, and they contain information about the switch, such as the switch's MAC address and the switch's port identifier (PID).\n\nWhen a switch receives a BPDU from another switch, it compares the information in the BPDU with the information in its own BPDUs to determine the root bridge and root port for the network. The switch with the lowest PID becomes the root bridge, and the port with the lowest PID becomes the root port for each switch.\n\n## BPDU types\n\nThere are two types of Bridge Protocol Data Units (BPDUs): Configuration BPDUs and Topology Change Notification (TCN) BPDUs.\n\nConfiguration BPDUs are used to exchange information about the switches in the network and to establish the root bridge and root port for each switch. They are sent on a regular basis to ensure that the spanning tree is up-to-date and to prevent loops in the network. Configuration BPDUs contain information about the switch, such as the switch's MAC address, the switch's port identifier (PID), and the switch's path cost.\n\nTopology Change Notification (TCN) BPDUs are used to inform other switches in the network of a change in the network topology. They are sent by the switch that detects the change, and they are used to trigger a reconfiguration of the spanning tree. TCN BPDUs are used to ensure that the spanning tree remains up-to-date and to prevent loops in the network.\n\n# Port states\n\nIn Spanning Tree Protocol (STP), there are five port states that a port can be in:\n\n1. Disabled: In the disabled state, a port is not participating in the forwarding of traffic and is not receiving or sending any traffic. This state is usually used for administrative purposes, such as when a port is being configured or troubleshooted.\n\n2. Blocking: In the blocking state, a port does not participate in the forwarding of traffic, and it blocks all incoming traffic except for STP BPDUs. This state is used to prevent loops in the network by ensuring that there is only one active path between any two points in the network.\n\n3. Listening: In the listening state, a port is preparing to forward traffic, and it listens for BPDUs to ensure that the network is stable. The port blocks all incoming traffic except for STP BPDUs and sends BPDUs to confirm the network topology.\n\n4. Learning: In the learning state, a port is learning about the network and building its MAC address table. The port blocks all incoming traffic except for STP BPDUs and begins to forward traffic to the root bridge.\n\n5. Forwarding: In the forwarding state, a port is actively forwarding traffic and is participating in the normal operation of the network. The port accepts and forwards all incoming traffic.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Socket-programming":{"title":"Socket programming","content":"\n# Overview\n\nSocket programming is a technique for developing networked applications that use sockets to communicate over a network. A socket is a computer network endpoint for sending and receiving data.\n\nA socket is used by the client and server in socket programming to communicate with each other. The client makes a request to the server, and the server responds with the information requested. This communication can be synchronous (blocking) or asynchronous (non-blocking).\n\nOne advantage of socket programming is that it enables the development of networked applications that can communicate with one another regardless of the underlying operating system or hardware platform. This makes it an effective tool for developing distributed systems and applications that can communicate across a wide area network (WAN).\n\nSockets are classified into two types: stream sockets and datagram sockets. Stream sockets are TCP/IP-based connections that provide a dependable, stream-oriented connection between the client and server. They are appropriate for applications that require consistent data delivery, such as file transfer and email.\n\nDatagram sockets communicate between the client and server using the UDP/IP protocol and are connectionless. They are appropriate for applications that require fast data transmission, such as real-time audio and video streaming, but do not require reliable data delivery.\n\nThe first step in creating a socket in a client-server application is to create a socket descriptor with the `socket()` function. This function accepts three arguments: the address family (AF_INET for IPV4 and AF_INET6 for IPV6), the type of socket (SOCK STREAM for stream sockets and SOCK DGRAM for datagram sockets), and the protocol (IPV4 or IPV6) (usually 0, which allows the operating system to choose the appropriate protocol).\n\nOnce the socket descriptor has been created, the server must use the `bind()` function to bind the socket to a specific port and address. The client then uses the `connect()` function to connect to the server.\n\nFollowing the establishment of the connection, the client and server can exchange data using the `send()` and `recv()` functions. When the communication is finished, the client and server should use the `close()` function to close the socket.\n\nSocket programming is a powerful tool for developing networked applications that is used in a wide range of applications and systems. Developers can create robust and scalable network-capable applications with a solid understanding of socket programming and its underlying principles.\n\n# Examples\n\n## Server\n\n```C\n#include \u003carpa/inet.h\u003e  \n#include \u003cstdio.h\u003e  \n#include \u003cstring.h\u003e  \n#include \u003csys/socket.h\u003e  \n#include \u003cunistd.h\u003e  \n  \n// Main function for the server  \nint main(int argc, char *argv[]) {  \n    int socket_desc, client_sock, c, read_size;  \n    struct sockaddr_in server, client;  \n    // Initialize the message buffer to 0  \n    char client_message[2000] = {0};  \n  \n    // Create socket  \n    socket_desc = socket(AF_INET, SOCK_STREAM, 0);  \n    if (socket_desc == -1) {  \n        printf(\"Could not create socket\");  \n    }\n    puts(\"Socket created\");  \n  \n    // Prepare the sockaddr_in structure  \n    server.sin_family = AF_INET;  \n    server.sin_addr.s_addr = INADDR_ANY;  \n    server.sin_port = htons(8888);  \n  \n    // Bind  \n    if (bind(socket_desc, (struct sockaddr *)\u0026server, sizeof(server)) \u003c 0) {  \n        // print the error message  \n        perror(\"bind failed. Error\");  \n        return 1;  \n    }\n    puts(\"bind done\");  \n  \n    // Listen  \n    listen(socket_desc, 3);  \n  \n    // Accept and incoming connection  \n    puts(\"Waiting for incoming connections...\");  \n    c = sizeof(struct sockaddr_in);  \n  \n    // accept connection from an incoming client  \n    client_sock =  \n        accept(socket_desc, (struct sockaddr *)\u0026client, (socklen_t *)\u0026c);  \n    if (client_sock \u003c 0) {  \n        perror(\"accept failed\");  \n        return 1;  \n    }    puts(\"Connection accepted\");  \n  \n    // Receive a message from client  \n    while ((read_size = recv(client_sock, client_message, 2000, 0)) \u003e 0) {  \n        // fix garbled message after first message  \n        client_message[read_size] = '\\0';  \n  \n        // Echo the message back to the client  \n        write(client_sock, client_message, strlen(client_message));  \n  \n        // Clear the message buffer  \n        memset(client_message, 0, 2000);  \n    }  \n    // Check if client disconnected  \n    if (read_size == 0) {  \n        puts(\"Client disconnected\");  \n        fflush(stdout);  \n    }else if (read_size == -1) {  \n        perror(\"recv failed\");  \n    }  \n    return 0;  \n}\n```\n\n## Client\n\n```C\n#include \u003carpa/inet.h\u003e  \n#include \u003cstdio.h\u003e  \n#include \u003cstring.h\u003e  \n#include \u003csys/socket.h\u003e  \n#include \u003cunistd.h\u003e  \n  \n// Main function for the client  \nint main(int argc, char *argv[]) {  \n    int sock;  \n    struct sockaddr_in server;  \n    char message[1000], server_reply[2000];  \n  \n    // Create socket  \n    sock = socket(AF_INET, SOCK_STREAM, 0);  \n    if (sock == -1) {  \n        printf(\"Could not create socket\");  \n    }    puts(\"Socket created\");  \n  \n    // Prepare the sockaddr_in structure  \n    server.sin_addr.s_addr = inet_addr(\"127.0.0.1\");  \n    server.sin_family = AF_INET;  \n    server.sin_port = htons(8888);  \n  \n    // Connect to remote server retrying every 5 seconds if connection fails and print status  \n    while (connect(sock, (struct sockaddr *)\u0026server, sizeof(server)) \u003c 0) {  \n        printf(\"Connection failed. Retrying in 5 seconds...\\n\");  \n        sleep(5);  \n    }  \n    puts(\"Connected\\n\");  \n  \n    // keep communicating with server  \n    while (1) {  \n        // get multiple words input from user  \n        printf(\"Enter message : \");  \n        fgets(message, 1000, stdin);  \n  \n        // Send some data  \n        if (send(sock, message, strlen(message), 0) \u003c 0) {  \n            puts(\"Send failed\");  \n            return 1;  \n        }  \n        // Clear the message buffer  \n        memset(message, 0, 1000);  \n  \n        // Receive a reply from the server  \n        if (recv(sock, server_reply, 2000, 0) \u003c 0) {  \n            puts(\"recv failed\");  \n            break;  \n        }  \n        // Print the server's reply  \n        printf(\"Server reply :\");  \n        puts(server_reply);  \n  \n        // Clear the message buffer  \n        memset(server_reply, 0, 2000);  \n    }  \n    // close the socket  \n    close(sock);  \n    return 0;  \n}\n```\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Thorium":{"title":"Thorium","content":"\nChromium fork for linux named after [radioactive element No. 90](https://en.wikipedia.org/wiki/Thorium) that takes pride in being a highly optimized web browser.\n\nThorium makes many modifications to compiler configurations which highly improve performance and responsiveness. Google tries to minimize size at any cost (including RAM usage and performance), but Thorium takes a different approach. Thorium takes up approximately ~250MB compared to ~150MB for Chrome. Me and many others appreciate speed and performance over the smallest size.\n\nYou can get Thorium from \u003chttps://github.com/Alex313031/Thorium\u003e\n\n## Compiler Optimizations\n\nThorium enables the use of numerous instruction set extensions, allowing the CPU to perform certain operations much more efficiently and quickly. For example the Chromium Project, makes extensive use of vectorizable code, so AVX (Advanced Vector Extensions) is a natural next step in performance improvement. The only reason it isn't used by default in Chromium is for compatibility: older processors (pre-2011) lack AVX capability and thus cannot run AVX-compliant programs. But don't worry if you have an old processor that lacks AVX; the creator occasionally makes SSE4/SSE3-only releases for Linux and Windows.\n\nThis represents only the tip of the iceberg. If you're interested in learning more about Thorium's performance optimizations, click [here](https://thorium.rocks/optimizations).\n\n## Some Benchmarks\n\nDepending on your operating system and hardware, performance improvements may vary. Here are some results from tests on an old CPU, an FX-8370 clocked at 4.7GHz across all cores.\n\n### Chromium\n\n![[notes/assets/img/O_chromium_octane.png]]\n![[notes/assets/img/O_chromium_speedometer.png]]\n\n### Thorium\n\n![[notes/assets/img/O_thorium_octane.png]]\n![[notes/assets/img/O_thorium_speedometer.png]]\n\nThere are significant performance improvements, but they may not be as dramatic on your device. For example, on my Ryzen 5 5500U, I get a 105 on the chromium speedometer and a 175 on the Thorium speedometer. Not a 3x score difference but still very significant.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Transparent-Huge-Pages":{"title":"Transparent Huge Pages","content":"\nWhen the CPU assigns memory to processes that require it, it typically does so in 4 KB page chunks. Because the CPU's MMU unit actively needs to translate virtual memory to physical memory upon incoming I/O requests, going through all 4 KB pages is naturally an expensive operation. Fortunately, it has its own TLB cache (translation lookaside buffer), which reduces the potential amount of time required to access a specific memory address by caching the most recently used memory. The only issue is that TLB cache size is typically very limited, and when it comes to gaming, especially playing triple AAA games, the high memory entropy nature of those applications causes a huge potential bottleneck.\n\nIn terms of the overhead that TLB lookups will incur. This is due to the technically inherent inefficiency of having a large number of entries in the page table, all with very small sizes.\n\nTo enable automatic use of transparent hugepages, first ensure that they are enabled in your kernel by running `cat /sys/kernel/mm/transparent_hugepage/enabled`. If it says error: the file or directory cannot be found, it means your kernel was built without support for it, and you must either manually build and enable the feature before compiling it or use a different kernel.\n\nThere are 3 values you can choose for transparent huge pages:\n\n### always\n\nShould be self explanatory.\n\n### madvise\n\nOnly enabled inside MADV_HUGEPAGE regions (to avoid the risk of consuming more memory resources, relevant for embedded systems).\n\n### never\n\nEntirely disabled(mostly for debugging purposes).\n\nUse `echo 'always' | sudo tee /sys/kernel/mm/transparent_hugepage/enabled` to set the value to 'always'.\n\nIt may appear that `always` is the best option, but in some cases, such as database software, it degrades performance.\nFor example mongodb docs says:\n\n\u003e Transparent Huge Pages (THP) is a Linux memory management system that reduces the overhead of Translation Lookaside Buffer (TLB) lookups on machines with large amounts of memory by using larger memory pages.\n\u003e\n\u003e However, database workloads often perform poorly with THP enabled, because they tend to have sparse rather than contiguous memory access patterns. When running MongoDB on Linux, THP should be disabled for best performance.\n\nSo you should experiment with each value to see which one works best for your workload.\n\n# Additional sources\n\n\u003chttps://www.kernel.org/doc/html/latest/admin-guide/mm/transhuge.html\u003e\n\n\u003chttps://access.redhat.com/solutions/46111\u003e\n\n\u003chttps://www.mongodb.com/docs/manual/tutorial/transparent-huge-pages/#:~:text=Transparent%20Huge%20Pages%20(THP)%20is,by%20using%20larger%20memory%20pages.\u003e\n\n\u003chttps://www.reddit.com/r/linux_gaming/comments/uhfjyt/underrated_advice_for_improving_gaming/\u003e\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Trim":{"title":"Why do SSDs need trim","content":"\n## How does SSD store data\n\nLet's look at the structure of the SSD to understand the problems it faces and why we need TRIM operation to solve them. Data is typically stored in pages, which are groups of 4KB cells. For most SSDs, the pages are then grouped into clusters of 128 pages called Blocks, with each block containing 512KB.\n\nYou can read data from a page that contains some information or write data to clean pages (with no data from before in them). However, you cannot overwrite data on a previously written 4KB page without also overwriting the remaining 512KB.\n\nThis is because the voltages required to flip a 0 to 1 are frequently much higher than the reverse. Excess voltage has the potential to flip bits on adjacent cells and corrupt data.\n\n## File deletion\n\nWhen you delete a file the SSD simply marks all corresponding pages as invalid. Instead of being physically zeroed out, the sectors are marked as free. This significantly speeds up the deletion process.\n\nAssume you change a file, which corresponds to a single 4KB page change. When you try to modify a 4KB page in an SSD, the entire content of its block, all 512KB of it, must be read into a cache (which can be built into the SSD or use system's main memory), the block must be erased, and then you can write the new data to your target 4KB page. You will also need to restore the remaining unmodified 508KB of data from your cache.\n\n## So what does TRIM do?\n\nTRIM informs the drive that the blocks are no longer in use. That is, they can be deleted and used again for new data.\n\nAn SSD does not understand the file system that has been written to it. As a result, it has no idea how NTFS (For example) deletes files. Now TRIM comes into play. After a file is deleted, the operating system sends a TRIM command to the SSD, along with a list of sectors that should be marked free and erased.\n\nThe TRIM command reduces performance degradation by trimming invalid pages on a regular basis. Windows 10 for example TRIMs your SSD once a week. When that operation is run, the SSD controller cleans out all the data that has been marked as deleted by the OS from the memory cells. Yes, it still has to go through the read-modify-write operation, but it only happens once a week, so if all pages in a block are marked for deletion by the time trimming occurs, there will be no pages to copy to the cache therefore reducing writes and improving device lifespan.\n\nWhen you want to write to a page again, it will be empty and ready for a direct write operation!\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/VLAN":{"title":"VLAN","content":"\nA virtual LAN (VLAN) is a logical grouping of devices in a computer network that behaves as if they are part of the same LAN, despite the fact that the devices are physically connected to different switches or located in different parts of the network. VLANs are used to divide a network into smaller, more manageable segments, as well as to improve network performance and security. This is accomplished by allocating a VLAN to each device and configuring the switch to forward traffic between devices in the same VLAN.\n\nVLANs are commonly used to divide a network into different subnets or broadcast domains, which can be useful for distinguishing between different types of traffic, such as guest and corporate traffic, or for isolating different departments or teams within an organization. VLANs can also be used to improve network security by limiting the scope of broadcasts and limiting access to specific network areas.\n\nVLANs are implemented through VLAN tagging, which adds a VLAN identifier to the header of a packet as it travels across the network. This enables switches to determine which VLAN a packet belongs to and forward it to the appropriate devices. Most modern networking devices, including switches, routers, and network interface cards, support VLAN tagging (NICs).\n\n# VLAN interface types\n\nThere are several types of layer 2 interfaces that can be used in a virtual LAN (VLAN), including:\n\n1. Access ports: An access port is a layer 2 interfaces that are configured to belong to a single VLAN. All traffic sent or received on an access port is associated with the VLAN to which the port is assigned. Access ports are typically used to connect end devices to the network, such as computers and servers.\n\n2. Trunk ports: Trunk ports are layer 2 interfaces that are configured to carry traffic from multiple VLANs. Trunk ports use VLAN tagging to determine which VLAN each packet belongs to and to route the packet to the correct VLAN. Trunk ports are commonly used to connect switches to one another or to connect a switch to a router or other network device.\n\n3. Hybrid ports: A hybrid port is a layer 2 interface that, depending on the configuration, can function as either an access port or a trunk port. Hybrid ports are useful when the VLAN configuration needs to be changed or when a device needs to be connected to multiple VLANs at the same time.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/VS-Code-Server":{"title":"VS Code Server","content":"\nRun [VS Code](https://github.com/Microsoft/vscode) on any machine anywhere and access it in the browser.\n\nCompilations, downloads, and other similar tasks should not be done on your primary computer. To avoid straining your current device, you can perform all of these tasks on a remote machine. Extensions can also be run remotely, consuming fewer system resources.\n\nThe default bundled electron isn't very optimized; however, with VS Code server, you can use your local web browser without having to launch another browser (electron). You can also maximize resource efficiency by using an optimized browser, such as [[notes/Thorium]].\n\nI'm running code server on my Raspberry Pi, and I can also access the pi from anywhere using [[notes/ZeroTier]].\n\nVideo Demo:\n\u003chttps://xeome.github.io/notes/assets/img/code-server.mp4\u003e\n\nFor more information visit [here](https://github.com/coder/code-server)\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Valgrind":{"title":"Valgrind","content":"\n# Overview\n\nValgrind is a tool that aids in debugging and profiling programs written in C, C++, and other languages. It helps developers identify and fix issues such as memory leaks, buffer overflows, and other problems that can cause bugs and crashes.\n\nValgrind works by executing a program in a simulated environment and monitoring its behavior. It can identify a variety of problems, including:\n\n- Memory leaks: Valgrind can detect when a program fails to free memory that it has allocated, resulting in an accumulation of unused memory over time.\n\n- Memory errors: Valgrind can detect when a program accesses memory that it is not intended to, such as when it reads from or writes to uninitialized memory or memory that has already been freed.\n\n- Buffer overflows: Valgrind can detect when a program writes more data to a buffer than it is designed to hold, potentially causing a crash or introducing security vulnerabilities.\n\n- Race conditions: Valgrind can detect when multiple threads of a program access shared resources in an inconsistent or conflicting manner, leading to unpredictable or incorrect behavior.\n\n# Common paremeters\n\nValgrind has many options and parameters that can be used to customize its behavior and the types of problems it can detect. Here are a few of the more commonly used options:\n\n- `--leak-check=full`: This option enables Valgrind's memory leak detection features, and provides a detailed report of any memory that was allocated but not freed by the program.\n\n- `--track-origins=yes`: This option enables Valgrind's origin tracking feature, which can help identify the source of uninitialized memory reads and other errors.\n\n- `--tool=\u003ctoolname\u003e`: This option allows you to specify which tool Valgrind should use to analyze the program. Valgrind comes with a number of different tools, including `memcheck` for memory error detection, `cachegrind` for cache profiling, and `helgrind` for detecting threading errors.\n\n- `--log-file=\u003cfilename\u003e`: This option specifies a file to which Valgrind should write its output. By default, Valgrind writes its output to `stderr`, but this option allows you to redirect the output to a file for easier analysis.\n\n- `--suppressions=\u003cfilename\u003e`: This option specifies a file containing suppression rules that tell Valgrind to ignore certain errors or warnings. This can be useful if you are running Valgrind on a program that generates a lot of false positives or if you are only interested in certain types of errors.\n\nThese are just a few examples of the many options and parameters that are available in Valgrind.\n\n# More examples\n\nExample 1: How Valgrind can be used to detect a memory leak in a C program:\n\n```C\n#include \u003cstdlib.h\u003e\n\nint main(int argc, char** argv) {\n  char* ptr = (char*) malloc(100);\n  // Do something with ptr\n  return 0;\n}\n\n```\n\nIf we compile and run this program using Valgrind, it will report that there is a 100-byte memory leak, because the program allocated memory with `malloc` but did not release it with `free`.\n\n```bash\n$ valgrind --leak-check=full ./a.out\n==4410== Memcheck, a memory error detector\n==4410== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.\n==4410== Using Valgrind-3.19.0 and LibVEX; rerun with -h for copyright info\n==4410== Command: ./a.out\n==4410==\n==4410==\n==4410== HEAP SUMMARY:\n==4410==     in use at exit: 100 bytes in 1 blocks\n==4410==   total heap usage: 1 allocs, 0 frees, 100 bytes allocated\n==4410==\n==4410== 100 bytes in 1 blocks are definitely lost in loss record 1 of 1\n==4410==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==4410==    by 0x109151: main (mem_leak.c:4)\n==4410==\n==4410== LEAK SUMMARY:\n==4410==    definitely lost: 100 bytes in 1 blocks\n==4410==    indirectly lost: 0 bytes in 0 blocks\n==4410==      possibly lost: 0 bytes in 0 blocks\n==4410==    still reachable: 0 bytes in 0 blocks\n==4410==         suppressed: 0 bytes in 0 blocks\n==4410==\n==4410== For lists of detected and suppressed errors, rerun with: -s\n==4410== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)\n```\n\nExample 2: Detecting a buffer overflow:\n\n```C\n#include \u003cstdio.h\u003e\n\nint main(int argc, char** argv) {\n  char *buffer = malloc(10);\n  snprintf(buffer, 20, \"Hello, world!\"); // buffer is too small\n  printf(\"%s\\n\", buffer);\n  return 0;\n}\n```\n\nValgrind is not the best tool for detecting static buffer overflows, but because the code uses dynamically allocated buffers, it works fine.\nWhen we run this program through Valgrind, we get an error because the program tries to write more data to the buffer than it was designed to hold:\n\n```bash\n$ valgrind --leak-check=full ./a.out\n==6888== Memcheck, a memory error detector\n==6888== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.\n==6888== Using Valgrind-3.19.0 and LibVEX; rerun with -h for copyright info\n==6888== Command: ./a.out\n==6888==\n==6888== Invalid write of size 1\n==6888==    at 0x48FF7A5: _IO_default_xsputn (genops.c:394)\n==6888==    by 0x48FF7A5: _IO_default_xsputn (genops.c:370)\n==6888==    by 0x48D8932: outstring_func (vfprintf-internal.c:239)\n==6888==    by 0x48D8932: __vfprintf_internal (vfprintf-internal.c:767)\n==6888==    by 0x48FAA9D: __vsnprintf_internal (vsnprintf.c:114)\n==6888==    by 0x48D4FA5: snprintf (snprintf.c:31)\n==6888==    by 0x109192: main (buffer_overflow.c:6)\n==6888==  Address 0x4a6904a is 0 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== Invalid write of size 1\n==6888==    at 0x48FAAAA: __vsnprintf_internal (vsnprintf.c:117)\n==6888==    by 0x48D4FA5: snprintf (snprintf.c:31)\n==6888==    by 0x109192: main (buffer_overflow.c:6)\n==6888==  Address 0x4a6904d is 3 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== Invalid read of size 1\n==6888==    at 0x4847D14: strlen (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x48F3AB7: puts (ioputs.c:35)\n==6888==    by 0x10919E: main (buffer_overflow.c:7)\n==6888==  Address 0x4a6904a is 0 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== Invalid read of size 1\n==6888==    at 0x48FF713: _IO_default_xsputn (genops.c:399)\n==6888==    by 0x48FF713: _IO_default_xsputn (genops.c:370)\n==6888==    by 0x48FDB34: _IO_new_file_xsputn (fileops.c:1264)\n==6888==    by 0x48FDB34: _IO_file_xsputn@@GLIBC_2.2.5 (fileops.c:1196)\n==6888==    by 0x48F3B6B: puts (ioputs.c:40)\n==6888==    by 0x10919E: main (buffer_overflow.c:7)\n==6888==  Address 0x4a6904a is 0 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\nHello, world!\n==6888==\n==6888== HEAP SUMMARY:\n==6888==     in use at exit: 10 bytes in 1 blocks\n==6888==   total heap usage: 2 allocs, 1 frees, 1,034 bytes allocated\n==6888==\n==6888== 10 bytes in 1 blocks are definitely lost in loss record 1 of 1\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== LEAK SUMMARY:\n==6888==    definitely lost: 10 bytes in 1 blocks\n==6888==    indirectly lost: 0 bytes in 0 blocks\n==6888==      possibly lost: 0 bytes in 0 blocks\n==6888==    still reachable: 0 bytes in 0 blocks\n==6888==         suppressed: 0 bytes in 0 blocks\n==6888==\n==6888== For lists of detected and suppressed errors, rerun with: -s\n==6888== ERROR SUMMARY: 12 errors from 5 contexts (suppressed: 0 from 0)\n```\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/XDP-Tutorial":{"title":"XDP-Tutorial","content":"\n## Introduction\n\nXDP is an upstream Linux kernel component that allows users to install packet processing programs into the kernel. The programs are written in restricted C and compiled into eBPF byte code. Read the [the academic paper (pdf)](https://github.com/xdp-project/xdp-paper/blob/master/xdp-the-express-data-path.pdf) or the [Cilium BPF reference guide](https://cilium.readthedocs.io/en/latest/bpf/) for a general introduction to XDP.\n\nThis tutorial aims to provide a hands-on introduction to the various steps required to create useful programs with the XDP system. We assume you know the basics of Linux networking and how to configure it with the iproute2 suite of tools, but you have no prior experience with eBPF or XDP. All of the lessons are written in C, and they cover basic pointer arithmetic and aliasing. This tutorial is intended to be a hands-on introduction to the various steps required to successfully write useful programs using the XDP system.\n\nPlease keep in mind that this tutorial was written by a university first-year computer science student who has only recently begun learning XDP.\n\n## Dependencies\n\nFor basic dependencies refer to \u003chttps://github.com/xdp-project/xdp-tutorial/blob/master/setup_dependencies.org\u003e.\n\nYou will also need xdp-tools. If your distribution repositories lack xdp-tools, you can follow the build instructions from here \u003chttps://github.com/xdp-project/xdp-tools\u003e .\n\n## Examples\n\n### Example 1 - Writing a program to pass all packets\n\n```c\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n    return XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n#### Compiling and loading the example code\n\nThe LLVM+clang compiler turns this restricted-C code into BPF-byte-code and stores it in an ELF object file, named `xdp_pass.o`\n\n**Building:**\n\n`clang -O2 -g -Wall -target bpf -c xdp_pass.c -o xdp_pass.o`\n\n**Loading:**\n\n`sudo xdp-loader load -m skb -s prog interface_name xdp_pass.o`\n\nChange the interface_name to the name of your interface (for example, `eth0`, `wlan0`).\n\n**Unloading:**\n\n`sudo xdp-loader unload -a interface_name`\nAs previously described, change the interface name.\n\n### Example 2 - Blocking ICMP packets\n\n```C\n#include \u003cstdint.h\u003e\n#include \u003carpa/inet.h\u003e\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n#include \u003clinux/icmp.h\u003e\n#include \u003clinux/if_ether.h\u003e\n#include \u003clinux/ip.h\u003e\n#include \u003clinux/ipv6.h\u003e\n#include \u003clinux/tcp.h\u003e\n\n#define OVER(x, d) (x + 1 \u003e (typeof(x))d)\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n    /* data and data_end are pointers to the beginning and end of the packet’s raw\n    memory. Note that ctx-\u003edata and ctx-\u003edata_end are of type __u32, so we have\n    to perform the casts */\n    void *data_end = (void *)(uintptr_t)ctx-\u003edata_end;\n    void *data = (void *)(uintptr_t)ctx-\u003edata;\n    \n    struct ethhdr *eth = data;\n    struct iphdr *iph = (struct iphdr *)(eth + 1);\n    struct icmphdr *icmph = (struct icmphdr *)(iph + 1);\n\n    /* sanity check needed by the eBPF verifier\n    When accessing the data in struct ethhdr, we must make sure we don't\n    access invalid areas by checking whether data + sizeof(struct ethhdr) \u003e\n    data_end, and returning without further action if it's true. This check\n    is compulsory by the BPF verifer that verifies your program at runtime. */\n    if (OVER(eth, data_end))\n        return XDP_DROP;\n\n    if (eth-\u003eh_proto != ntohs(ETH_P_IP))\n        return XDP_PASS;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(iph, data_end))\n        return XDP_DROP;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(icmph, data_end))\n        return XDP_DROP;\n\n    /* \n\tstruct iphdr {\n\t#if defined(__LITTLE_ENDIAN_BITFIELD)\n\t\t__u8\tihl:4,\n\t\t\tversion:4;\n\t#elif defined (__BIG_ENDIAN_BITFIELD)\n\t\t__u8\tversion:4,\n  \t\t\tihl:4;\n\t#else\n\t#error\t\"Please fix \u003casm/byteorder.h\u003e\"\n\t#endif\n\t\t__u8\ttos;\n\t\t__be16\ttot_len;\n\t\t__be16\tid;\n\t\t__be16\tfrag_off;\n\t\t__u8\tttl;\n\t\t__u8\tprotocol;\n\t\t__sum16\tcheck;\n\t\t__be32\tsaddr;\n\t\t__be32\tdaddr;     \n\t}; \n\tThis is the ipheader structure from ip.h; we can see the elements we can access \n    and their types. We can use iph-\u003eprotocol to determine whether an incoming \n    packet is an ICMP packet or not. */\n    if (iph-\u003eprotocol != IPPROTO_ICMP)\n        return XDP_PASS;\n\n    /* drop icmp */\n    if (iph-\u003eprotocol == IPPROTO_ICMP)\n        return XDP_DROP;\n    \n    return XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n### Example 3 - Recording how many ICMP packets arrived\n\nIn this example, we count the number of ICMP packets received from each individual source address and block incoming packets after the first five. So each source address can only send 5 ICMP packets.\n\n![[notes/assets/img/O_BPF_internals.png]]\n\nAs shown in the image we can use **eBPF maps** (Map Storage) for storing the amount of packets received. Maps are a general-purpose data structure used to store various types of data. They allow data sharing between eBPF kernel programs as well as between kernel and user-space applications.\n\nEach map type has the following attributes:\n\n```ini\n   *  type\n\n   *  maximum number of elements\n\n   *  key size in bytes\n\n   *  value size in bytes\n```\n\nExample code:\n\n```C\n#include \u003cstdint.h\u003e\n#include \u003carpa/inet.h\u003e\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n#include \u003clinux/icmp.h\u003e\n#include \u003clinux/if_ether.h\u003e\n#include \u003clinux/ip.h\u003e\n#include \u003clinux/ipv6.h\u003e\n#include \u003clinux/tcp.h\u003e\n\n#define OVER(x, d) (x + 1 \u003e (typeof(x))d)\n\n/* Creating a BPF map for counting ICMP packets as described above */\nstruct bpf_map_def SEC(\"maps\") cnt = {\n    .type = BPF_MAP_TYPE_HASH,\n    .key_size = sizeof(__be32),\n    .value_size = sizeof(long),\n    .max_entries = 65536,\n};\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n\t/* data and data_end are pointers to the beginning and end of the packet’s raw\n    memory. Note that ctx-\u003edata and ctx-\u003edata_end are of type __u32, so we have\n    to perform the casts */\n\tvoid *data_end = (void *)(uintptr_t)ctx-\u003edata_end;\n\tvoid *data = (void *)(uintptr_t)ctx-\u003edata;\n\t\n    long *value;\n    \n    /* Define headers */\n\tstruct ethhdr *eth = data;\n\tstruct iphdr *iph = (struct iphdr *)(eth + 1);\n\tstruct icmphdr *icmph = (struct icmphdr *)(iph + 1);\n\n\t/* sanity check needed by the eBPF verifier\n    When accessing the data in struct ethhdr, we must make sure we don't\n    access invalid areas by checking whether data + sizeof(struct ethhdr) \u003e\n    data_end, and returning without further action if it's true. This check\n    is compulsory by the BPF verifer that verifies your program at runtime. */\n\n\tif (OVER(eth, data_end))\n\t\treturn XDP_DROP;\n\n\tif (eth-\u003eh_proto != ntohs(ETH_P_IP))\n\t\treturn XDP_PASS;\n\n\t/* sanity check needed by the eBPF verifier */\n\tif (OVER(iph, data_end))\n\t\treturn XDP_DROP;\n\n\t/* sanity check needed by the eBPF verifier */\n\tif (OVER(icmph, data_end))\n\t\treturn XDP_DROP;\n\n\t/* \n\tstruct iphdr {\n\t#if defined(__LITTLE_ENDIAN_BITFIELD)\n\t\t__u8\tihl:4,\n\t\t\tversion:4;\n\t#elif defined (__BIG_ENDIAN_BITFIELD)\n\t\t__u8\tversion:4,\n  \t\t\tihl:4;\n\t#else\n\t#error\t\"Please fix \u003casm/byteorder.h\u003e\"\n\t#endif\n\t\t__u8\ttos;\n\t\t__be16\ttot_len;\n\t\t__be16\tid;\n\t\t__be16\tfrag_off;\n\t\t__u8\tttl;\n\t\t__u8\tprotocol;\n\t\t__sum16\tcheck;\n\t\t__be32\tsaddr;\n\t\t__be32\tdaddr;     \n\t}; \n\tThis is the ipheader structure from ip.h; we can see the elements we can access \n    and their types. We can use iph-\u003eprotocol to determine whether an incoming \n    packet is an ICMP packet or not. */\n\n\tif (iph-\u003eprotocol != IPPROTO_ICMP)\n\t\treturn XDP_PASS;\n\n\t/* Check protocol of the packet */\n    if (iph-\u003eprotocol == IPPROTO_ICMP) {\n        /* Get source address */\n        __be32 source = iph-\u003esaddr;\n        /* Get value pointer address*/\n        value = bpf_map_lookup_elem(\u0026cnt, \u0026source);\n\n        if (value) {\n            *value += 1;\n        } else {\n            long temp = 1;\n            bpf_map_update_elem(\u0026cnt, \u0026source, \u0026temp, BPF_ANY);\n        }\n\n        if (value \u0026\u0026 *value \u003e 5)\n            return XDP_DROP;\n\n        return XDP_PASS;\n    }\n    \n\treturn XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n### Example 4 - Packet modification\n\nIn this example, we will set TTL to a pseudorandom number between 1-255.\n\n```C\n#include \u003cstdint.h\u003e\n#include \u003carpa/inet.h\u003e\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n#include \u003clinux/icmp.h\u003e\n#include \u003clinux/if_ether.h\u003e\n#include \u003clinux/ip.h\u003e\n#include \u003clinux/ipv6.h\u003e\n#include \u003clinux/tcp.h\u003e\n\n#define OVER(x, d) (x + 1 \u003e (typeof(x))d)\n\nstatic inline void csum_replace2(uint16_t *sum, uint16_t old, uint16_t new)\n{\n\tuint16_t csum = ~*sum;\n\n\tcsum += ~old;\n\tcsum += csum \u003c (uint16_t)~old;\n\n\tcsum += new;\n\tcsum += csum \u003c (uint16_t)new;\n\n\t*sum = ~csum;\n}\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n    /* data and data_end are pointers to the beginning and end of the packet’s raw\n    memory. Note that ctx-\u003edata and ctx-\u003edata_end are of type __u32, so we have\n    to perform the casts */\n    void *data_end = (void *)(uintptr_t)ctx-\u003edata_end;\n    void *data = (void *)(uintptr_t)ctx-\u003edata;\n    uint8_t old_ttl;\n\n    struct ethhdr *eth = data;\n    struct iphdr *iph = (struct iphdr *)(eth + 1);\n    struct icmphdr *icmph = (struct icmphdr *)(iph + 1);\n\n    /* sanity check needed by the eBPF verifier\n    When accessing the data in struct ethhdr, we must make sure we don't\n    access invalid areas by checking whether data + sizeof(struct ethhdr) \u003e\n    data_end, and returning without further action if it's true. This check\n    is compulsory by the BPF verifer that verifies your program at runtime. */\n    if (OVER(eth, data_end))\n        return XDP_DROP;\n\n    if (eth-\u003eh_proto != ntohs(ETH_P_IP))\n        return XDP_PASS;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(iph, data_end))\n        return XDP_DROP;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(icmph, data_end))\n        return XDP_DROP;\n\n    /* set the TTL to a pseudorandom number 1..255 */\n    old_ttl = iph-\u003ettl;\n    iph-\u003ettl = bpf_get_prandom_u32() \u0026 0xff ?: 1;\n\n    /* recalculate the checksum, otherwise the IP stack will drop it */\n    csum_replace2(\u0026iph-\u003echeck, htons(old_ttl \u003c\u003c 8), htons(iph-\u003ettl \u003c\u003c 8));\n\n    return XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n## Sources\n\nMany sources have influenced this tutorial, including:\n\n- \u003chttps://github.com/xdp-project/xdp-tutorial/\u003e\n- \u003chttps://developers.redhat.com/blog/2021/04/01/get-started-with-xdp\u003e\n- \u003chttps://www.tigera.io/learn/guides/ebpf/ebpf-xdp/\u003e\n- \u003chttps://www.seekret.io/blog/a-gentle-introduction-to-xdp/\u003e\n- \u003chttps://man7.org/linux/man-pages/man2/bpf.2.html\u003e\n- \u003chttps://gist.github.com/teknoraver/b66115e3518bb1b7f3e79f52aa2c3424\u003e\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/ZeroTier":{"title":"ZeroTier","content":"\n[ZeroTier](https://www.zerotier.com/) is a secure virtual network backbone that allows multiple machines to communicate as if they were all connected to the same network. It is a peer-to-peer encrypted technology, which means that unlike traditional VPN solutions, messages are sent directly from host to host rather than via a central server or router.\n\nAll of the code is open source, and you can host the controller yourself or use the ZeroTierOne service, which has both free and paid plans. I'm currently on their free plan, which is solid, reliable, and consistent.\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null},"/notes/Zram":{"title":"Zram","content":"\n### Compression ratio difference\n\n| Algorithm | Cp time | Data | Compressed |  Total | Ratio |\n| :-------: | :-----: | :--: | :--------: | :----: | :---: |\n|    lzo    |  4.571s | 1.1G |   387.8M   | 409.8M | 2.689 |\n|  lzo-rle  |  4.471s | 1.1G |    388M    |  410M  | 2.682 |\n|    lz4    |  4.467s | 1.1G |   403.4M   | 426.4M | 2.582 |\n|   lz4hc   | 14.584s | 1.1G |   362.8M   | 383.2M | 2.872 |\n|    842    | 22.574s | 1.1G |   538.6M   | 570.5M | 1.929 |\n|    zstd   |  7.897s | 1.1G |   285.3M   | 298.8M | 3.961 |\n\n### Page-cluster values, latency difference\n\npage-cluster controls the number of pages up to which consecutive pages are read in from swap in a single attempt. This is the swap counterpart to page cache readahead. The mentioned consecutivity is not in terms of virtual/physical addresses, but consecutive on swap space - that means they were swapped out together.\n\nIt is a logarithmic value - setting it to zero means “1 page”, setting it to 1 means “2 pages”, setting it to 2 means “4 pages”, etc. Zero disables swap readahead completely.\n\nThe default value is three (eight pages at a time). There may be some small benefits in tuning this to a different value if your workload is swap-intensive.\n\nLower values mean lower latencies for initial faults, but at the same time extra faults and I/O delays for following faults if they would have been part of that consecutive pages readahead would have brought in.\n\n![[notes/assets/img/O_benchmarks_zram_throughput.png]]\n\n![[notes/assets/img/O_benchmarks_zram_latency.png]]\n\n## Main takeaways\n\nAs you can see zstd has highest compression ratio but is also slower (but still at acceptable speeds). However, compression ratio advantage is more important here because high compression ratio lets more of the working set fit in uncompressed memory, reducing the need for swap and improving performance.\n\n**If you're running desktop systems, I recommend running zstd with page-cluster set to 0, because the majority of the swapped data is most likely stale (old browser tabs). However, if you are running something that requires constant swapping, lz4 may be a better choice due to its higher throughput and lower latency.**\n\nWith zstd, the decompression is so slow that that there's essentially zero throughput gain from readahead. Use vm.page-cluster=0 as higher values has a huge latency cost. (This is default on [ChromeOS](https://bugs.chromium.org/p/chromium/issues/detail?id=263561#c16=) and seems to be standard practice on [Android](https://cs.android.com/search?q=page-cluster\u0026start=21).)\n\nThe default is `vm.page-cluster=3`, which is better suited for physical swap. Git blame says it was there in 2005 when the kernel switched to git, so it might even come from a time before SSDs.\n\n# Sources\n\n\u003chttps://linuxreviews.org/Zram\u003e\n\n\u003chttps://docs.kernel.org/admin-guide/sysctl/vm.html\u003e\n\n\u003chttps://www.reddit.com/r/Fedora/comments/mzun99/new_zram_tuning_benchmarks/\u003e\n","lastmodified":"2023-01-19T21:24:47.895094174Z","tags":null}}