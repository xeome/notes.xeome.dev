{"/":{"title":"xeome.github.io","content":"\n### About me\n\nI have a strong interest in Linux and other Unix-like operating systems, with a particular focus on optimization, efficiency, and low-level system programming. I enjoy reading kernel documentation and learning about low-level optimizations and the clever tricks that have been used to make the most of limited hardware. I am currently working on creating my own Linux distribution and writing documentation on various topics related to the Linux internals and other low-level systems programming topics, such as network programming(XDP) and the use of languages like C and x86 assembly. Overall, I have a passion for exploring and learning about the inner workings of low-level systems and finding ways to optimize and improve their performance.\n\nGithub: \u003chttps://github.com/xeome\u003e\n\n### Highlights\n\n#### CachyOS\n\nArch Linux based distribution with heavy optimizations and multi architecture support for ultimate desktop experience.\n\nLink: \u003chttps://github.com/CachyOS\u003e\n\n#### JomOS\n\nJomOS is a meta Linux distribution which allows users to mix-and-match well tested configurations and optimizations with little to no effort. JomOS integrates these configurations into one largely cohesive system.\n\nLink: \u003chttps://github.com/xeome/jomOS\u003e\n\nDocument: [[notes/JomOS]]\n\n#### xeome.github.io\n\nThis site contains all the documents i write about Linux and other topics.\n\nTo access all my notes, click here \u003chttps://xeome.github.io/notes/\u003e.\n","lastmodified":"2023-03-16T10:37:39.772180942Z","tags":null},"/notes/Btrfs-Maintenance":{"title":"Btrfs Maintenance","content":"\n## Btrfs Scrub\n\nThe Btrfs scrub operation reads all data and metadata from devices and verifies their checksums. This can help to detect problems with faulty hardware early, as it touches data that may not be in use and may be vulnerable to bit rot. If there is data/metadata redundancy in the file system, such as DUP or RAID1/5/6 profiles, scrub can automatically repair the data if a good copy is available.\n\nTo start a scrub operation, use the following command:\n\n```bash\nsudo btrfs scrub start /\n```\n\nTo check the status of a scrub operation, use the following command:\n\n```bash\nsudo btrfs scrub status /\n```\n\n## Btrfs balance\n\nThe balance command can do a lot of things, but it primarily moves data in large chunks. It is used here to reclaim the space of the underutilized chunks so that it can be allocated again based on current needs.\n\nThe goal is to avoid situations in which it is impossible to allocate new metadata chunks, for example, because the entire device space is reserved for all the chunks, even though the total space occupied is smaller and the allocation should succeed.\n\nThe balance operation requires enough space to shuffle data around. By workspace, we mean device space with no filesystem chunks on it, not free space as reported by df, for example.\n\nThe balance command may fail due to a lack of space, but this is considered a minor error because the internal filesystem layout may prevent the command from finding enough workspace. This could be a good time to inspect the space manually.\n\nRunning `btrfs balance start` without any filters, would re-write every Data and Metadata chunk on the disk. Usually, this is not what we want. Instead use the `usage` filter to limit what blocks should be balanced.\n\nUsing `-dusage=5` we can limit balance to compact data blocks that are less than 5% full. This is a good start, and we can increase it to 10-15% or more if needed. A small (less than 100GiB) filesystem may need a higher number.\n\nSimilarly using `-musage=5` we can limit balance to compact metadata chunks.\n\n### Examples\n\nTo start balance on data chunks:\n\n`sudo btrfs balance start --bg -dusage=5 /path`\n\nTo start balance on metadata chunks:\n\n`sudo btrfs balance start --bg -musage=5 /path`\n\nto check status of balance operation:\n\n`sudo btrfs balance status /path`\n\n**Expected outcome:** If all underutilized chunks are removed, the total value in the output of `btrfs fi df /path` should be lower than before. Examine the logs.\n\n## Manual deduplication using duperemove\n\n\u003e Duperemove is a simple tool for finding duplicated extents and submitting them for deduplication. When given a list of files it will hash their contents on a block by block basis and compare those hashes to each other, finding and categorizing blocks that match each other. When given the -d option, duperemove will submit those extents for deduplication using the Linux kernel extent-same ioctl.\n\u003e Duperemove can store the hashes it computes in a 'hashfile'. If given an existing hashfile, duperemove will only compute hashes for those files which have changed since the last run. Thus you can run duperemove repeatedly on your data as it changes, without having to re-checksum unchanged data.\n\nAs the above explanation from project's github readme states, you can use this tool for checking and reporting duplicate extents to kernel.\n\nI saved an estimate of around 17G on 180GiB of mixed data, photos, videos, games, documents etc.\n![[notes/assets/img/O_Pasted image 20230119010141.png]]\nHere is how I use this tool:\n\n```bash\nsudo duperemove --hashfile=/home/$USERNAME/.hashfile -dhr /\n```\n\nParameter explanations:\n\n- `--hashfile=location` can be used to specify location of hashfile to be reused later.\n\n\u003e Hashfiles are essentially sqlite3 database files with 3 tables, `config`, `files` and `hashes`. Hashfiles are meant to be reused - duperemove will store the results of the scan and dedupe stages to speed up subsequent runs.\n\n- `-d` De-dupe the results - only works on btrfs and xfs.\n- `-h` Print numbers in human-readable format.\n- `-r` Enable recursive dir traversal.\n\nand lastly `/` which is the location we want to dedupe.\n\nNotice: The hash file format in Duperemove master branch is under development and may change. If the changes are not backwards compatible, you will have to re-create your hash file.\n\n## Trimming\n\nAlthough trimming is not exclusive to btrfs, I felt like still needs to be mentioned.\n\nThe TRIM (aka discard) operation can instruct the underlying device to optimize blocks that are not being used by the filesystem. The fstrim utility performs this task on demand.\n\nThis makes sense for SSDs or other types of storage that can translate TRIM actions into useful data (eg. thin-provisioned storage).\n\nYou can use `sudo fstrim --fstab --verbose` to run fstrim on all mounted filesystems mentioned in /etc/fstab on devices that support the discard operation.\n\n`--fstab`:\n\nOn devices that support the discard operation, trim all mounted filesystems listed in /etc/fstab. If the root filesystem is missing from the file, it is determined from the kernel command line. Other provided options, such as `--offset`, `--length`, and `--minimum`, are applied to all of these devices. Errors originating from filesystems that do not support the discard operation, as well as read-only devices, autofs, and read-only filesystems, are silently ignored. Filesystems with the mount option `X-fstrim.notrim` are skipped.\n\n`--verbose`:\n\nVerbose execution. With this option fstrim will output the number of bytes passed from the filesystem down the block stack to the device for potential discard. This number is a maximum discard amount from the storage device’s perspective, because FITRIM ioctl called repeated will keep sending the same sectors for discard repeatedly.\n\nYou can read more about trim here [[notes/Trim]].\n\n## Sources\n\n\u003chttps://github.com/kdave/btrfsmaintenance\u003e\n\n\u003chttps://github.com/markfasheh/duperemove#duperemove\u003e\n\n\u003chttps://github.com/markfasheh/duperemove/wiki/Duperemove-Design#hashfiles\u003e\n\n\u003chttps://man.archlinux.org/man/fstrim.8.en\u003e\n","lastmodified":"2023-03-16T10:37:39.772180942Z","tags":null},"/notes/C++-multithreading":{"title":"C++ multithreading","content":"\n# Overview\n\nMultithreading is a programming technique that allows a single process to execute multiple threads concurrently. This allows a program to perform multiple tasks simultaneously, improving the performance and responsiveness of the program. In C++, the `std::thread` class, part of the C++11 standard library, is used to implement multithreading.\n\nTo use concurrency in C++, you will need to use the `\u003cthread\u003e` header, which provides the `std::thread` class and other related types and functions for creating and managing threads. Here's a simple example of how to create and start a new thread:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo() { std::cout \u003c\u003c \"Hello from a new thread!\" \u003c\u003c std::endl; }  \n  \nint main() {  \n    std::thread t(foo);  \n    t.join();  \n    return 0;  \n}\n```\n\nThis program creates a new `std::thread` object, passing the function `foo` as the argument to the thread's constructor. The `join` member function blocks the calling thread (in this case, the main thread) until the new thread has completed execution.\n\nYou can also use the `std::async` function to run a function asynchronously and get a `std::future` object that can be used to retrieve the result of the function when it becomes available. For example:\n\n```cpp\n#include \u003cfuture\u003e  \n#include \u003ciostream\u003e  \n  \nint foo() { return 10; }  \n  \nint main() {  \n    std::future\u003cint\u003e f = std::async(foo);  \n    int x = f.get();  \n    std::cout \u003c\u003c \"x = \" \u003c\u003c x \u003c\u003c std::endl;  \n    return 0;  \n}\n```\n\nThis program creates a new asynchronous task that executes the `foo` function and returns a `std::future` object that can be used to retrieve the result of the function when it becomes available. The `get` member function of the `std::future` object blocks the calling thread until the result is available, and then returns the result.\n\n# Basic examples\n\n##### Example 1: Passing arguments to a thread function\n\nIn this example, we pass two arguments to the thread function:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo(int x, std::string str) {  \n    std::cout \u003c\u003c \"x = \" \u003c\u003c x \u003c\u003c \", str = \" \u003c\u003c str \u003c\u003c std::endl;  \n}  \n  \nint main() {  \n    std::thread t(foo, 10, \"Hello\");  \n    t.join();  \n    return 0;  \n}\n\n```\n\nWhen the `foo` function is executed by the new thread, it will receive the arguments `10` and `\"Hello\"`.\n\n##### Example 2: Using std::move to transfer ownership of a thread\n\nIn this example, we use `std::move` to transfer ownership of a thread object to a new thread:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo() { std::cout \u003c\u003c \"Hello from a new thread!\" \u003c\u003c std::endl; }  \n  \nint main() {  \n    std::thread t1(foo);  \n    std::thread t2 = std::move(t1);  \n    t2.join();  \n    return 0;  \n}\n```\n\nThe `t1` thread object is created and starts executing the `foo` function. The `t2` thread object is then created by moving the `t1` object using `std::move`. This transfers ownership of the thread to the `t2` object, and the `t1` object is left in a moved-from state and is no longer associated with any thread. The `t2` object can then be used to manage the thread.\n\n##### Example 3: Detaching a thread\n\nIn this example, we create a thread and detach it from the main thread of execution:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo() { std::cout \u003c\u003c \"Hello from a new thread!\" \u003c\u003c std::endl; }  \n  \nint main() {  \n    std::thread t(foo);  \n    t.detach();  \n    return 0;  \n}\n\n```\n\nThe `detach` member function of the `std::thread` object detaches the thread from the main thread of execution, allowing it to run independently. The main thread can then continue execution without waiting for the detached thread to complete.\n\n##### Example 4: Passing arguments by reference to std::thread\n\nIn this example, we pass an argument by reference to thread function:\n\n```cpp\n#include \u003ciostream\u003e  \n#include \u003cthread\u003e  \n  \nvoid foo(int x, std::string \u0026str) {  \n    std::cout \u003c\u003c \"x = \" \u003c\u003c x \u003c\u003c \", str = \" \u003c\u003c str \u003c\u003c std::endl;  \n}  \n  \nint main() {  \n    std::string str = \"Hello\";  \n    std::thread t(foo, 10, std::ref(str));  \n    t.join();  \n    return 0;  \n}\n```\n\n# More algorithmic examples\n\nThere are many other algorithms that can be implemented as multithreaded versions to take advantage of concurrency, including the following:\n\n- Sorting algorithms: Many sorting algorithms, such as merge sort and quick sort, can be implemented as multithreaded versions to improve performance on multi-core systems.\n\n- Matrix multiplication: Matrix multiplication can be implemented as a multithreaded algorithm to take advantage of parallelism, particularly for large matrices.\n\n- Graph algorithms: Many graph algorithms, such as breadth-first search and depth-first search, can be implemented as multithreaded versions to improve performance on multi-core systems.\n\n- Search algorithms: Some search algorithms, such as binary search and linear search, can be implemented as multithreaded versions to improve performance on multi-core systems.\n\n### Example 1: Merge sort\n\n```cpp\n#include \u003ciostream\u003e\n#include \u003cthread\u003e\n\nvoid merge(int arr[], int l, int m, int r) {\n\n    // Find sizes of two sub arrays to be merged\n    int i, j, k;\n    int n1 = m - l + 1;\n    int n2 = r - m;\n\n    // create temp arrays\n    int L[n1], R[n2];\n\n    // Copy data to temp arrays L[] and R[]\n    std::copy(arr + l, arr + l + n1, L);\n    std::copy(arr + m + 1, arr + m + 1 + n2, R);\n\n    // Merge the temp arrays back into arr[l..r]\n    i = 0; // Initial index of first subarray\n    j = 0; // Initial index of second subarray\n    k = l; // Initial index of merged subarray\n    while (i \u003c n1 \u0026\u0026 j \u003c n2) {\n        // if left subarray is smaller than right subarray then put left\n        // subarray element into arr and increment i and k by 1 otherwise put\n        // right subarray element into arr and increment j and k by 1\n        if (L[i] \u003c= R[j]) {\n            arr[k] = L[i];\n            i++;\n        } else {\n            arr[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n\n    // Copy the remaining elements of L[], if there are any \n    std::copy(L + i, L + n1, arr + k);\n\n    // Copy the remaining elements of R[], if there are any \n    std::copy(R + j, R + n2, arr + k);\n}\n\n// Parallel version of the merge sort algorithm\nvoid mergeSort(int *arr, int l, int r) {\n    if (l \u003c r) {\n        // Same as (l+r)/2, but avoids overflow for large l and h\n        int m = l + (r - l) / 2;\n        // Sort first and second halves\n        std::thread t1(mergeSort, arr, l, m);\n        std::thread t2(mergeSort, arr, m + 1, r);\n        t1.join();\n        t2.join();\n        // Merge the sorted halves\n        merge(arr, l, m, r);\n    }\n}\n\nint main() {\n    // Test the merge sort algorithm\n    int arr[] = {12, 11, 13, 5, 6, 7};\n    int arr_size = std::size(arr);\n\n    std::cout \u003c\u003c \"Given array is \\n\";\n    for (int i = 0; i \u003c arr_size; i++)\n        std::cout \u003c\u003c arr[i] \u003c\u003c \" \";\n\n    mergeSort(arr, 0, arr_size - 1);\n\n    std::cout \u003c\u003c \"\\nSorted array is \\n\";\n    for (int i = 0; i \u003c arr_size; i++)\n        std::cout \u003c\u003c arr[i] \u003c\u003c \" \";\n    return 0;\n}\n```\n","lastmodified":"2023-03-16T10:37:39.772180942Z","tags":null},"/notes/Cockpit-caddy-reverse-proxy":{"title":"Setting up Cockpit with caddy reverse proxy","content":"\nCockpit is a web-based server management tool that provides a user-friendly interface for administrators to manage their servers. In this article, we will walk through the process of setting up Cockpit with Caddy reverse proxy.\n\n# Prerequisites\n\nBefore we begin, make sure that you have the following:\n\n- Cockpit installed on the server\n- Caddy installed on the server (\u003chttps://caddyserver.com/docs/install\u003e)\n- A domain name pointing to your server's IP address\n\n# Step 1: Setup SSL Certificates\n\nYou can follow the steps for obtaining certificates in [[notes/Cockpit nginx reverse proxy]]\nPut the certificates to a different location, i.e. `/etc/caddy/certs`\nMake sure the folder is owned by caddy user if you get permission errors.\n\n# Step 2: Setting Up Caddy\n\nCreate a new Caddyfile in your server's configuration directory (usually `/etc/caddy/`). This file will define the reverse proxy rules for Caddy.\n\nIn the Caddyfile, add the following lines to define a reverse proxy rule for your Cockpit panel:\n\n```nginx\npanel.example.com {\n        reverse_proxy localhost:9090\n        tls /etc/caddy/certs/fullchain.pem /etc/caddy/certs/privkey.pem\n}\n```\n\nSave the Caddyfile and restart Caddy to apply the changes. You can use the following command to restart Caddy:\n\n```bash\nsudo systemctl restart caddy\n```\n\n# Step 3: Make Cockpit proxy aware\n\n\u003chttps://github.com/cockpit-project/cockpit/wiki/Proxying-Cockpit-over-nginx#make-cockpit-proxy-aware\u003e\n\n# See Also\n\n- \u003chttps://github.com/caddyserver/caddy\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Cockpit-nginx-reverse-proxy":{"title":"Setting up Cockpit with nginx reverse proxy","content":"\nCockpit is a web-based server management tool that provides a user-friendly interface for administrators to manage their servers. In this article, we will walk through the process of setting up Cockpit with Nginx reverse proxy.\n\n# Prerequisites\n\nBefore we begin, make sure that you have the following:\n\n- Cockpit installed on the server\n- Nginx installed on the server\n- A domain name pointing to your server's IP address\n\n# Step 1: Setup SSL Certificates\n\nFirst, we need to obtain SSL certificates for our domain name. We will use Certbot to obtain SSL certificates. Run the following command to obtain SSL certificates for your domain name.\n\n```bash\nsudo certbot certonly --manual --preferred-challenges=dns -d \"*.example.com\" -d \"example.com\"\n```\n\nMake sure to replace `example.com` with your domain name.\n\nNext, we need to create a directory to store our SSL certificates. Run the following command to create a directory named `ssl` in the `/etc/nginx/` directory.\n\n```bash\nsudo mkdir /etc/nginx/ssl\n```\n\nCopy the SSL certificates to the newly created `ssl` directory using the following commands.\n\n```bash\nsudo cp /etc/letsencrypt/live/example.com-0001/fullchain.pem /etc/nginx/ssl\nsudo cp /etc/letsencrypt/live/example.com-0001/privkey.pem /etc/nginx/ssl\n```\n\nMake sure to replace `example.com` with your domain name.\n\n# Step 2: Setting Up Nginx\n\nNow, we need to create an Nginx configuration file for Cockpit. Run the following command to create a new file named `cockpit.conf` in the `/etc/nginx/sites-available/` directory.\n\n```bash\nsudo nvim /etc/nginx/sites-available/cockpit.conf\n```\n\nEnter the following configuration into the `cockpit.conf` file.\n\n```hs\nserver {\n    listen 80;\n    listen [::]:80;\n\n    server_name panel.example.com;\n\n    return 301 https://$host$request_uri;\n}\n\nserver {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n\n    server_name panel.example.com;\n\n    ssl_certificate /etc/nginx/ssl/fullchain.pem;\n    ssl_certificate_key /etc/nginx/ssl/privkey.pem;\n\n\n    location / {\n        # Required to proxy the connection to Cockpit\n        proxy_pass https://127.0.0.1:9090;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # Required for web sockets to function\n        proxy_http_version 1.1;\n        proxy_buffering off;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n}\n\n```\n\nWe need to modify the Nginx configuration file to enable the Cockpit configuration we just created. Run the following command to edit the `nginx.conf` file.\n\n```bash\nsudo nvim /etc/nginx/nginx.conf\n```\n\nAdd the following line to the `http` block.\n\n```json\ninclude /etc/nginx/sites-enabled/*;\n```\n\nCreate a symbolic link to the Cockpit configuration file we just created using the following command.\n\n```bash\nsudo ln -s /etc/nginx/sites-available/cockpit.conf /etc/nginx/sites-enabled/cockpit\n```\n\nRestart the Nginx service to apply the changes we made using the following command.\n\n```bash\nsudo systemctl restart nginx\n```\n\n# Step 3: Make Cockpit proxy aware\n\n\u003chttps://github.com/cockpit-project/cockpit/wiki/Proxying-Cockpit-over-nginx#make-cockpit-proxy-aware\u003e\n\n# See Also\n\n- \u003chttps://github.com/cockpit-project/cockpit/wiki/Proxying-Cockpit-over-nginx\u003e\n- \u003chttps://ryan.lovelett.me/posts/letsencrypt-cockpit/\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Computer-Science":{"title":"Computer Science","content":"\n# Index\n\n- [[notes/Linux]]\n- [[notes/Networking]]\n- [[notes/Misc]]\n- [[notes/Resources]]\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Data-Structures":{"title":"Data Structures","content":"\n# Overview\n\nThere are numerous data structures used in computer science and software engineering, each with their own set of characteristics and trade-offs. Here's a quick rundown of some of the most common data structures, as well as their use cases and time complexities for common operations:\n\n1. Arrays: Arrays are simple data structures that store a fixed-size sequence of elements. They perform well when accessing individual elements but poorly when inserting or deleting elements. Time complexity for common operations:\n\n- Access: O(1)\n- Insertion/Deletion: O(n)\n\n2. Vectors: Vectors are similar to arrays, but they are mutable and have automatic resizing. Time complexity for common operations:\n\n- Access: O(1)\n- Insertion/Deletion: O(n)\n\n3. Linked Lists: Linked lists are data structures that store a list of elements, each of which contains a reference to the next element in the list. They perform well when inserting and deleting elements but poorly when accessing individual elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(1)\n\n4. Stacks: Stacks are data structures that store a sequence of elements and allow only the most recently added element to be accessed (last in, first out). They perform well when adding and removing elements from the top of the stack, but poorly when accessing other elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(1)\n\n5. Queues: Queues are data structures that store a sequence of elements and allow only the oldest element to be accessed (first in, first out). They perform well when adding and removing elements from the front and back of the queue, but poorly when accessing other elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(1)\n\n6. Trees: Trees are hierarchical data structures made up of nodes connected by a parent-child relationship. They are good at searching, inserting, and deleting elements, but not so good at accessing individual elements. Time complexity for common operations:\n\n- Access: O(n)\n- Insertion/Deletion: O(log n)\n\n7. Hash Tables: Hash tables are data structures that map keys to array indices using a hash function. They are good at searching, inserting, and deleting elements, but not so good at accessing individual elements. Time complexity for common operations:\n\n- Access: O(1) average case, O(n) worst case\n- Insertion/Deletion: O(1) average case, O(n) worst case\n\n8. Heaps: Heaps are data structures that store a complete binary tree in which the parent node is always greater than or equal to its children (max heap) or less than or equal to its children (min heap). They are good at finding the maximum or minimum element, but not so good at inserting or deleting elements. Time complexity for common operations:\n\n- Access: O(1)\n- Insertion/Deletion: O(log n)\n\n# Implementations\n\n## Vector\n\nMethods available:\n\n- size() - the number of items it can hold\n- capacity() - the number of items it can hold\n- is_empty()\n- at(index) - returns the item at the given index, but fails if the index is out of bounds.\n- push(item)\n- insert(index, item) - inserts item at index, shifts that index's value and trailing elements to the right\n- prepend(item) - inserts item at index 0\n- pop() - remove from the end and return the value\n- delete(index) - Remove the item at index by shifting all trailing elements to the left.\n- remove(item) - searches for value and removes the index that holds it (even if in multiple places)\n- find(item) - searches for a value and returns the first index containing that value. If not found, return -1\n- resize(new capacity) - When you reach capacity, when popping an item, resize to double the size; if size is 1/4 of capacity, resize to half.\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/vector.c\u003e\n\n## Linked List\n\nMethods available:\n\n- size() - returns number of data elements in list\n- empty() - bool returns true if empty\n- value_at(index) - returns the value of the nth item (starting at 0 for first)\n- push_front(value) - adds an item to the front of the list\n- pop_front() - remove front item and return its value\n- push_back(value) - adds an item at the end\n- pop_back() - removes end item and returns its value\n- front() - get value of front item\n- back() - get value of end item\n- insert(index, value) - insert value at index, so current item at that index is pointed to by new item at index\n- erase(index) - removes node at given index\n- value_n_from_end(n) - returns the value of the node at nth position from the end of the list\n- reverse() - reverses the list\n- remove_value(value) - removes the first item in the list with this value\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/linked_list.c\u003e\n\n## Queue\n\nMethods available:\n\n- enqueue(value) - adds item at end of available storage\n- dequeue() - returns value and removes least recently added element\n- empty()\n- full()\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/queue.c\u003e\n\n## Hashmap\n\nMethods available:\n\n- hash_map_init\n- hash_map_destroy\n- hash_siphash\n- hash_map_insert\n- hash_map_lookup\n\nImplementation:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/hashmap.c\u003e\n\nExplanation:\n[[notes/Hashmap]]\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Emulating-Cortex-A72":{"title":"Emulating Cortex A72","content":"\n# Introduction\n\nThis document provides a step-by-step guide on how to emulate Cortex A72 using a Debian RasPi4 image. Please note that this is not intended for production. Use at your own risk.\n\n## Prerequisites\n\n- A Linux or macOS (I haven't tried this on MacOS) system\n- `wget` to download the Debian RasPi4 image\n- `xz` to decompress the image\n- `fdisk` to determine the starting sector number\n- `qemu-img` to convert the image to qcow2\n- `nano` or any other text editor of your choice to edit the fstab file\n\n# Preparation\n\n### Create a Project directory\n\nCreate a directory to store the project files:\n\n```sh\n$ mkdir rpi_image\n$ cd rpi_image\n```\n\n### Download and decompress the Debian RasPi4 image\n\nDownload the Debian RasPi4 image and decompress it:\n\n```sh\n$ wget https://raspi.debian.net/tested/20220808_raspi_4_bookworm.img.xz\n$ xz --decompress 20220808_raspi_4_bookworm.img.xz\n```\n\n### Determine the starting sector number\n\nUsing `fdisk`, determine the starting sector number of the image:\n\n```sh\n$ fdisk -l 20220808_raspi_4_bookworm.img\n```\n\nThis will give you output similar to this:\n\n```\nDisk 20220808_raspi_4_bookworm.img: 1,95 GiB, 2097152000 bytes, 4096000 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0xf7e489e2\n\nDevice         Boot  Start     End Sectors  Size Id Type\n20220808_raspi_4_bookworm.img1        8192  819199  811008  396M  c W95 FAT32\n20220808_raspi_4_bookworm.img2      819200 4095999 3276800  1,6G 83 Linux\n```\n\n### Get offset for mounting\n\nTo mount the image, we need to find the offset by finding the `Start` number in the second partition (in this case, `20220808_raspi_4_bookworm.img2`). In this example, the start number is 819200. Multiply this number by 512 to get the offset, which is 419430400.\n\n### Create a mount directory\n\nCreate a mount directory:\n\n```sh\n$ mkdir /mnt/raspi4\n```\n\n### Mount the image\n\nMount the image using the offset:\n\n```sh\n$ sudo mount -o offset=419430400 20220808_raspi_4_bookworm.img /mnt/raspi4\n```\n\n### Extract kernel and initrd\n\nNow we can extract kernel and initrd from image:\u003cbr\u003e(NOTE: We are cd'd into rpi_image directory):\n\n```sh\n$ cp /mnt/raspi4/vmlinuz .\n$ cp /mnt/raspi4/initrd.img .\n```\n\n### Edit fstab for slicker(?) QEMU operation\n\nFinally, we need to edit `fstab` for slicker(?) mounting via QEMU:\n\n```\n$ nano /mnt/raspi4/etc/fstab\n```\n\n```sh\n# The root file system has fs_passno=1 as per fstab(5) for automatic fsck.\nLABEL=RASPIROOT / ext4 rw 0 1\n# All other file systems have fs_passno=2 as per fstab(5) for automatic fsck.\nLABEL=RASPIFIRM /boot/firmware vfat rw 0 2\n```\n\n- Replace `LABEL=RASPIROOT` with `/dev/vda2`\n\n- Replace `LABEL=RASPIFIRM` with `/dev/vda1`\n\nThe file should look something like this:\n\n```sh\n# The root file system has fs_passno=1 as per fstab(5) for automatic fsck.\n/dev/vda2 / ext4 rw 0 1\n# All other file systems have fs_passno=2 as per fstab(5) for automatic fsck.\n/dev/vda1 /boot/firmware vfat rw 0 2\n```\n\nWe can now convert the image to qcow2:\n\n```sh\nqemu-img convert -f raw -O qcow2 20220808_raspi_4_bookworm.img rpi.qcow2\n```\n\n# Emulation Time!\n\nWe can finally start making our launch script.\n\n```sh\n$ nano rpistart.sh\n```\n\n**rpistart.sh**\n\n```sh\n#!/bin/bash\nscreen -mS raspberry-pi-4 \\\nsudo qemu-system-aarch64 \\\n-M virt \\\n-m 4096 -smp 4 \\\n-cpu cortex-a72 \\\n-kernel vmlinuz \\\n-initrd initrd.img \\\n-append \"root=/dev/vda2 panic=1 rootfstype=ext4 rw\" \\\n-hda rpi.qcow2 \\\n-no-reboot \\\n-nographic\n```\n\nPaste the above into the script and save.\n\n### Some info about script\n\n- Since QEMU doesn't natively support Raspberry Pi 4(b), our only option is to virtualize Cortex A72 (Which is CPU used in Raspberry Pi 4(b)).\n\n- `-nographic` because _who needs graphics._\n\n- `screen` is used 'cuz _why not_.\n\n- Make script executable\n\n```sh\n$ chmod +x rpistart.sh\n```\n\n- __And you should_ be able to run QEMU instance._*\n- LAUNCH!\n\n```sh\n$ ./rpistart.sh\n```\n\n# Some wacky reality.\n\nYou have booted into nice Debian. Oh, btw, username is passwordless `root`.\u003cbr\u003eBut there are two problems:\n\n- Not enough space!\n- No internet!\n\n## Not enough space!\n\nVery simple. Just:\n\n- poweroff the VM.\n\n```sh\nVM$ poweroff\n```\n\n- In our `rpi_image` directory, we can resize `qcow2` image via:\n\n```sh\n$ qemu-img resize rpi.qcow2 +4G\n```\n\nSide note: You can also set exact size by getting rid of that + sign.\n\n- Now we need to boot into VM once again:\n\n```sh\n$ ./rpistart.sh\n```\n\n- We have resized the image capacity, but not partition size. We can do that with:\n\n```sh\nVM$ resize2fs /dev/vda2\n```\n\n- You can check final result via\n\n```sh\nVM$ df -H\n```\n\n## No internet!\n\nNow we are going to configure our ethernet network interface.\n\n- You can check available network interfaces via:\n\n```sh\nVM$ ip addr\n```\n\n```\n1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp0s1: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 52:54:00:12:34:56 brd ff:ff:ff:ff:ff:ff\n```\n\n- Notice, that `enp0s1` has zero IP addresses. We gotta fix that! _By creating another file._\n\n```sh\nVM$ nano /etc/network/interfaces.d/enp0s1\n```\n\nand paste this in:\u003cbr\u003e\u003cbr\u003e\n**enp0s1**\n\n```sh\nauto enp0s1\n\niface enp0s1 inet dhcp\n```\n\n- And delete eth0 interface\n- Reboot (Although config won't actually let you reboot.)\n\n```sh\nVM$ poweroff\n```\n\n```sh\n$ ./rpistart.sh\n```\n\n- You may still receive a networking service error, but you should be able to access the internet.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Fedora-On-Headless-Raspberry-PI-4":{"title":"Fedora On Raspberry PI 4","content":"\nIn this guide, we will walk through the steps to set up Fedora Server on your Raspberry Pi 4. This guide assumes that you have some knowledge of using Linux, and have access to the necessary hardware and software components. Note that this guide has been created based on multiple sources and has been modified to reflect the specific requirements for a successful installation on the author's device.\n\n##### Hardware Requirements\n\n- Raspberry Pi 4 Model B\n- A microSD card with a capacity of at least 8GB\n- A power supply for Raspberry Pi 4\n- A microSD card reader\n\n##### Software Requirements\n\n- arm-image-installer\n- A terminal emulator\n- qemu-user-static\n- qemu-user-static-binfmt\n\n### Step 1: Download Fedora Server Image\n\nDownload current raw image for aarch64 from \u003chttps://getfedora.org/en/server/download/\u003e.\n\n### Step 2: Download UEFI Firmware\n\nNext, download the current UEFI firmware for Raspberry Pi 4 from the following link: \u003chttps://github.com/pftf/RPi4/releases\u003e. Unzip the file in a temporary location, such as the Downloads folder.\n\n### Step 3: Preparing The Raw Image\n\nIn this step, we will decompress the raw image and prepare it for use.\n\nDecompress the image:\n\n```bash\nxz --decompress Fedora-Server-37-1.7.aarch64.raw.xz\n```\n\nThis will delete the original xz file after decompression and you will be left with `Fedora-Server-37-1.7.aarch64.raw`. You can add `--keep` to keep the compressed version.\n\nNext, list the partitions in the raw image with fdisk:\n\n```bash\n$ fdisk -l Fedora-Server-37-1.7.aarch64.raw\nDisk Fedora-Server-37-1.7.aarch64.raw: 7 GiB, 7516192768 bytes, 14680064 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0x5c5e303a\n\nDevice                            Boot   Start      End  Sectors  Size Id Type\nFedora-Server-37-1.7.aarch64.raw1 *       2048  1230847  1228800  600M  6 FAT16\nFedora-Server-37-1.7.aarch64.raw2      1230848  3327999  2097152    1G 83 Linux\nFedora-Server-37-1.7.aarch64.raw3      3328000 14680063 11352064  5,4G 8e Linux LVM\n```\n\nThe raw image has three partitions: `.raw1` is the bootloader partition, `.raw2` is the Linux boot partition (id 83), and `.raw3` is the partition we want, a Linux LVM partition (id 8e) where Fedora is installed.\n\nTo mount the image at the right place, we need to calculate the mount offset as follows:\n\n```bash\nsector size (512) x start sector (3328000) = 1703936000\n```\n\nHowever, if we mount the image with this offset, it will fail:\n\n```bash\n$ sudo mount -o loop,offset=1703936000 Fedora-Server-37-1.7.aarch64.raw /mnt/raw3\n\nmount: /mnt/raw3: unknown filesystem type 'LVM2_member'.\n```\n\nTo solve this issue, we need to use a tool like `kpartx`. This utility creates a virtual device in `/dev/mapper` that we can manipulate as a real device. Run the following command to add a device verbosely:\n\n```bash\n$ sudo kpartx -a -v Fedora-Server-37-1.7.aarch64.raw\nadd map loop0p1 (253:0): 0 1228800 linear 7:0 2048\nadd map loop0p2 (253:1): 0 2097152 linear 7:0 1230848\nadd map loop0p3 (253:2): 0 11352064 linear 7:0 3328000\n```\n\nThen verify the new partitions in `/dev/mapper`:\n\n```bash\n$ ls -l /dev/mapper/\ntotal 0\ncrw------- 1 root root 10, 236 Şub 10 11:28 control\nlrwxrwxrwx 1 root root       7 Şub 11 00:17 fedora-root -\u003e ../dm-3\nlrwxrwxrwx 1 root root       7 Şub 11 00:17 loop0p1 -\u003e ../dm-0\nlrwxrwxrwx 1 root root       7 Şub 11 00:17 loop0p2 -\u003e ../dm-1\nlrwxrwxrwx 1 root root       7 Şub 11 00:17 loop0p3 -\u003e ../dm-2\n```\n\nFinally, create a directory and mount the LVM partition to the new directory:\n\n```bash\nsudo mkdir /mnt/raw3  \nsudo mount /dev/fedora/root /mnt/raw3\n```\n\n### Step 4:  Working Directly Within The Image\n\nIt's time to start making changes to the image. To do this, we'll use `chroot` to change the working root of our session to the root from the image, or alternatively `systemd-nspawn`. To support emulation between architectures, we'll need to install `qemu-user-static`, `qemu-user-static-binfmt` and restart `systemd-binfmt.service`.\n\nChroot to the mounted disk image and start a shell:\n\n```bash\nsudo chroot /mnt/raw3 /bin/bash\n```\n\nEnsure that the architecture is `aarch64` and not `x86_64` (use `uname -a`).\n\nNext, we'll create a local user that we'll use to connect via SSH later. The following commands create a group and user named `pi`. The user will have a UID of 1000 and be assigned to the `pi` and `wheel` groups:\n\n```bash\n/usr/sbin/groupadd pi  \n/usr/sbin/useradd -g pi -G wheel -m -u 1000 pi\n```\n\nCreate the `.ssh` directory, the `authorized_keys` file, and set proper permissions:\n\n```bash\nmkdir /home/pi/.ssh  \nchmod 700 /home/pi/.ssh  \ntouch /home/pi/.ssh/authorized_keys  \nchmod 600 /home/pi/.ssh/authorized_keys  \nchown -R pi.pi /home/pi/.ssh/\n```\n\nAdd your public key (`~/.ssh/id_rsa.pub`) to the `authorized_keys` file.\n\nSince our new user belongs to the _wheel_ group, allow this group to use sudo without password:\n\n```bash\necho \"%wheel ALL=(ALL) NOPASSWD:ALL\" \u003e\u003e /etc/sudoers.d/wheel-nopasswd\n```\n\nAlso, Fedora prompts you to finish the setup on the first boot. To avoid that, disable the initial setup:\n\n```bash\nunlink /etc/systemd/system/multi-user.target.wants/initial-setup.service  \nunlink /etc/systemd/system/graphical.target.wants/initial-setup.service\n```\n\nChange the current directory to the EFI partition. Rename `config.txt` to `config.txt.save`.\nAnd then you can ssh. Congratulations! You successfully connected to your new Fedora Server on your Raspberry Pi!\nIn the EFI partition, copy the updated firmware files that were downloaded in Step 2. This will replace several files and add a new `config.txt` file:\n\n```bash\ncp -r ~/Downloads/rpi4efi/* .\n```\n\nIn the EFI partition edit config.txt. It should have the following contents:\n\n```ini\narm_64bit=1\nenable_uart=1\nuart_2ndstage=1\nenable_gic=1\narmstub=RPI_EFI.fd\ndisable_commandline_tags=1\ndisable_overscan=1\ndevice_tree_address=0x1f0000\ndevice_tree_end=0x200000\ndtoverlay=miniuart-bt\n```\n\nChange the contents to look like the contents below. The two changes are an addition of the kernel line a the top and comment out the armstub line. **Be sure to comment out or delete the start_x=1 line if it exists.** Save and exit the file:\n\n```ini\nkernel=rpi4-u-boot.bin\narm_64bit=1\nenable_uart=1\nuart_2ndstage=1\nenable_gic=1\n# armstub=RPI_EFI.fd\ndisable_commandline_tags=1\ndisable_overscan=1\ndevice_tree_address=0x1f0000\ndevice_tree_end=0x200000\ndtoverlay=miniuart-bt\n```\n\nThat’s all we need to change. Exit the chroot and unmount the disk image:\n\n```bash\nexit  \nsudo umount /mnt/raw3\n```\n\nDeactivate the logical volume inside the volume group **fedora**:\n\n```bash\nsudo vgchange --activate n fedora\n```\n\nThen delete the virtual device:\n\n```bash\nsudo kpartx -d Fedora-Server-37-1.7.aarch64.raw\n```\n\n### Step 5: Installing the modified image\n\nTwo time-consuming tasks remain: compressing the image and installing it on a microSD card.\n\nCompress the raw disk image to a `.xz` file, but this time keep the `.raw` file:\n\n```\nxz --compress Fedora-Server-37-1.7.aarch64.raw --keep\n```\n\nI recommend you keep the raw file if you want to make incremental changes in the future. Otherwise, remove the `--keep` parameter.\n\n\u003e This command will take a while.\n\nFinally, copy the modified disk image to a microSD card:\n\n```bash\nsudo arm-image-installer --image=Fedora-Server-37-1.7.aarch64.raw.xz --media=/dev/sda --target=rpi4 --addkey=/home/xeome/.ssh/id_rsa.pub --norootpass --relabel --resizefs -y\n```\n\n\u003e This command will take some time as well.\n\n### Step 6: Validation\n\nPower on the RPi4. Observe the behavior of the red and green LED lights and the network lights during the boot process, which may take several minutes. The red and green led lights on one end will variously blink, or stay steady, or go out. The network leds will stay steady for several minutes and go out at least twice. At the end, the red and green leds will go out and the network lights will start to blink, indicating that Fedora is now booted and requesting an IP address from your network's DHCP service.\n\nSubsequent boots are much faster.\n\nFind the dynamic IP address assigned to your Raspberry Pi using `nmap` or a similar tool on a Fedora machine or any other computer connected to your home network. Replace the CIDR range as necessary:\n\n```bash\n$ sudo nmap -sn 192.168.1.100/25\nNmap scan report for 192.168.1.106\nHost is up (0.0048s latency).\nMAC Address: E4:5F:01:AA:BB:CC (Raspberry Pi Trading)\n```\n\nConnect to your new Fedora Server on the Raspberry Pi using `ssh`. Congratulations! You have successfully connected to your new Fedora Server on your Raspberry Pi!\n\n#### Sources\n\n- \u003chttps://medium.com/geekculture/how-to-install-fedora-on-a-headless-raspberry-pi-62adfb7efc5\u003e\n- \u003chttps://forums.raspberrypi.com/viewtopic.php?t=292630\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Hashmap":{"title":"Hashmap","content":"\nFollowing text is explanation for this code:\n\u003chttps://github.com/xeome/data-structures-implementations/blob/master/hashmap.c\u003e\n\nA hash map is a data structure that allows you to store key-value pairs and quickly retrieve the value associated with a given key.\n\nThe HashMap data structure consists of a size field, which represents the number of key-value pairs stored in the hash map, a `capacity` field, which represents the maximum number of key-value pairs the hash map can hold, and a `buckets` field, which is an array of pointers to Nodes. Each Node represents a key-value pair, and the buckets array is used to store linked lists of Nodes that have the same hash value.\n\n# hash_map_init\n\nThe `hash_map_init` function initializes a hash map by allocating memory for the buckets array and setting the `capacity` and `size` fields to the specified values.\n\n# hash_map_destroy\n\nThe `hash_map_destroy` function frees the memory allocated for the buckets array and the Nodes stored in the hash map.\n\n# hash_siphash and hash_djb2\n\nThe `hash_siphash` function is a SipHash implementation, which is a cryptographic hash function that can be used to compute a hash value for a given string. The `hash_djb2` function is an alternative, simpler hash function called DJB2.\n\ndjb2 is a simple, fast hashing function created by Dan Bernstein. It is designed to be easy to implement and produce good hash values with a minimum of collisions.\n\nThe function works by iterating over the characters in a string and performing a series of operations on each character to generate a numerical hash value. The basic structure of the function is as follows:\n\n```C\nunsigned long djb2_hash(unsigned char *str) {\n    unsigned long hash = 5381;\n    int c;\n\n    while (c = *str++)\n        hash = ((hash \u003c\u003c 5) + hash) + c; /* hash * 33 + c */\n\n    return hash;\n}\n```\n\nThe first line initializes the hash value to 5381. This is a magic number that has been found to work well with djb2. The second line declares an integer c that will be used to store the current character being processed. The third line is a while loop that iterates over the characters in the string. The loop terminates when all characters have been processed or when a null character is encountered.\n\nInside the loop, the current character is fetched from the string and stored in c. Then, the hash value is updated using the following expression:\n\nhash = ((hash \u003c\u003c 5) + hash) + c;\n\nThis expression first shifts the current value of hash left by 5 bits. This has the effect of multiplying the hash value by 32. Then, the original value of hash is added to the result, effectively multiplying the hash value by 33. Finally, the character value c is added to the hash value.\n\nThe result of this operation is that each character in the string is used to update the hash value in a way that is dependent on all of the previous characters. This helps to ensure that the hash value is spread evenly over the range of possible values and minimizes the likelihood of collisions.\n\nOnce all characters have been processed, the final value of hash is returned as the hash value for the string.\n\nOverall, djb2 is a simple, fast, and effective hashing function that is widely used in a variety of applications. Its simplicity makes it easy to implement and its good performance makes it well-suited for use in a wide range of situations.\n\n# hash_map_insert\n\nThe `hash_map_insert` function inserts a key-value pair into the hash map. It first computes the hash value for the key using either `hash_siphash` or `hash_djb2`, and then inserts the key-value pair into the linked list at the corresponding index in the buckets array.\n\n# hash_map_lookup\n\nThe `hash_map_lookup` function looks up the value associated with a given key in the hash map. It first computes the hash value for the key using either `hash_siphash` or `hash_djb2`, and then searches the linked list at the corresponding index in the buckets array for a Node with the matching key. If a match is found, the function returns the value associated with the key. If no match is found, the function returns -1.\n\n# ROTL\n\nThe `ROTL` macro stands for \"rotate left\" and is used to rotate the bits in the first argument by the number of positions specified in the second argument.\n\n# SIPROUND\n\nThe `SIPROUND` macro is used in the implementation of SipHash. It performs a series of operations on the variables v0, v1, v2, and v3 that are intended to scramble the input data in a way that makes it difficult to predict the output hash value based on the input data.\n\nThe do { ... } while (0) construct is used in the SIPROUND macro to create a loop that is guaranteed to execute only once. This is a common pattern in C macros, and it is used to ensure that the macro can be used as a single statement without causing syntax errors.\n\nFor example, consider the following code:\n\n```C\nif (x \u003e 0)\n    MACRO;\n```\n\nIf MACRO is a simple macro that does not contain any control statements, it will be expanded as follows:\n\n```C\nif (x \u003e 0)\n    statement1;\n    statement2;\n    ...\n\n```\n\nThis will cause a syntax error, because the `if` statement is not properly terminated. To fix this, we can use the `do { ... } while (0)` construct in the macro to ensure that it is always treated as a single statement:\n\n```C\n#define MACRO                                                                 \\\n    do {                                                                     \\\n        statement1;                                                           \\\n        statement2;                                                           \\\n        ...                                                                   \\\n    } while (0)\n\n```\n\nNow, the macro will be expanded as follows:\n\n```C\nif (x \u003e 0)\n    do {\n        statement1;\n        statement2;\n        ...\n    } while (0);\n\n```\n\nThis ensures that the macro can be used as a single statement without causing syntax errors.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/JomOS":{"title":"JomOS","content":"\n## About\n\nJomOS is an aggressively optimized meta Linux distribution designed for people who wants to get most out of their hardware. It allows users to mix-and-match well tested configurations and optimizations with little to no effort.\n\nJomOS integrates these configurations \u0026 optimizations into one largely cohesive system.\n\n## How does JomOS improve performance\n\nWe use tuned systctl values, udev rules and other configurations. We also provide a optimized repo with march=x86-64-v3 support (CachyOS repos) which comes with a notable performance boost. It depends on your cpu if it does support that, but you dont need to worry about it - the installer will detect the correct µarch and adjust to your system. Custom tuned kernel is also planned.\nFor more information refer to [[notes/JomOS Optimizations]].\n\n## Screenshots\n\n![[notes/assets/img/O_distro.png]]\n\n## Credits\n\nHuge thanks to Linux community and CachyOS team for some of the optimizations and general help.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/JomOS-Optimizations":{"title":"JomOS Optimizations","content":"\n## Optimized repositories\n\nJomOS adds optimized repositories automatically to improve performance and system responsiveness. These repositories also include custom kernels with various CPU schedulers and other goodies.\n\nThe optimizations used in the repositories are listed below.\n\n### Compiler optimizations\n\n-march is the first and most important option. This instructs GCC(or other compilers) to generate code for a specific type of CPU. Different CPUs have different capabilities, support different instruction sets, and execute code in different ways. The -march flag instructs the compiler to generate specific code for the selected architecture, including all of its capabilities, features, instruction sets, quirks, and so on.\n\nIf the CPU type is unknown, or if the user is unsure which setting to use, the -march=native option can be used. When this flag is set, GCC will attempt to detect the processor and set appropriate flags for it automatically. This should not be used if you want to compile packages for different CPUs!\n\nWhen compiling packages on one computer to run on another (for example, when using a fast computer to build for an older, slower machine), do not use -march=native. The term \"native\" indicates that the code produced will only run on that type of CPU. Applications developed with -march=native on an Intel Core CPU will not run on an old Intel Atom CPU.\n\nThese are the four x86-64 microarchitecture levels on top of the x86-64 baseline:\n\n- x86-64: CMOV, CMPXCHG8B, FPU, FXSR, MMX, FXSR, SCE, SSE, SSE2\n- x86-64-v2: (close to Nehalem) CMPXCHG16B, LAHF-SAHF, POPCNT, SSE3, SSE4.1, SSE4.2, SSSE3\n- x86-64-v3: (close to Haswell) AVX, AVX2, BMI1, BMI2, F16C, FMA, LZCNT, MOVBE, XSAVE\n- x86-64-v4: AVX512F, AVX512BW, AVX512CD, AVX512DQ, AVX512VL\n\nMost Linux distributions use x86-64-v2 for compatibility with older hardware, but this may limit performance on newer hardware. We detect whether your CPU supports x86-64-v3 and add repositories accordingly. The performance improvement could range from 10% to 35% depending on the processor and software used.\n\n![[notes/assets/img/O_benchmarks.png]]\n\n![[notes/assets/img/O3_generic_O3_march_haswell_Comparison.png]]\n\nTo check if your cpu supports x86-64-v3, you can use the following command:\n`/lib/ld-linux-x86-64.so.2 --help | grep \"x86-64-v3 (supported, searched)\"`\n\nIf you get an output saying `x86-64-v3 (supported, searched)` then congratulations, your cpu supports x86-64-v3.\n\nThis repository is provided by CachyOS. As theres no reason to create our own v3 repositories. Many thanks to the CachyOS team for creating and maintaining this repository.\n\n## Default browser Thorium\n\nAs far as I am aware, Thorium is the fastest browser available. It also makes use of some of the compiler optimizations we use, as well as others; for more information, see [[notes/Thorium]].\n\n## Tuned sysctl values and other configurations\n\n### /etc/sysctl.d/99-JomOS-settings.conf\n\nThis file contains JomOS sysctl tweaks.\n\n#### vm.swappiness\n\nThe swappiness sysctl parameter represents the kernel's preference (or avoidance) of swap space. Swappiness can have a value between 0 and 100, the default value is 60.\n\nA low value causes the kernel to avoid swapping, a higher value causes the kernel to try to use swap space. Using a low value on sufficient memory is known to improve responsiveness on many systems.\n\nThis value is automatically calculated using your ram amount\n\n#### vm.vfs_cache_pressure\n\nThe value controls the tendency of the kernel to reclaim the memory which is used for caching of directory and inode objects (VFS cache).\n\nLowering it from the default value of 100 makes the kernel less inclined to reclaim VFS cache (do not set it to 0, this may produce out-of-memory conditions)\n\nThis value is automatically calculated using your ram amount\n\n#### vm.page-cluster\n\nrefer to \u003chttps://xeome.github.io/notes/Zram#page-cluster-values-latency-difference\u003e\n\n#### vm.dirty_ratio\n\nContains, as a percentage of total available memory that contains free pages and reclaimable pages, the number of pages at which a process which is generating disk writes will itself start writing out dirty data (Default is 20).\n\n#### vm.dirty_background_ratio\n\nContains, as a percentage of total available memory that contains free pages and reclaimable pages, the number of pages at which the background kernel flusher threads will start writing out dirty data (Default is 10).\n\n#### Network tweaks (only for CachyOS kernels)\n\nThe BBR congestion control algorithm can help achieve higher bandwidths and lower latencies for internet traffic\n\nTCP Fast Open is an extension to the transmission control protocol (TCP) that helps reduce network latency by enabling data to be exchanged during the sender’s initial TCP SYN. Using the value 3 instead of the default 1 allows TCP Fast Open for both incoming and outgoing connections\n\n#### kernel.nmi_watchdog\n\nDisabling NMI watchdog will speed up your boot and shutdown, because one less module is loaded. Additionally disabling watchdog timers increases performance and lowers power consumption\n\n### /etc/udev/rules.d/ioscheduler.rules\n\nThe kernel component that determines the order in which block I/O operations are submitted to storage devices is the input/output (I/O) scheduler.The goal of the I/O scheduler is to optimize how these can deal with read requests, it is useful to review some specifications of the two main drive types:\n\n- An HDD has spinning disks and a physical head that moves to the required location. As a result, random latency is quite high, ranging between 3 and 12ms (depending on whether it is a high-end server drive or a laptop drive bypassing the disk controller write buffer), whereas sequential access provides significantly higher throughput. The average HDD throughput is approximately 200 I/O operations per second (IOPS).\n\n- An SSD does not have moving parts, random access is as fast as sequential one, typically under 0.1ms, and it can handle multiple concurrent requests. The typical SSD throughput is greater than 10,000 IOPS, which is more than needed in common workload situations.\n\nThousands of IOPS can be generated if multiple processes make I/O requests to different storage parts, whereas a typical HDD can only handle about 200 IOPS. There is a queue of requests that must wait for storage access. This is where I/O schedulers can help with optimization.\n\nThe best scheduler to use is determined by both the device and the specific nature of the workload. Furthermore, throughput in MB/s is not the only measure of performance: deadlines or fairness reduce overall throughput while improving system responsiveness.\n\n```ini\n# set scheduler for NVMe\nACTION==\"add|change\", KERNEL==\"nvme[0-9]n[0-9]\", ATTR{queue/scheduler}=\"none\"\n# set scheduler for SSD and eMMC\nACTION==\"add|change\", KERNEL==\"sd[a-z]*|mmcblk[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"mq-deadline\"\n# set scheduler for rotating disks\nACTION==\"add|change\", KERNEL==\"sd[a-z]*\", ATTR{queue/rotational}==\"1\", ATTR{queue/scheduler}=\"bfq\"\n```\n\nFor example the [udev](https://wiki.archlinux.org/title/Udev \"Udev\") rule above sets the scheduler to _none_ for [NVMe](https://wiki.archlinux.org/title/NVMe \"NVMe\"), _mq-deadline_ for [SSD](https://wiki.archlinux.org/title/SSD \"SSD\")/eMMC, and _bfq_ for rotational drives:\n\n### /etc/mkinitcpio.conf\n\nBase and udev replaced with systemd for faster boots and set compression algorithm to zstd and compression level to 2 because compression ratio increase isn't worth the increased boot time.\n\n### /etc/systemd/zram-generator.conf\n\nUse zstd compression by default, for more information visit [[notes/Zram]]\n\n# Sources\n\n## Benchmarks\n\n\u003chttps://lists.archlinux.org/pipermail/arch-general/2021-March/048739.html\u003e\n\n\u003chttps://openbenchmarking.org/result/2103142-HA-UARCHLEVE55\u0026rmm=O1_generic%2CO3_march_nehalem\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Linux":{"title":"Linux","content":"\n- [[notes/Btrfs Maintenance]]\n- [[notes/Emulating Cortex A72]]\n- [[notes/JomOS]]\n- [[notes/JomOS Optimizations]]\n- [[notes/Linux Memory Management]]\n- [[notes/Post install optimizations]]\n- [[notes/Transparent Huge Pages]]\n- [[notes/XDP-Tutorial]]\n- [[notes/Zram]]\n- [[notes/Cockpit nginx reverse proxy]]\n- [[notes/Cockpit caddy reverse proxy]]","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Linux-Memory-Management":{"title":"Linux Memory Management","content":"\n## Memory Management Concepts\n\n### Virtual Memory\n\nVirtual memory is a feature of an operating system (OS) that enables a computer to be able to compensate for shortages of physical memory by temporarily transferring pages of data from random access memory (RAM) to disk storage. This allows a computer to run larger applications or multiple applications concurrently.\n\nIn the Linux operating system, data is organized into blocks called pages, which are typically 4 kilobytes (KB) in size. When a process in a computer attempts to access a specific piece of data in memory, the CPU translates the virtual address (used by the process) into a physical address (where the data is actually stored). This translation process requires multiple memory accesses and can be time-consuming.\n\nTo reduce the number of memory accesses required for address translation and improve the performance of the system, CPUs utilize a cache called the Translation Lookaside Buffer (TLB). The TLB stores recently used virtual-to-physical address translations, allowing the CPU to access the physical address more quickly. However, the TLB is typically a limited resource and applications with large memory working sets may suffer performance degradation if they are unable to utilize the TLB effectively.\n\n### Transparent Huge Pages\n\nWhen assigning memory to processes, CPUs typically use blocks of memory called pages, which are typically 4 kilobytes (KB) in size. The CPU's Memory Management Unit (MMU) is responsible for translating virtual memory addresses into physical memory addresses when processing incoming input/output (I/O) requests. This process can be time-consuming, especially when dealing with a large number of 4 KB pages. Fortunately, it has its own TLB cache (translation lookaside buffer), which reduces the potential time required to access a given memory address by caching the most recently used memory. The fact that the TLB cache size is usually very limited can cause a large potential bottleneck for applications with high memory entropy.\n\nMany modern CPU architectures support direct memory page mapping via higher levels in the page table. On x86, for example, entries in the second and third level page tables can be used to map 2M and even 1G pages. In Linux, such pages are referred to as huge. The use of huge pages relieves TLB pressure, improves TLB hit-rate, and thus improves overall system performance.\n\n### LRU list\n\nA pair of least recently used (LRU) lists are used by the Linux kernel to track pages. Pages that have been recently accessed are kept in the \"active\" list, and newly accessed pages are at the top of the list. If a page has not been accessed recently, it is removed from the list's queue and moved to the top of the \"inactive\" list. When a process accesses a page in the inactive list, it is returned to the active list.\n\n### Unevictable LRU Infrastructure\n\nAn x86 64 platform with 128 GB main memory, for example, will have more than 32 million 4k pages in a single region. If the majority of these pages are unevictable, vmscan will scan the LRU lists for evictable parts, which will consume a significant amount of CPU. The system's performance will deteriorate.\n\nThe unevictable list addresses the following classes of unevictable pages:\n\n- Those owned by ramfs.\n- Those in the SHM_LOCK shared memory zones of ramfs\n- VMAs marked as VM_LOCKED (mlock()ed) (virtual memory area)\n\nFor each zone, the Unevictable LRU engine generates a separate list of LRUs. The unevictable list is referred to as such, and the PG_unevictable flag is used to indicate that pages are unevictable.\n\nThe Unevictable LRU infrastructure maintains unevictable pages on an additional LRU list for a few reasons:\n\n1. We get to “treat unevictable pages just like we treat other pages in the system - which means we get to use the same code to manipulate them, the same code to isolate them (for migrate, etc.), the same code to keep track of the statistics, etc...” - Rik van Riel\n2. We want to be able to migrate unevictable pages between nodes for memory defragmentation, workload management and memory hotplug. The linux kernel can only migrate pages that it can successfully isolate from the LRU lists. If we were to maintain pages elsewhere than on an LRU-like list, where they can be found by isolate_lru_page(), we would prevent their migration, unless we reworked migration code to find the unevictable pages itself.\n\nThe unevictable list does not differentiate between files and anonymous, swap pages. This distinction only applies when pages are evictable.\n\n# What is MGLRU\n\nThe Linux kernel has developed mechanisms designed to increase the chances of predicting which memory pages will be accessed in the near future. Yu Zhao's MGLRU (multi generational least recently used) patch set is an attempt to improve the situation. It aims to make it easier for the system to discard unused data pages in order to make room in memory for new data.\n\nA pair of least recently used (LRU) lists are used by the kernel to track pages. Pages that have been recently accessed are kept in the \"active\" list, and newly accessed pages are at the top of the list. Some pages end up in the inactive list, which means they will be reclaimed relatively quickly once they are no longer required. For various reasons, the kernel has a long history of dumping file-backed pages. This issue is especially effective on cloud systems.\n\nThe MGLRU patches attempt to address these issues with two key changes:\n\n- Add more LRU lists to cover the range of page ages between the current active and inactive lists; these lists are called \"generations\".\n- Reduce overhead by changing the way pages are scanned (the old system uses a complex reverse mapping algorithm)\n\nOnly the oldest generation should be considered when reclaiming pages. The \"oldest generation\" may differ for anonymous and file-backed pages; anonymous pages may be more difficult to reclaim in general (they must always be written to swap), and the new code retains some of the bias toward aggressively reclaiming file-backed pages. As a result, file-backed pages may not survive reclaim for as many generations as anonymous pages. However, the current patch only allows reclaiming of file-backed pages to get one generation ahead of anonymous pages.\n\n# Sources\n\n- \u003chttps://lwn.net/Articles/851184/\u003e\n- \u003chttps://www.kernel.org/doc/html/v5.0/vm/unevictable-lru.html\u003e\n- \u003chttps://docs.kernel.org/admin-guide/mm/concepts.html#mm-concepts\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Misc":{"title":"Misc","content":"\n# Index\n\n- [[notes/ZeroTier]]\n- [[notes/VS Code Server]]\n- [[notes/Recommended Tools]]\n- [[notes/Data Structures]]\n- [[notes/Valgrind]]\n- [[notes/C++ multithreading]]\n- [[notes/Optimizing images]]\n- [[notes/Socks5 Proxy]]\n- [[notes/Fedora On Headless Raspberry PI 4]]\n- [[notes/Optimization Techniques]]\n- [[notes/SIMD Intrinsics]]\n- [[notes/System management \u0026 devops]]\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Networking":{"title":"Networking","content":"\nWIP\n\nWelcome to the networking section of my digital garden. In this section, you will find a collection of notes and articles related to networking and network technologies. The following is an index of the various topics that you will find in this section:\n\n# Index\n\n- [[notes/OSPF]]\n- [[notes/VLAN]]\n- [[notes/STP]]\n- [[notes/XDP-Tutorial]]\n- [[notes/Socket programming]]\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/OSPF":{"title":"OSPF","content":"\nWIP\n\n# Link-state routing protocols\n\nRouters in a link-state routing protocol exchange information about the state of their own links via a process known as link-state advertising. Each router broadcasts to all other routers in the network a link-state advertisement (LSA) containing information about the state of its own links.\n\nThe LSA includes the following information:\n\n- The router's ID: This is a unique identifier for the router.\n- The links or neighbors the router is connected to: This includes the destination of the link, the cost or metric of the link, and the status of the link (up or down).\n- The sequence number: This is a number that indicates the age of the LSA. The router increments the sequence number each time it sends an updated LSA.\n\nWhen a router receives an LSA from another router, it stores the information in its own link-state database and sends a copy to all of its neighbors. This procedure is repeated until all routers in the network have received the LSA and updated their link-state databases.\n\nThe topological map of the entire network is stored in the link-state database, which the router uses to calculate the shortest path to a destination using a routing algorithm. The topological map is used to calculate the shortest path between any two points in the network using a routing algorithm, such as Dijkstra's algorithm. This allows the router to determine the best path to send data packets to their destination.\n\nAlthough link-state routing protocols are more complex and resource-intensive than distance-vector routing protocols, they have several advantages. They provide more accurate and up-to-date network information, allowing for more efficient routing. They also enable the creation of hierarchical networks, in which the network is divided into smaller sections and only the links between these sections are exchanged between routers, reducing the amount of information exchanged and increasing efficiency.\n\nOne example of a link-state routing protocol is Open Shortest Path First (OSPF).\n\n# Open Shortest Path First (OSPF)\n\n## OSPF Packet Types\n\nOpen Shortest Path First (OSPF) is a link-state routing protocol that exchanges information between routers using five different types of protocol packets or messages. These packets are:\n\n1. Hello: The Hello packet is used by routers to establish and maintain neighbor relationships. It is sent on a regular basis to all of a router's neighbors to confirm that the link is still active and to negotiate OSPF connection parameters such as the router's ID and the area it belongs to.\n\n2. Database Description (DD): The DD packet is used by routers to exchange link-state information. A router sends it to its neighbors in order to describe the contents of its link-state database. This information is then used by the neighbors to update their own link-state databases.\n\n3. Link-State Request (LSR): The LSR packet is used to ask a neighbor for specific pieces of link-state information. If a router's link-state database is missing some information, it can send an LSR to request the missing data.\n\n4. Link-State Update (LSU): The LSU packet is used to send link-state information to a neighbor. It is sent in response to an LSR or as part of the routers' regular exchange of link-state information.\n\n5. Link-State Acknowledgment (LSAck): The LSAck packet is used to acknowledge the receipt of an LSU. A router sends it to the LSU sender to confirm that the link-state information was received and processed correctly.\n\nThese five types of OSPF packets are used to establish and maintain neighbor relationships, exchange link-state information, and ensure the link-state database's accuracy and reliability.\n\n## OSPF Entries\n\nIn Open Shortest Path First (OSPF), there are three types of entries or tables that are used to store information about the network. These tables are:\n\n1. Router table: The router table, also known as the forwarding table, stores information about all known network destinations' routes. It is used by the router to determine the next hop for a forwarded packet. The router table is filled with data from the link-state database.![[notes/assets/img/O_Pasted image 20221224185350.png]]\n\n2. Link-state database: The link-state database stores a detailed representation of the entire network, including information about the links and neighbors of each router, as well as the cost or metric of each link. The link-state database is populated using link-state advertisements (LSAs) received from other routers. `display ospf lsdb` command to view lsdb information.![[notes/assets/img/O_Pasted image 20221224185330.png]]\n\n3. Neighbor table: The neighbor table stores data about the routers that are directly connected to the local router. It contains the router's ID, the link to the neighbor, and the neighbor's status (up or down). The neighbor table is used to keep track of neighbors and exchange link-state information with other routers. `display ospf peer` command to view status information.![[notes/assets/img/O_Pasted image 20221224185301.png]]\n\nThese three tables are used by OSPF routers to exchange information about the network and determine the best route for forwarding packets to their destination.\n\n## Establishing OSPF adjacency\n\nRouters discover each other by exchanging Hello packets. When a router receives a Hello packet from a neighbor, it adds the neighbor to its neighbor table and replies with another Hello packet. This establishes the two routers' neighbor relationship. They negotiate which router will be the master and which will be the slave. The master router initiates the exchange of link-state information, while the slave router responds to information requests.\n\nThe role of master or slave is determined based on the following criteria:\n\n1. Router ID: The router with the highest Router ID becomes the master. The Router ID is a unique identifier for each router, and it is determined by the highest IP address of the router's active interfaces.\n\n2. Priority: If the Router IDs are the same, the router with the highest priority becomes the master. The priority is a value between 0 and 255 that can be manually configured on each router. If the priorities are also the same, both routers become masters.\n\nAfter establishing a neighbor relationship, the routers begin exchanging link-state information. A Database Description (DD) packet is sent from one router to the other, describing the **summary** of contents of its link-state database. The other router then sends a Link-State Request (LSR) packet to inquire about any missing data. The first router responds with the requested information in the form of a Link-State Update (LSU) packet. After that, the other router sends LSAck to confirm receipt of the LSU. This process is repeated until each router has a complete copy of the other's link-state database.\n\nBoth routers are considered fully adjacent once they have a complete copy of each other's link-state database. They can then exchange routing information and forward packets to one another.\n\n![[notes/assets/img/O_Pasted image 20221224191057.png]]\n\n## DR and BDR\n\nIn Open Shortest Path First (OSPF), the Designated Router (DR) and the Backup Designated Router (BDR) are special roles that are used to reduce the amount of link-state information that is exchanged between routers in a multi-access network, such as a LAN.\n\nA multi-access network is a type of network where multiple devices are connected to the same physical link, such as a Ethernet switch. In a multi-access network, all the routers are connected to the same broadcast domain, and they can all send and receive packets to and from any other device on the network.\n\nIn OSPF, the DR and BDR are responsible for exchanging link-state information with the other routers in the network. This reduces the amount of link-state information that needs to be exchanged, as the other routers only need to exchange information with the DR and BDR, rather than with every other router on the network.\n\nThe DR is the primary router responsible for exchanging link-state information, while the BDR is a backup router that takes over if the DR fails. The DR and BDR are elected by the routers in the network based on their Router IDs and priorities. The router with the highest Router ID becomes the DR, and the router with the next highest Router ID becomes the BDR. If the Router IDs are the same, the router with the highest priority becomes the DR. If the priorities are also the same, both routers become DRs.\n\nIn summary, the DR and BDR are special roles in OSPF that are used to reduce the amount of link-state information exchanged in a multi-access network. The DR is the primary router responsible for exchanging link-state information, while the BDR is a backup router that takes over if the DR fails. The DR and BDR are elected by the routers in the network based on their Router IDs and priorities.\n\n## Multi Area OSPF\n\nIn Open Shortest Path First (OSPF), a multi-area network is a network that is divided into multiple areas, with each area containing a collection of networks and routers that are connected by a common **area border router (ABR)**. This allows for more efficient routing within the OSPF network, as routers within the same area exchange information about the state of their own links and do not need to exchange information about links in other areas.\n\nEach area in a multi-area OSPF network is given a unique area ID, which is used to identify the area in the link-state database. The ABR is in charge of connecting the area to the rest of the network and exchanging link-state information with other areas.\n\nIn the form of a summary LSA, the ABR sends a summary of the link-state information for the area to the other areas. This allows the other areas to get a high-level view of the networks in the area without having to keep detailed information about every link and router.\n\nThe ABR also maintains a link-state database for the entire network, which includes information about the links and routers in all the areas. This allows the ABR to route packets between areas and to calculate the shortest path between any two points in the network.\n\nMulti-area OSPF provides several benefits, including improved scalability and reduced network traffic. It also allows for the creation of a hierarchical network structure, which can make it easier to manage and troubleshoot the network.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Optimization-Techniques":{"title":"Optimization Techniques","content":"\n# WARNING: WORK IN PROGRESS\n\n# Introduction\n\nIn this document, I will try to explain various optimization techniques that can be applied to software development to improve its performance, power efficiency, and security. These techniques include Profile-Guided Optimization (PGO), Link-Time Optimization (LTO), LLVM BOLT, Compiler Flags, and other optimization techniques such as dead code elimination, constant propagation, register allocation, loop unrolling, inlining, instruction scheduling and vectorization, and interprocedural optimization (IPO). I will explain the concepts, working mechanism, benefits, and limitations of each optimization technique, along with examples of how they can be applied in practice. By the end of this document, I hope that the readers will have a comprehensive understanding of the different optimization techniques available and be able to choose the appropriate optimization technique for their specific use case.\n\n# Link-Time Optimization (LTO)\n\n## Definition and concept\n\n## How LTO works\n\n# LLVM BOLT\n\n## Definition and concept\n\nLLVM BOLT (Binary Optimization and Analysis Tool) is a tool for optimizing and analyzing binary code. It is built on top of the LLVM compiler infrastructure, and it works by analyzing the control flow graph (CFG) of the binary code and applying a variety of optimization techniques to improve performance.\n\n## How BOLT works\n\nBOLT runs passes with either code transformations or analyses, similar to a compiler. BOLT is also equipped with a data-flow analysis framework to feed information to passes that need it. Some passes are architecture-independent while others are not. In this section, we discuss the passes applied to the Intel x86-64 target.\n\n| Pass Name             | Description                                                                                                       |\n| :-------------------- | :---------------------------------------------------------------------------------------------------------------- |\n| 1. strip-rep-ret      | Strip repz from repz retq instructions used for legacy AMD processors                                             |\n| 2. icf                | Identical code folding                                                                                            |\n| 3. icp                | Indirect call promotion                                                                                           |\n| 4. peepholes          | Simple peephole optimizations                                                                                     |\n| 5. simplify-ro-loads  | Fetch constant data in .rodata whose address is known   statically and mutate a load into a mov                   |\n| 6. icf                | Identical code folding (second run)                                                                               |\n| 7. plt                | Remove indirection from PLT calls                                                                                 |\n| 8. reorder-bbs        | Reorder basic blocks and split hot/cold blocks into separate sections (layout optimization)                       |\n| 9. peepholes          | Simple peephole optimizations (second run)                                                                        |\n| 10. uce               | Eliminate unreachable basic blocks                                                                                |\n| 11. fixup-branches    | Fix basic block terminator instructions to match the CFG and the current layout (redone by reorder-bbs)           |\n| 12. reorder-functions | Apply HFSort to reorder functions (layout optimization)                                                           |\n| 13. sctc              | Simplify conditional tail calls                                                                                   |\n| 14. frame-opts        | Removes unnecessary caller-saved register spilling                                                                |\n| 15. shrink-wrapping   | Moves callee-saved register spills closer to where they are needed, if profiling data shows it is better to do so |\n\nSome parts of bellow information is rewritten and some are directly taken from the paper.\n\nstrip-rep-ret:\n\n\u003e In favor of I-cache space, such as removing alignment NOPs and AMD-friendly REPZ bytes, or using shorter versions of instructions. Our findings show that, for large applications, it is better to aggressively reduce I-cache occupation, except if the change incurs D-cache overhead since the cache is one of the most constrained resources in the data-center space. This explains BOLT’s policy of discarding all NOPs after reading the input binary. Even though compiler-generated alignment NOPs are generally useful, the extra space required by them does not pay off and simply stripping them from the binary provides a small but measurable performance improvement.\n\nicf:\n\n\u003e BOLT features identical code folding (ICF) to complement the ICF optimization done by the linker. An additional benefit of doing ICF at the binary level is the ability to optimize functions that were compiled without the -ffunction-sections flag and functions that contain jump tables. As a result, BOLT is able to fold more identical functions than the linkers. We have measured the reduction of code size for the HHVM binary [19] to be about 3% on top of the linker’s ICF pass.\n\nicp and plt:\n\nPasses 3 and 7 leverage call frequency information to optimize function calls. Pass 3, indirect call promotion, mutates a function call into a more performant version, while pass 7, PLT call optimization, removes indirection from PLT calls. BOLT also has the ability to do function inlining, but it is a limited version compared to what compilers perform at higher levels. The inlining opportunities that BOLT can take advantage of typically come from more accurate profile data, BOLT’s own indirect-call promotion optimization, cross-module nature, or a combination of these factors.\n\nsimplify-ro-loads:\n\n\u003e Simplification of load instructions, explores a tricky tradeoff by fetching data from statically known values (in read-only sections). In these cases, BOLT may convert loads into immediate-loading instructions, relieving pressure from the D-cache but possibly increasing pressure on the I-cache, since the data is now encoded in the instruction stream. BOLT’s policy, in this case, is to abort the promotion if the new instruction encoding is larger than the original load instruction, even if it means avoiding an arguably more computationally expensive load instruction. However, we found that such opportunities are not very frequent in our workloads.\n\nreorder-bbs:\n\n\u003e Pass 8, reorder and split hot/cold basic blocks, reorders basic blocks according to the most frequently executed paths, so the hottest successor will most likely be a fall-though, reducing taken branches and relieving pressure from the branch predic- tor unit\n\n# Profile-Guided Optimization (PGO)\n\nI recommend checking out the following document written by my friend which can be found at \u003chttps://misile00.github.io/notes/PGO\u003e. This document provides a detailed explanation of PGO and how it can be applied in practice.\n\n# Compiler Flags\n\n## Overview of compiler flags\n\n## Commonly used flags for optimization\n\n# LLVM POLLY\n\n## Definition and concept\n\n## How POLLY works\n\n# Other Optimization Techniques\n\n## Dead Code Elimination\n\n## Constant Propagation\n\n## Register Allocation\n\n## Loop Unrolling\n\n## Inlining\n\n## Instruction Scheduling\n\n## Vectorization\n\n## Interprocedural Optimization (IPO)\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Optimizing-images":{"title":"Optimizing images","content":"\n# Overview\n\nImage optimization is the process of reducing the file size of an image without compromising its visual quality. Optimizing images can improve the speed and performance of a website or application, as well as reduce data usage and improve the user experience. This documentation will provide an in-depth look at the various techniques and tools available for optimizing images as well as best practices for implementing image optimization in your projects.\n\nLossy and lossless compression are 2 types of compression. Lossy compression algorithms discards some of the data in order to achieve a smaller file size. This can result in visible artifacts and a degradation of image quality (although with good settings it can be very hard to notice), but the compression ratio is usually much higher than lossless compression. Lossless compression algorithms do not discard any image data as the name suggests. This results in a lower compression ratio. The most common lossless image compression formats include PNG and GIF while JPEG is the most widely used lossy image compression format. It's important to consider the purpose of the image and the intended audience when choosing between lossy and lossless compression. If the image will be used for professional or critical applications lossless compression is recommended, while lossy compression may be more suitable for casual or web-based applications.\n\nThere are a lot of different image formats out there, and some aren't as good at compression as others, but they might work better with certain things. I personally like WEBP because it has both lossless and lossy compression options and it's pretty popular. This guide will also show you how to get the best compression with each format. If you don't care about compatibility and just want to shrink the file size as much as possible you can try using less mainstream formats like AVIF or JPEG XL (not to be confused with regular JPEG).\n\n# Optimizing PNG Files\n\nI personally optimize with oxipng, a multithreaded lossless PNG compression optimizer. Because it is a command line tool, it may not be appropriate for non-power users.\n\n## Examples:\n\n#### Optimizing Every .png File In A Directory\n\n```C\noxipng -o max --strip safe *.png\n```\n\nThis command will optimize all png files in the current directory. This command provides nearly maximum optimization; further optimization can be obtained by including the -Z flag, which enables a slower but better compressing Zopfli algorithm; I did not include it because it significantly lengthens the optimization process.\n\n`-o max` sets optimization level to maximum, its a stable alias for maximum compression.\n\n## Optimization Levels for Oxipng\n\nOptimization levels:\n\n```C\n-o 0   =\u003e --zc 5  --fast             (1 trial, determined heuristically)\n-o 1   =\u003e --zc 10 --fast             (1 trial, determined heuristically)\n-o 2   =\u003e --zc 11 -f 0,1,6,7 --fast  (1 trial, determined by fast evaluation)\n-o 3   =\u003e --zc 11 -f 0,7,8,9         (4 trials)\n-o 4   =\u003e --zc 12 -f 0,7,8,9         (4 trials; same as `-o 3` for zopfli)\n-o 5   =\u003e --zc 12 -f 0,1,2,5,6,7,8,9 (8 trials)\n-o 6   =\u003e --zc 12 -f 0-9             (10 trials)\n-o max =\u003e                            (stable alias for the max compression)\n```\n\n# Optimizing WEBP\n\n### Lossless\n\nFollowing command can be used to losslessly compress a png file to webp with highest compression settings:\n\n```C\ncwebp -quiet -v -mt -lossless -z 9 input.png -o output.webp\n```\n\n`-mt` Use multi-threading for encoding, if possible.\n\n`-lossless`  Enable lossless compression.\n\n`-m 6` This parameter controls the trade off between encoding speed and the compressed file size and quality.  Possible\nvalues range from 0 to 6. Default value is 4.  When higher values are used, the encoder will spend more time inspecting additional encoding  possibilities  and  decide on the quality gain.  Lower value can result in faster processing time at the expense of larger file size and lower compression quality.\n\n### Lossy\n\nFollowing command can be used to lossy compress a png file to webp with highest compression settings:\n\n```C\ncwebp -quiet -v -mt -af -m 6 -q 97 input.png -o output.webp\n```\n\n`-mt` Use multi-threading for encoding, if possible.\n\n`-af` Turns auto-filter on. This algorithm will spend additional time optimizing the filtering strength to reach a well-balanced quality.\n\n`-m 6` This parameter controls the trade off between encoding speed and the compressed file size and quality.  Possible\nvalues range from 0 to 6. Default value is 4.  When higher values are used, the encoder will spend more time inspecting additional encoding  possibilities  and  decide on the quality gain.  Lower value can result in faster processing time at the expense of larger file size and lower compression quality.\n\n`-q 97` Controls quality level.\n\nAdditionally, `-hint` can be used to specify a hint about the type of input image. The following values are possible: photo, picture or graph. By knowing what type of data is being compressed, webp can potentially achieve higher compression.\n\n# See Also\n\n- \u003chttps://github.com/shssoichiro/oxipng\u003e\n- \u003chttps://developers.google.com/speed/webp/docs/cwebp\u003e\n- \u003chttps://github.com/libjxl/libjxl\u003e","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Post-install-optimizations":{"title":"Post install Optimizations","content":"\n### Editing mkinitcpio.conf for faster boot times\n\nReplace udev with systemd for faster boots and set compression algorithm to zstd and compression level to 2 because compression ratio increase isn't worth the increased boot time.\n\n(bellow isnt the whole file, just the parts that needs changes)\n\n```ini\nHOOKS=\"base systemd autodetect...\n\nCOMPRESSION=\"zstd\"\nCOMPRESSION_OPTIONS=(-2)\n```\n\nNote: You can replace base AND udev with systemd but you will lose access to recovery shell.\n\n### Changing io schedulers\n\nThe process to change I/O scheduler, depending on whether the disk is rotating or not can be automated and persist across reboots. For example the udev rule below sets the scheduler to none for NVMe, mq-deadline for SSD/eMMC, and bfq for rotational drives:\n\n```ini\n# /etc/udev/rules.d/60-ioschedulers.rules\n\n# set scheduler for NVMe\nACTION==\"add|change\", KERNEL==\"nvme[0-9]n[0-9]\", ATTR{queue/scheduler}=\"none\"\n# set scheduler for SSD and eMMC\nACTION==\"add|change\", KERNEL==\"sd[a-z]*|mmcblk[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"mq-deadline\"\n# set scheduler for rotating disks\nACTION==\"add|change\", KERNEL==\"sd[a-z]*\", ATTR{queue/rotational}==\"1\", ATTR{queue/scheduler}=\"bfq\"\n```\n\n### Editing /etc/makepkg.conf (in Arch linux or derivatives)\n\nEdit makepkg config file for it to utilize all threads on your cpu\nExample for 12 threads:\n\n```ini\nMAKEFLAGS=\"-j12\"\n```\n\n### Auto nice daemons and irq balance\n\nAnanicy-cpp can be installed to automatically set [nice](https://en.wikipedia.org/wiki/Nice_(Unix)) levels.\n\n[Irq balance](https://wiki.archlinux.org/title/Improving_performance#irqbalance) distributes [hardware interrupts](https://en.wikipedia.org/wiki/Interrupt_request_(PC_architecture)) across available processors to improve system performance.\n\n### Zram or Zswap\n\nZswap is a kernel feature that provides a compressed RAM cache for swap pages. Pages which would otherwise be swapped out to disk are instead compressed and stored into a memory pool in RAM. Once the pool is full or the RAM is exhausted, the least recently used (LRU) page is decompressed and written to disk, as if it had not been intercepted. After the page has been decompressed into the swap cache, the compressed version in the pool can be freed.\n\nThe difference compared to ZRAM is that zswap works in conjunction with a swap device while zram is a swap device in RAM that does not require a backing swap device.\n\nSince it is enabled by default, [disable zswap](https://wiki.archlinux.org/title/Zswap#Toggling_zswap \"Zswap\") when you use zram to avoid it acting as a swap cache in front of zram. Having both enabled also results in incorrect [zramctl](https://man.archlinux.org/man/zramctl.8) statistics as zram remains mostly unused; this is because zswap intercepts and compresses memory pages being swapped out before they can reach zram.\n\n##### Recommended configurations for zswap\n\n```C\n# echo lz4 \u003e /sys/module/zswap/parameters/compressor\n\n# echo 10 \u003e /sys/module/zswap/parameters/max_pool_percent\n```\n\nAbove will change zswap settings only for current session, to make the setting changes persist add `zswap.compressor=zstd zswap.max_pool_percent=10` to your bootloader's config file for the kernel command line.\n\n`/etc/sysctl.d/99-swap-tune.conf:`\nfor ssd:\n\n```ini\nvm.page-cluster = 0\n```\n\nfor hdd:\n\n```ini\nvm.page-cluster = 2\n```\n\n##### Recommended configurations for zram\n\n`/etc/systemd/zram-generator.conf:`\n\n```ini\n[zram0]\nzram-size = ram * 1\ncompression-algorithm = lz4\n```\n\nAbove config file is for [systemd zram generator](https://github.com/systemd/zram-generator)\n\nYou can increase `zram-size` further if you find compression ratio to be high enough.\n\n`/etc/sysctl.d/99-swap-tune.conf:`\n\n```ini\nvm.page-cluster = 0\n```\n\nA more detailed explanation can about why these values were chosen can be found in [[notes/Zram]].\n\n### Transparent Huge Pages\n\nTo summarize, transparent hugepages are a framework within the Linux kernel that allows it to automatically facilitate and allocate large memory page block sizes to processes (such as games) with sizes averaging around 2 MB per page and occasionally 1 GB (the kernel will automatically adjust the size to what the process needs).\n\n```bash\n[user@host ~]$ cat /sys/kernel/mm/transparent_hugepage/enabled\n[always] madvise never\n```\n\nThere are 3 values you can choose You should try each value yourself to see if it improves your workflow, for more information click here: [[notes/Transparent Huge Pages]].\nTo change the value for current session:\n\n```bash\necho 'always' | sudo tee /sys/kernel/mm/transparent_hugepage/enabled\n```\n\nTo make changes persist:\\\nInstall sysfsutils and then add `kernel/mm/transparent hugepage/enabled=always` to `/etc/sysfs.conf` or add `transparent_hugepage=always` to your bootloader's config file for the kernel command line.\n\n# Additional sources\n\n#### initramfs\n\n\u003chttps://wiki.archlinux.org/title/Mkinitcpio/Minimal_initramfs\u003e\n\n#### Zram\n\n\u003chttps://linuxreviews.org/Zram\u003e\n\n\u003chttps://docs.kernel.org/admin-guide/sysctl/vm.html\u003e\n\n\u003chttps://www.reddit.com/r/Fedora/comments/mzun99/new_zram_tuning_benchmarks/\u003e\n\n#### Transparent Huge Pages\n\n\u003chttps://www.kernel.org/doc/html/latest/admin-guide/mm/transhuge.html\u003e\n\n\u003chttps://access.redhat.com/solutions/46111\u003e\n\n\u003chttps://www.reddit.com/r/linux_gaming/comments/uhfjyt/underrated_advice_for_improving_gaming/\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Recommended-Tools":{"title":"Recommended Tools","content":"\nThese are some of the tools and programs that I recommend and use. I'll keep adding more as I find them.\n\n## gping\n\nPing, but with graph and statistics. Works fine on tty.\n![[notes/assets/img/O_gping.png]]\n\n## Bat\n\nCat clone with syntax highlighting and git integration.\n![[notes/assets/img/O_bat.png]]\n\n\n## grc\n\nGeneric colorizer that works on many commands.\n\n![[notes/assets/img/O_Pasted image 20221229141033.png]]\n\n![[notes/assets/img/O_Pasted image 20221229141309.png]]","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Resources":{"title":"Resources","content":"\nThis is an index for resources I collected for various topics\n\n# Compilers\n\n- \u003chttps://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/\u003e\n- \u003chttps://github.com/DoctorWkt/acwj\u003e\n\n# Systems Performance\n\n- \u003chttps://www.brendangregg.com/linuxperf.html#Documentation\u003e\n- [[notes/Post install optimizations]]\n\n# Programming Performance\n\n- \u003chttps://products.easyperf.net/perf-ninja\u003e\n- [[notes/SIMD Intrinsics]]\n- [[notes/Optimization Techniques]]\n\n# Low Level Systems Programming\n\n- \u003chttps://github.com/gurugio/lowlevelprogramming-university\u003e\n\n# Operating Systems\n\n- \u003chttps://learn.saylor.org/course/view.php?id=94\u003e\n\n# Algorithms \u0026 Data Structures\n\n- [[notes/Data Structures]]\n- \u003chttps://github.com/jwasham/coding-interview-university\u003e (this has alot of things)\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/SIMD-Intrinsics":{"title":"Improving Performance With SIMD intrinsics","content":"\n\u003e Modern CPUs increasingly rely on parallelism to achieve peak performance. The most well-known form is task parallelism, which is supported at the hardware level by multiple cores, hyperthreading and dedicated instructions supporting multitasking operating systems. Less known is the parallelism known as instruction level parallelism: the capability of a CPU to execute multiple instructions simultaneously, i.e., in the same cycle(s), in a single thread. Older CPUs such as the original Pentium used this to execute instructions utilizing two pipelines, concurrently with high-latency floating point operations. Typically, this happens transparent to the programmer. Recent CPUs use a radically different form of instruction level parallelism. These CPUs deploy a versatile set of vector operations: instructions that operate on 4 or 8 inputs1 , yielding 4 or 8 results, often in a single cycle. This is known as SIMD: Single Instruction, Multiple Data. To leverage this compute potential, we can no longer rely on the compiler. Algorithms that exhibit extensive data parallelism benefit most from explicit SIMD programming, with potential performance gains of 4x - 8x and more.\n\nOutside of niche areas like high-performance computing, game development, or compiler development, even very experienced C and C++ programmers are largely unfamiliar with SIMD intrinsics.\n\n## Concepts\n\n![[notes/assets/img/O_Pasted image 20230216230406.png]]\n\nRegisters are used by a CPU to store data for operations. A typical register holds 32 or 64 bits. Some of these registers can be split in to 16bit parts or even single bytes.\n\nVector registers store 4 (SSE) or 8 (AVX) scalars. This means that the C# or C++ vector remains a vector at the assembler level: rather than storing 4 separate values in 4 registers, we store 4 values in a single vector register. And rather than operating on a, b, c and d separately, we use a single SIMD instruction to perform addition (for example) to all 4 values.\n\nIf you're a C++ programmer, you're probably familiar with the basic types like char, short, int, and float. Each of these has a different size: A char has 8 bits, a short has 16, an int has 32, and a float has 32. Because bits are just bits, the only difference between a float and an int is in the interpretation. This enables us to do some nasty things:\n\n```Cpp\nint a;\nfloat\u0026 b = (float\u0026)a;\n```\n\nThis creates one integer and a float reference to a. Because variables a and b now share the same memory location, changing one changes the other. An alternative way to achieve this is using a union:\n\n```C\nunion { int a; float b; };\n```\n\nAgain, a and b reside in the same memory location. Here’s another example:\n\n```C\nunion { unsigned int a4; unsigned char a[4]; };\n```\n\nThis time, a small array of four chars overlaps the 32-bit integer value a4. We can now access the individual bytes in a4 via array a[4]. Note that a4 now basically has four 1-byte ‘lanes’, which is somewhat similar to what we get with SIMD. We could even use a4 as 32 1-bit values, which is an efficient way to store 32 boolean values.\n\nAn SSE register is 128 bits in size and is labeled `__m128` if it stores four floats or `__m128i` if it stores ints. For simplicity, we will refer to `__m128` as 'quadfloat' and `__m128i` as 'quadint'. `__m256` ('octfloat') and `__m256i` ('octint') are the AVX versions. To use the SIMD types, we need to include the following headers:\n\n```C\n#include \"nmmintrin.h\" // for SSE4.2\n#include \"immintrin.h\" // for AVX\n```\n\nA `__m128` variable contains four floats, so we can use the union trick again:\n\n```C\nunion { __m128 a4; float a[4]; };\n```\n\nNow we can conveniently access the individual floats in the `__m128` vector. We can also create the quadfloat directly:\n\n```C\n__m128 a4 = _mm_set_ps( 4.0f, 4.1f, 4.2f, 4.3f );\n__m128 b4 = _mm_set_ps( 1.0f, 1.0f, 1.0f, 1.0f );\n```\n\nTo add them together, we use `__mm_add_ps`:\n\n```C\n__m128 sum4 = _mm_add_ps( a4, b4 );\n```\n\nThe `__mm_set_ps` and `_mm_add_ps` keywords are called intrinsics. SSE and AVX intrinsics all compile to a single assembler instruction; using these means that we are essentially writing assembler code directly in our program.\n\n# Examples\n\n## Basic Addition\n\n```C\n#include \u003cimmintrin.h\u003e\n#include \u003cstdio.h\u003e\n\nint main(int argc, char** argv) {\n    const int N = 16;\n    float a[N], b[N], c[N];\n    // Initialize arrays\n    for (int i = 0; i \u003c N; i++) {\n        a[i] = (float)i;\n        b[i] = 2.0f;\n    }\n    // Perform element-wise addition using vector instructions\n    __m256 a_vec, b_vec;\n    for (int i = 0; i \u003c N; i += 8) {\n        a_vec = _mm256_load_ps(\u0026a[i]);\n        b_vec = _mm256_load_ps(\u0026b[i]);\n        _mm256_store_ps(\u0026c[i], _mm256_add_ps(a_vec, b_vec));\n    }\n    // Print the result\n    for (int i = 0; i \u003c N; i++) {\n        printf(\"%f + %f = %f\\n\", a[i], b[i], c[i]);\n    }\n    return 0;\n}\n```\n\nThis code performs element-wise addition of two arrays a and b, and stores the result in c. The addition is performed using vector instructions from the AVX instruction set, which allows us to operate on 8 elements at a time. This can result in significant performance improvements compared to a scalar implementation, especially on systems with support for hardware acceleration of vector instructions.\n\n## Dot Product\n\n### One accumulator, no FMA\n\n```C\nfloat dotProduct(const float* p1, const float* p2, size_t count) {\n    if (count % 8 != 0)\n        return 0.0f;\n    __m256 acc = _mm256_setzero_ps();\n    // p1End points to the end of the array, so that we don't process past the end.\n    const float* const p1End = p1 + count;\n    for (; p1 \u003c p1End; p1 += 8, p2 += 8) {\n        // Load 2 vectors, 8 floats / each\n        const __m256 a = _mm256_loadu_ps(p1);\n        const __m256 b = _mm256_loadu_ps(p2);\n        // vdpps AVX instruction does not compute dot product of 8-wide vectors.\n        // Instead, that instruction computes 2 independent dot products of\n        // 4-wide vectors.\n        const __m256 dp = _mm256_dp_ps(a, b, 0xFF);\n        acc = _mm256_add_ps(acc, dp);\n    }\n    // Add the 2 results into a single float.\n    const __m128 low = _mm256_castps256_ps128(acc);     //\u003c Compiles into no instructions. The low half of a YMM register\n                                                        // is directly accessible as an XMM register with the same\n                                                        // number.\n    const __m128 high = _mm256_extractf128_ps(acc, 1);  //\u003c This one however does need to move data, from high half of a\n                                                        // register into low half. vextractf128 instruction does that.\n    // Add the first element of two __m128 vectors (low and high)\n    const __m128 result = _mm_add_ss(low, high);\n    // By the way, the intrinsic below compiles into no instructions.  \n\t// When a function is returning a float, modern compilers pass the return value in the lowest lane of xmm0 vector register.\n    return _mm_cvtss_f32(result);\n}\n```\n\nThis function calculates dot product without using FMA(Fused Multipy and Add) instructions and using a single accumulator.\n\n### Why multiple accumulators?\n\n\u003e Data dependencies is the main thing I’d like to illustrate with this example.\n\n\u003e From a computer scientist point of view, dot product is a form of [reduction](https://en.wikipedia.org/wiki/Reduce_(parallel_pattern)). [](https://en.wikipedia.org/wiki/Reduce_(parallel_pattern))The algorithm needs to process large input vectors, and compute just a single value. When the computations are fast (like in this case, multiplying floats from sequential blocks of memory is very fast), the throughput is often limited by latency of the reduce operation.\n\nLet’s compare code of two specific versions, `AvxVerticalFma` and `AvxVerticalFma2`. The former has the following main loop:\n\n```C\nfor (; p1 \u003c p1End; p1 += 8, p2 += 8) {  \n    const __m256 a = __mm256_loadu_ps_(p1);  \n    const __m256 b = __mm256_loadu_ps_(p2);  \n    acc = _mm256_fmadd_ps(a, b, acc);  // Update the only accumulator  \n}\n```\n\n`AvxVerticalFma2` version runs following code:\n\n```C\nfor (; p1 \u003c p1End; p1 += 16, p2 += 16) {  \n    __m256 a = __mm256_loadu_ps_(p1);  \n    __m256 b = __mm256_loadu_ps_(p2);  \n    dot0 = __mm256_fmadd_ps_(a, b, dot0);  // Update the first accumulator  \n    a = __mm256_loadu_ps_(p1 + 8);  \n    b = __mm256_loadu_ps_(p2 + 8);  \n    dot1 = __mm256_fmadd_ps_(a, b, dot1);  // Update the second accumulator  \n}\n```\n\n\u003e `_mm256_fmadd_ps` intrinsic computes (a*b)+c for arrays of eight float values, that instruction is part of [FMA3](https://en.wikipedia.org/wiki/FMA_instruction_set#FMA3_instruction_set) instruction set. The reason why `AvxVerticalFma2` version is almost 2x faster—deeper pipelining hiding the latency.\n\n\u003e When the processor submits an instruction, it needs values of the arguments. If some of them are not yet available, the processor waits for them to arrive. The tables on \u003chttps://www.agner.org/\u003e say on AMD Ryzen the latency of that FMA instruction is five cycles. This means once the processor started to execute that instruction, the result of the computation will only arrive five CPU cycles later. When the loop is running a single FMA instruction which needs the result computed by the previous loop iteration, that loop can only run one iteration in five CPU cycles.\n\n\u003e With two accumulators that limit is the same, five cycles. However, the loop body now contains two FMA instructions that don’t depend on each other. These two instructions run in parallel, and the code delivers twice the throughput on the desktop.\n\n# Optimizing and Debugging SIMD Code, Hints\n\nIn the previous sections, we discussed how to vectorize code and handle conditional code. In this section, we will explore some common opportunities for improving the efficiency of SIMD code.\n\nInstruction count is an important factor in program size and speed. As a general rule, shorter source code leads to smaller and faster programs. Advanced instructions, such as `_mm_blendv_ps`, can often replace a sequence of simpler instructions. It is useful to become familiar with the available instructions.\n\nFloating point support in SSE and AVX is generally better than integer support. In some cases, converting temporary integers to floats can result in more efficient code, even if conversion back to integers is necessary. Floating point arithmetic is often simpler than integer intrinsics, some of which can be quite obscure, such as `_mm_mullo_epi32`.\n\nFrequent use of `_mm_set_ps` to create constants in vectorized code can be costly since it takes four operands. To avoid this, consider caching the quadfloat outside loops so it can be used many times inside the loop without penalty. If scalars need to be expanded to quadfloats, consider caching the expanded version in the class.\n\nGather operations, which rely on scattered memory locations, can cause issues related to `_mm_set_ps`. For faster data retrieval from memory to quadfloat, it is best to have the data already stored as a quadfloat in 16 consecutive bytes of memory.\n\nData alignment is crucial when working with quadfloats since they must always be stored at a multiple of 16 in memory. In C++, variables created on the stack will automatically follow this rule, but variables allocated using new may not be aligned, leading to unexpected crashes. Checking whether the data being processed is properly aligned can help diagnose crashes.\n\n![[notes/assets/img/O_Pasted image 20230216235536.png]]\n\nSupport for SIMD is well-integrated in the Jetbrains Clion. It allows for effortless inspection of individual values in SIMD variables.\n\nWhen using AVX/AVX2 instructions, ensure that the target hardware is compatible. If the code is not compatible, provide an alternative implementation for older hardware. Failing to do so may cause unexpected crashes or performance issues.\n\nFocus vectorization efforts on bottlenecks only. In real-world situations, it is best to focus vectorization efforts on bottlenecks only, such as a large loop that updates variables.\n\nEvade fancy SIMD libraries Vectorization is hard, and it feels unnatural to write `_mm_mul_ps(a,b)` when you meant to write `a * b`. Resist the urge to write your own operators; get used to the raw intrinsics. Anything more complex is bound to hide inefficiencies or even introduce them. Besides, some SIMD in your code makes it look like wizardry (which it is, in fact). If you must use something convenient, consider Agner Fog’s vector library: \u003chttp://www.agner.org/optimize/#vectorclass\u003e . Also read the rest of his site, the man is a guru of software optimization.\n\n# See Also\n\n- \u003chttp://ftp.cvut.cz/kernel/people/geoff/cell/ps3-linux-docs/CellProgrammingTutorial/BasicsOfSIMDProgramming.html\u003e\n- \u003chttps://www.agner.org/optimize/\u003e\n- \u003chttps://software.intel.com/sites/landingpage/IntrinsicsGuide/\u003e\n-  [http://www.cs.uu.nl/docs/vakken/magr/2017-2018/files/SIMD%20Tutorial.pdf](https://envs.sh/5o)\n- \u003chttps://en.wikipedia.org/wiki/Advanced_Vector_Extensions\u003e\n- \u003chttps://stackoverflow.blog/2020/07/08/improving-performance-with-simd-intrinsics-in-three-use-cases/\u003e","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/STP":{"title":"STP","content":"\n# Overview\n\nSpanning Tree Protocol (STP) is a network protocol that ensures an Ethernet network has a loop-free topology. STP is used to prevent network loops, which can occur when two devices on a network have multiple paths. Broadcast storms can be caused by network loops, which can severely degrade network performance and even bring the network down.\n\nSTP selects a single path between two devices and blocks all other paths. STP will unblock one of the blocked paths and use it as the active path if the primary path fails. This ensures that only one active path exists between two devices, preventing loops from forming.\n\nSTP uses a tree-based algorithm to determine the best path between two devices and is based on the IEEE 802.1D standard. It determines the best path using a set of parameters, including the cost of the link and the port identifier. STP is implemented in switches and is transparent to end devices, which means it operates behind the scenes and does not require any end-user configuration.\n\n# Root Bridge Selection\n\nSpanning Tree Protocol (STP) is a networking protocol that is used to prevent loops in a network by selecting a root bridge (also called a root switch) and blocking unnecessary links. The root bridge is the central reference point in the network, and all other switches in the network determine their position relative to the root bridge.\n\nThe root bridge is selected based on the bridge identifier (BID), which consists of a priority value and the MAC address of the switch. The priority value is a numerical value that can be manually configured on each switch, and the MAC address is a unique identifier that is assigned to each switch. By default, the switch with the lowest priority value becomes the root bridge. If multiple switches have the same priority, the switch with the lowest MAC address becomes the root bridge.\n\nOnce the root bridge is selected, the root path cost is calculated for each switch. The root path cost is the total cost of the path from the root bridge to the switch. The cost is determined based on the speed of the link and the type of network media being used. The switch with the lowest root path cost becomes the root port for each switch, which is the port that is used to forward traffic to the root bridge.\n\n# Root Port and Designated Port\n\nThe port identifier (PID) is a value that is used to identify and manage the ports on a switch. The PID consists of a priority value and the port number, and it is used by the switch to determine the root port and the designated port for each switch.\n\nThe priority value is a numerical value that can be manually configured on each port, and it is used to determine the root port and the designated port for each switch. The port with the lowest priority becomes the root port and the designated port for the switch. If multiple ports have the same priority, the port with the lowest port number becomes the root port and the designated port.\n\nA **designated port** is a port on a switch that is connected to the segment with the lowest-cost path to the root bridge. It is responsible for forwarding traffic on that segment and is in a forwarding state. Only one port on a switch can be the designated port for a specific segment.\n\nA **root port** is a port on a switch that has the lowest-cost path to the root bridge. It is responsible for forwarding traffic from the switch to the root bridge and is in a forwarding state. Each switch in the network has one and only one root port.\n\n# Bridge Protocol Data Unit (BPDU)\n\nA Bridge Protocol Data Unit (BPDU) is a message that is used to exchange information between switches and to establish the root bridge and root port for each switch. BPDUs are sent between switches on a regular basis, and they contain information about the switch, such as the switch's MAC address and the switch's port identifier (PID).\n\nWhen a switch receives a BPDU from another switch, it compares the information in the BPDU with the information in its own BPDUs to determine the root bridge and root port for the network. The switch with the lowest PID becomes the root bridge, and the port with the lowest PID becomes the root port for each switch.\n\n## BPDU types\n\nThere are two types of Bridge Protocol Data Units (BPDUs): Configuration BPDUs and Topology Change Notification (TCN) BPDUs.\n\nConfiguration BPDUs are used to exchange information about the switches in the network and to establish the root bridge and root port for each switch. They are sent on a regular basis to ensure that the spanning tree is up-to-date and to prevent loops in the network. Configuration BPDUs contain information about the switch, such as the switch's MAC address, the switch's port identifier (PID), and the switch's path cost.\n\nTopology Change Notification (TCN) BPDUs are used to inform other switches in the network of a change in the network topology. They are sent by the switch that detects the change, and they are used to trigger a reconfiguration of the spanning tree. TCN BPDUs are used to ensure that the spanning tree remains up-to-date and to prevent loops in the network.\n\n# Port states\n\nIn Spanning Tree Protocol (STP), there are five port states that a port can be in:\n\n1. Disabled: Not participating in traffic forwarding, not receiving or sending any traffic. Typically used for administrative purposes like configuration or troubleshooting.\n\n2. Blocking: Not forwarding traffic, only allowing STP BPDUs to prevent loops in the network by ensuring only one active path between any two points.\n\n3. Listening: Preparing to forward traffic, and it listens for BPDUs to ensure that the network is stable. The port blocks all incoming traffic except for STP BPDUs and sends BPDUs to confirm the network topology.\n\n4. Learning: The port does not forward frames but can receive and process frames. The port is learning the MAC addresses of devices connected to the network.\n\n5. Forwarding: Actively forwarding traffic and participating in normal network operation, accepting and forwarding all incoming traffic. Only the root port or designated port can enter Forwarding state.\n\n## STP State Transition Timing\n\nSTP uses a timer-based mechanism to transition between states. The following are the default timer values for each state transition:\n\n- **Blocking to Listening**: 15 seconds\n- **Listening to Learning**: 15 seconds\n- **Learning to Forwarding**: 15 seconds\n\nOnce the network has converged, the STP algorithm will continuously monitor the network for changes. In case of a topology change, the STP will re-converge, which can take from 50 to 60 seconds.\n\n## Rapid Spanning Tree Protocol (RSTP)\n\nRapid Spanning Tree Protocol (RSTP) is an evolution of STP that improves the convergence time of the network after a topology change. RSTP uses a more efficient negotiation process to determine the root bridge and active paths in the network. This results in faster convergence times, typically within 2-3 seconds. RSTP has only three port states: Discarding, Learning, and Forwarding. This reduction in states allows ports to transition to the forwarding state more quickly compared to normal STP.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Socket-programming":{"title":"Socket programming","content":"\n# Overview\n\nSocket programming is a technique for developing networked applications that use sockets to communicate over a network. A socket is a computer network endpoint for sending and receiving data.\n\nA socket is used by the client and server in socket programming to communicate with each other. The client makes a request to the server, and the server responds with the information requested. This communication can be synchronous (blocking) or asynchronous (non-blocking).\n\nOne advantage of socket programming is that it enables the development of networked applications that can communicate with one another regardless of the underlying operating system or hardware platform. This makes it an effective tool for developing distributed systems and applications that can communicate across a wide area network (WAN).\n\nSockets are classified into two types: stream sockets and datagram sockets. Stream sockets are TCP/IP-based connections that provide a dependable, stream-oriented connection between the client and server. They are appropriate for applications that require consistent data delivery, such as file transfer and email.\n\nDatagram sockets communicate between the client and server using the UDP/IP protocol and are connectionless. They are appropriate for applications that require fast data transmission, such as real-time audio and video streaming, but do not require reliable data delivery.\n\nThe first step in creating a socket in a client-server application is to create a socket descriptor with the `socket()` function. This function accepts three arguments: the address family (AF_INET for IPV4 and AF_INET6 for IPV6), the type of socket (SOCK STREAM for stream sockets and SOCK DGRAM for datagram sockets), and the protocol (IPV4 or IPV6) (usually 0, which allows the operating system to choose the appropriate protocol).\n\nOnce the socket descriptor has been created, the server must use the `bind()` function to bind the socket to a specific port and address. The client then uses the `connect()` function to connect to the server.\n\nFollowing the establishment of the connection, the client and server can exchange data using the `send()` and `recv()` functions. When the communication is finished, the client and server should use the `close()` function to close the socket.\n\nSocket programming is a powerful tool for developing networked applications that is used in a wide range of applications and systems. Developers can create robust and scalable network-capable applications with a solid understanding of socket programming and its underlying principles.\n\n# Examples\n\n## Server\n\n```C\n#include \u003carpa/inet.h\u003e  \n#include \u003cstdio.h\u003e  \n#include \u003cstring.h\u003e  \n#include \u003csys/socket.h\u003e  \n#include \u003cunistd.h\u003e  \n  \n// Main function for the server  \nint main(int argc, char *argv[]) {  \n    int socket_desc, client_sock, c, read_size;  \n    struct sockaddr_in server, client;  \n    // Initialize the message buffer to 0  \n    char client_message[2000] = {0};  \n  \n    // Create socket  \n    socket_desc = socket(AF_INET, SOCK_STREAM, 0);  \n    if (socket_desc == -1) {  \n        printf(\"Could not create socket\");  \n    }\n    puts(\"Socket created\");  \n  \n    // Prepare the sockaddr_in structure  \n    server.sin_family = AF_INET;  \n    server.sin_addr.s_addr = INADDR_ANY;  \n    server.sin_port = htons(8888);  \n  \n    // Bind  \n    if (bind(socket_desc, (struct sockaddr *)\u0026server, sizeof(server)) \u003c 0) {  \n        // print the error message  \n        perror(\"bind failed. Error\");  \n        return 1;  \n    }\n    puts(\"bind done\");  \n  \n    // Listen  \n    listen(socket_desc, 3);  \n  \n    // Accept and incoming connection  \n    puts(\"Waiting for incoming connections...\");  \n    c = sizeof(struct sockaddr_in);  \n  \n    // accept connection from an incoming client  \n    client_sock =  \n        accept(socket_desc, (struct sockaddr *)\u0026client, (socklen_t *)\u0026c);  \n    if (client_sock \u003c 0) {  \n        perror(\"accept failed\");  \n        return 1;  \n    }    puts(\"Connection accepted\");  \n  \n    // Receive a message from client  \n    while ((read_size = recv(client_sock, client_message, 2000, 0)) \u003e 0) {  \n        // fix garbled message after first message  \n        client_message[read_size] = '\\0';  \n  \n        // Echo the message back to the client  \n        write(client_sock, client_message, strlen(client_message));  \n  \n        // Clear the message buffer  \n        memset(client_message, 0, 2000);  \n    }  \n    // Check if client disconnected  \n    if (read_size == 0) {  \n        puts(\"Client disconnected\");  \n        fflush(stdout);  \n    }else if (read_size == -1) {  \n        perror(\"recv failed\");  \n    }  \n    return 0;  \n}\n```\n\n## Client\n\n```C\n#include \u003carpa/inet.h\u003e  \n#include \u003cstdio.h\u003e  \n#include \u003cstring.h\u003e  \n#include \u003csys/socket.h\u003e  \n#include \u003cunistd.h\u003e  \n  \n// Main function for the client  \nint main(int argc, char *argv[]) {  \n    int sock;  \n    struct sockaddr_in server;  \n    char message[1000], server_reply[2000];  \n  \n    // Create socket  \n    sock = socket(AF_INET, SOCK_STREAM, 0);  \n    if (sock == -1) {  \n        printf(\"Could not create socket\");  \n    }    puts(\"Socket created\");  \n  \n    // Prepare the sockaddr_in structure  \n    server.sin_addr.s_addr = inet_addr(\"127.0.0.1\");  \n    server.sin_family = AF_INET;  \n    server.sin_port = htons(8888);  \n  \n    // Connect to remote server retrying every 5 seconds if connection fails and print status  \n    while (connect(sock, (struct sockaddr *)\u0026server, sizeof(server)) \u003c 0) {  \n        printf(\"Connection failed. Retrying in 5 seconds...\\n\");  \n        sleep(5);  \n    }  \n    puts(\"Connected\\n\");  \n  \n    // keep communicating with server  \n    while (1) {  \n        // get multiple words input from user  \n        printf(\"Enter message : \");  \n        fgets(message, 1000, stdin);  \n  \n        // Send some data  \n        if (send(sock, message, strlen(message), 0) \u003c 0) {  \n            puts(\"Send failed\");  \n            return 1;  \n        }  \n        // Clear the message buffer  \n        memset(message, 0, 1000);  \n  \n        // Receive a reply from the server  \n        if (recv(sock, server_reply, 2000, 0) \u003c 0) {  \n            puts(\"recv failed\");  \n            break;  \n        }  \n        // Print the server's reply  \n        printf(\"Server reply :\");  \n        puts(server_reply);  \n  \n        // Clear the message buffer  \n        memset(server_reply, 0, 2000);  \n    }  \n    // close the socket  \n    close(sock);  \n    return 0;  \n}\n```\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Socks5-Proxy":{"title":"Secure SOCKS5 Proxy over SSH and ZeroTier","content":"\nSOCKS5 is a widely-used proxy protocol that allows for secure and flexible network connections. In this document, I will discuss how I create a secure SOCKS5 proxy over SSH and ZeroTier. ZeroTier is a virtual network that I use to connect different networks together. I personally use this setup to bypass network restrictions. ZeroTier allows me to connect to my RaspberryPI at home without the need for port forwarding or any similar configurations on my router.\n\n## Setting up an SSH Tunnel\n\nThis is done by using the `-D` option with the `ssh` command. The `-D` option creates a dynamic tunnel that listens on a specified port on the client machine forwarding all connections to the specified destination.\n\nFor example, the following command creates an SSH tunnel that listens on port 1080 on the client machine forwarding all connections to the server on IP address 10.0.0.5:\n\n```C\nssh -D 1080 -f -q -N user@10.0.0.5\n```\n\nRest of the options:\n`-f` Requests **ssh** to go to background just before command execution.\n`-q` Quiet mode. Causes most warning and diagnostic messages to be suppressed.\n`-N` Do not execute a remote command. This is useful for just forwarding ports (protocol version 2 only).\n\n## Setting up a ZeroTier Network\n\nThe next step is to set up a [[notes/ZeroTier]] network. ZeroTier is a virtual network that can be used to connect different networks together. It creates a virtual Ethernet switch that can be used to route traffic between different networks.\n\nTo set up a ZeroTier network you will need to sign up for a ZeroTier account. Download and install the ZeroTier client on each machine that will be a part of the network and then join the network using network ID. Once the client is installed and the network is joined everyone should be able to communicate with each other as if they were on the same LAN.\n\n## Configuring the SOCKS5 Proxy\n\nWith the SSH tunnel and ZeroTier network set up the final step is to configure the SOCKS5 proxy. This can be done by setting the `SOCKS5_PROXY` environment variable to the IP address and port of the SSH tunnel then configuring the application to use the SOCKS5 proxy.\n\nFor example, in Linux and macOS, you can set the `SOCKS5_PROXY` environment variable by running the following command:\n\n```\nexport SOCKS5_PROXY=socks5h://127.0.0.1:1080\n```\n\nAnd then in your application, you can configure it to use the SOCKS5 proxy by specifying the proxy settings, for example in curl you can use `--proxy 'socks5h://localhost:1080'`.\n\n```C\ncurl --proxy 'socks5h://localhost:1080' -O 'http://example.com/ex.txt'\n```\n\nWith this configuration, all traffic sent over the SOCKS5 proxy will be securely tunneled over the SSH connection and sent over the ZeroTier network. This allows for secure and flexible communication between networks.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/System-management-devops":{"title":"Devops","content":"\nThis is information dump for me to read again later if I forget things. There may be reduntant information.\n\n# Azure\n\nAzure is a cloud computing platform created by Microsoft. It provides a range of services for building, deploying, and managing applications and services. Some of the key services provided by Azure include:\n\n1. Azure Virtual Machines (VMs): These are virtual machines that you can rent on a pay-as-you-go basis. You can choose from a range of pre-configured virtual machines, or you can create your own.\n\n2. Azure App Service: This is a fully managed platform for building and deploying web apps, mobile apps, and APIs.\n\n3. Azure Functions: This is a serverless compute service that allows you to run code in response to events.\n\n4. Azure Cosmos DB: This is a fully managed NoSQL database service that provides global distribution, low latency, and high availability.\n\n5. Azure DevOps: This is a suite of tools for managing the entire application lifecycle, including source control, build and deployment automation, and testing.\n\n# AWS\n\nAWS (Amazon Web Services) is a cloud computing platform created by Amazon. It provides a range of services for building, deploying, and managing applications and services. Some of the key services provided by AWS include:\n\n1. Amazon EC2: This is a virtual machine service that allows you to rent virtual machines on a pay-as-you-go basis.\n\n2. Amazon S3: This is a highly scalable object storage service that provides a way to store and retrieve data from anywhere on the web.\n\n3. Amazon Lambda: This is a serverless compute service that allows you to run code in response to events.\n\n4. Amazon DynamoDB: This is a fully managed NoSQL database service that provides low latency, high scalability, and high availability.\n\n5. Amazon SQS: This is a message queue service that allows you to decouple and scale microservices, distributed systems, and serverless applications.\n\n6. Amazon Athena: This is an interactive query service that makes it easy to analyze data in Amazon S3 using SQL.\n\n7. Amazon Redshift: This is a fully managed data warehouse service that makes it easy to analyze large amounts of data using SQL.\n\n8. Amazon ElasticSearch: This is a search and analytics engine that makes it easy to search, analyze, and visualize data in real-time.\n\n# DBMS\n\n## What is the difference between a primary key and a foreign key in a database?\n\nA primary key is a unique identifier for a record in a table, while a foreign key is a reference to a primary key in another table.\n\n## How do you optimize database performance for a specific workload?\n\nDatabase performance can be optimized by properly indexing tables, optimizing SQL queries, minimizing disk I/O, and properly configuring database server settings. Host configuration can also play a big role, for example disabling [[notes/Transparent Huge Pages]]\n\n# Random Devops/sysadmin\n\n## What is Kubernetes, and how does it differ from Docker?\n\nKubernetes is an open-source container orchestration platform for automating the deployment, scaling, and management of containerized applications. Docker is a containerization technology that allows applications to be packaged and run in containers. Docker can be used with Kubernetes to create containerized applications, Kubernetes provides additional features such as load balancing, automatic scaling, and self-healing that make it ideal for managing complex containerized environments.\n\n## Can you explain the differences between a managed and unmanaged Kubernetes cluster?\n\nA managed Kubernetes cluster is provided as a service by a cloud provider, such as AWS or Google Cloud. The cloud provider manages the underlying infrastructure and takes care of tasks such as upgrading the Kubernetes version and patching security vulnerabilities. An unmanaged Kubernetes cluster is a Kubernetes cluster that is managed by the user who is responsible for maintaining the underlying infrastructure and performing tasks such as upgrading the Kubernetes version and patching security vulnerabilities.\n\n## Can you describe the architecture of EFK (Elasticsearch, Fluentd, Kibana) and how it is used for logging and monitoring?\n\nEFK is a popular open-source logging solution that uses Elasticsearch for indexing and searching log data, Fluentd for collecting and forwarding log data, and Kibana for visualizing and analyzing log data. Fluentd collects log data from various sources, formats it, and sends it to Elasticsearch for indexing and storage. Kibana provides a web-based interface for searching, analyzing, and visualizing log data.\n\n## Can you explain the difference between a process and a thread in a Linux environment?\n\nIn a Linux environment, a process is a running instance of a program, while a thread is a lightweight process that shares memory and other resources with the parent process. Processes have their own memory space and system resources, while threads share the same memory space and system resources as the parent process.\n\n## Apache\n\nApache is a free and open-source web server software that has been the most popular web server on the internet since the late 1990s. Apache is widely used for hosting static and dynamic web content and is capable of handling a wide range of web server tasks. Apache is highly customizable and supports a range of modules, making it a flexible and versatile solution for web server management.\n\n## Nginx\n\nNginx (pronounced \"engine-x\") is another popular open-source web server software that is designed for high-performance web applications. Nginx is known for its ability to handle high levels of concurrent connections and for its efficient use of system resources. Nginx is often used as a reverse proxy server or load balancer, helping to distribute web traffic across multiple servers for improved performance and reliability.\n\n## Puppet\n\nPuppet is a popular configuration management tool that allows administrators to manage IT infrastructure and applications through a centralized system. Puppet provides a declarative language for defining system configurations and automates the process of configuring, deploying, and maintaining systems at scale. With Puppet, administrators can easily manage servers, network devices, and applications across multiple platforms and environments. Puppet is widely used in DevOps and cloud computing environments to automate infrastructure management and application deployment.\n\n## How would you optimize the performance of a database system, such as MySQL or PostgreSQL, on a Linux-based server?\n\n- Tune the database configuration parameters, such as buffer sizes and cache settings.\n- Optimize the database schema and queries to reduce the load on the database.\n- Ensure that the system has enough memory and disk space to handle the workload.\n- Configure the server hardware, such as RAID and SSDs, for optimal database performance.\n- Implement database replication and clustering to distribute the workload and increase availability.\n\nThere are also various tools available for monitoring database performance, such as the MySQL Performance Schema and the PostgreSQL pg_stat_statements module, which can help identify performance bottlenecks and optimize database performance.\n\n## Describe how you would use AWS or Azure services to deploy a scalable web application.\n\n- Create a virtual private cloud (VPC) and set up the necessary network components, such as subnets, routing tables, and security groups.\n- Provision the application servers and load balancers using services like AWS EC2 or Azure VMs.\n- Set up auto-scaling groups to automatically scale the number of servers based on demand.\n- Use a content delivery network (CDN) to distribute static content and improve application performance.\n- Use a managed database service, such as AWS RDS or Azure Database, to host the database.\n- Use a caching service, such as AWS ElastiCache or Azure Cache for Redis, to improve application performance.\n- Use monitoring and logging services, such as AWS CloudWatch or Azure Monitor, to monitor the health and performance of the application.\n\n## What is the difference between AWS Lambda and AWS EC2?\n\nAWS Lambda is a serverless computing service that allows developers to run code in response to events without having to manage servers or infrastructure. It automatically scales and provisions resources as needed to run the code. AWS EC2, on the other hand, is a traditional cloud computing service that provides virtual machines for running applications. With EC2, users have more control over the environment and can customize the server to meet their needs.\n\n## How does DynamoDB differ from a traditional relational database?\n\nDynamoDB is a NoSQL database that is designed to handle large amounts of unstructured data at scale. Unlike traditional relational databases, it does not use a fixed schema, which allows for greater flexibility and scalability. It also uses a different data model called a key-value store, which allows for high performance and low latency. Additionally, DynamoDB provides automatic scaling, data replication, and backup and restore capabilities out of the box.\n\n## What is the difference between a Docker image and a Docker container?\n\nA Docker image is a pre-built package that contains all the files and dependencies required to run a particular application or service. A Docker container is an instance of an image that is running as a separate process on a host machine.\n\n## Can you explain the concept of a Docker volume and when it might be used?\n\nA Docker volume is a way to persist data between Docker containers and to share data between containers and the host machine. Volumes can be used to store configuration files, databases, or other types of persistent data that should not be lost when a container is stopped or restarted.\n\n## What is a Dockerfile, and how is it used in the Docker build process?\n\nA Dockerfile is a text file that contains a set of instructions for building a Docker image. The Dockerfile specifies the base image to use, any additional software dependencies, and the commands to run when the image is built. The Docker build process uses the Dockerfile to create a new image, which can then be used to run containers.\n\n## How would you troubleshoot a Docker container that fails to start?\n\nThere are several steps that can be taken to troubleshoot a Docker container that fails to start. First, check the container logs to see if there are any error messages or other clues as to what might be causing the issue. If that doesn't work, try running the container in interactive mode to get a better view of what's going on inside the container. If all else fails, try rebuilding the container from scratch and see if that resolves the issue.\n\n## How would you monitor the health of a Kubernetes cluster and its applications?\n\nKubernetes provides a number of built-in tools for monitoring the health of a cluster and its applications, including the Kubernetes API, the Kubernetes Dashboard, and various logging and metrics tools like Prometheus and Grafana. These tools can be used to monitor resource usage, application performance, and other key metrics.\n\n## Can you explain the difference between a Kubernetes pod and a Kubernetes deployment?\n\nA Kubernetes pod is the smallest deployable unit in Kubernetes, and represents a single instance of a running process in a container. A Kubernetes deployment is a higher-level abstraction that manages multiple pods as a single logical unit, allowing for easy scaling and management of the underlying containers.\n\n## What is an Ingress in Kubernetes? How does it differ from a Service?\n\nAnswer: In Kubernetes, an Ingress is an API object that manages external access to the services in a cluster. It provides a way to configure HTTP and HTTPS routing rules to reach the services, and can be used to expose multiple services under a single IP address. A Service, on the other hand, is an abstraction layer that represents a set of pods and defines a policy to access them. It is responsible for load balancing the traffic among the pods.\n\n## What is the purpose of a Kubernetes Deployment, and how does it ensure application redundancy and scalability?\n\nAnswer: A Kubernetes Deployment is an API object that provides declarative updates to manage the state of a set of replicas for a pod or a set of pods. It allows you to define the desired state of the application and ensure that the actual state matches the desired state. This helps to ensure application redundancy by automatically creating and replacing pods when they fail or are terminated. The Deployment also provides horizontal scaling capabilities by allowing you to increase or decrease the number of replicas based on resource usage and application demands.\n\n## How does Kubernetes handle rolling updates and rollbacks of containerized applications?\n\nAnswer: Kubernetes allows you to perform rolling updates and rollbacks of containerized applications using the Deployment API. Rolling updates are performed by gradually replacing the pods in a Deployment with new ones, while ensuring that the application remains available throughout the process. Rollbacks can be performed by reverting to a previous version of the Deployment or by rolling back a specific update.\n\n## What is a Kubernetes Pod, and how does it relate to containerization?\n\nAnswer: A Kubernetes Pod is the smallest and simplest unit in the Kubernetes object model. It represents a single instance of a running process in a cluster and can contain one or more containers. Pods provide a way to encapsulate and manage containers, and are often used to deploy and scale containerized applications.\n\n## How would you implement container-based Blue-Green deployments using Kubernetes?\n\nAnswer: In a container-based Blue-Green deployment, two identical environments are set up, one of which is active while the other is inactive. To implement this using Kubernetes, you can create two separate Deployments, one for the active environment and one for the inactive environment. A Service can be created to expose the active environment, and an Ingress can be configured to route traffic to the active environment. When a new version of the application is ready to be deployed, the inactive environment can be updated with the new version, and the Ingress can be updated to route traffic to the new environment.\n\n## What are some of the key features and benefits of Docker Compose, and how does it simplify multi-container application deployment?\n\nAnswer: Docker Compose is a tool for defining and running multi-container Docker applications. It allows you to define the services, networks, and volumes for your application in a YAML file, and then start and stop the application using a single command. Some of the key features and benefits of Docker Compose include service scaling, environment variable management, and simplified container networking.\n\n## How would you configure a Docker Swarm cluster for high availability and fault tolerance?\n\nTo configure a Docker Swarm cluster for high availability and fault tolerance, you would need to take the following steps:\n\n- Use a manager node to control the cluster and a minimum of three worker nodes for redundancy.\n- Enable swarm mode by initializing the manager node with the command \"docker swarm init\".\n- Join the worker nodes to the swarm by running the command \"docker swarm join\".\n- Create and manage services using the Docker CLI or API, which will automatically distribute tasks across the worker nodes.\n- Use the built-in load balancing features to ensure that traffic is distributed evenly across the worker nodes.\n- Use health checks to monitor the state of the containers and automatically replace them if they become unhealthy.\n\n## What is an Ingress in Kubernetes, and how is it used?\n\nIn Kubernetes, an Ingress is an API object that manages external access to the services in a cluster. It allows you to define a set of rules that route external traffic to the appropriate services based on the path and host. An Ingress can be used to expose multiple services using a single IP address, as well as to provide SSL termination and load balancing.\n\n## What is a Kubernetes Service, and how does it ensure high availability?\n\nIn Kubernetes, a Service is an abstraction that defines a logical set of pods and a policy by which to access them. It provides a stable IP address and DNS name for a set of pods, so that other parts of the cluster can access them even if they are moved or replaced. Services can be used to distribute traffic among multiple replicas of a pod, provide load balancing, and ensure that pods are restarted if they fail.\n\n## Can you describe a scenario where you had to troubleshoot a containerized application running in a Kubernetes cluster, and what tools did you use for this purpose?\n\nTo troubleshoot a containerized application running in a Kubernetes cluster, I would first look at the application's logs to identify any errors or issues. I would also check the cluster logs to see if there were any issues with the underlying infrastructure. I would then use Kubernetes tools like `kubectl` to check the status of the containers and pods, and use debugging tools like `exec` to connect to a running container and investigate further. Other useful tools for troubleshooting include `helm`, `kubetail`, and `KubeSpy`.\n\n## How would you secure the communication between the microservices in a distributed application running in a Kubernetes cluster, and what tools would you use for this purpose?\n\nTo secure the communication between the microservices in a distributed application running in a Kubernetes cluster, I would use encryption and authentication mechanisms like TLS/SSL and mutual TLS. I would also use service mesh tools like Istio or Linkerd to provide a layer of security and visibility for service-to-service communication.\n\n## Can you describe a scenario where you had to troubleshoot a networking issue between the containers running on different nodes in a Kubernetes cluster?\n\nTo troubleshoot a networking issue between containers running on different nodes in a Kubernetes cluster, I would use networking tools like `kubectl port-forward` to test connectivity between the containers. I would also use Kubernetes networking policies to restrict or allow traffic between different pods or services, and use tools like Wireshark or tcpdump to capture network traffic and analyze it.\n\n## How would you implement a horizontal scaling strategy for a containerized application running in a Kubernetes cluster, and what metrics would you use to trigger the scaling events?\n\nTo implement a horizontal scaling strategy for a containerized application running in a Kubernetes cluster, I would use metrics like CPU usage, memory usage, or network traffic to trigger scaling events. I would use Kubernetes Horizontal Pod Autoscaler (HPA) to automatically adjust the number of replicas of a deployment based on these metrics. I would also use tools like Prometheus or Grafana to monitor the application's performance and adjust the scaling metrics accordingly.\n\n## Can you explain how you have used Kubernetes ConfigMaps and Secrets to manage the configuration data for a containerized application running in a Kubernetes cluster?\n\nTo use Kubernetes ConfigMaps and Secrets to manage the configuration data for a containerized application running in a Kubernetes cluster, I would create ConfigMaps and Secrets resources in Kubernetes that store the application's configuration data. I would then mount these resources as volumes inside the containers that need access to the configuration data. This allows for easy management and sharing of configuration data across multiple containers or pods.\n\n## How would you handle a situation where a containerized application running in a Kubernetes cluster was causing resource contention and impacting the performance of other applications running in the same cluster?\n\nOne option might be to adjust the resource limits and requests for the containers to better match their actual usage patterns, and to ensure that they are not overcommitting resources. I could also consider scaling the application horizontally, either by increasing the number of replicas for the affected deployment, or by deploying the application to additional nodes in the cluster.\n\nAnother option might be to prioritize the resource allocation for the affected containers, using Kubernetes resource quotas and/or quality of service (QoS) classes to ensure that they have sufficient resources to operate properly. Alternatively, I could consider rescheduling the affected containers to different nodes in the cluster, in order to distribute the resource utilization more evenly.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Thorium":{"title":"Thorium","content":"\nChromium fork for linux named after [radioactive element No. 90](https://en.wikipedia.org/wiki/Thorium) that takes pride in being a highly optimized web browser.\n\nThorium makes many modifications to compiler configurations which highly improve performance and responsiveness. Google tries to minimize size at any cost (including RAM usage and performance), but Thorium takes a different approach. Thorium takes up approximately ~250MB compared to ~150MB for Chrome. Me and many others appreciate speed and performance over the smallest size.\n\nYou can get Thorium from \u003chttps://github.com/Alex313031/Thorium\u003e\n\n## Compiler Optimizations\n\nThorium enables the use of numerous instruction set extensions, allowing the CPU to perform certain operations much more efficiently and quickly. For example the Chromium Project, makes extensive use of vectorizable code, so AVX (Advanced Vector Extensions) is a natural next step in performance improvement. The only reason it isn't used by default in Chromium is for compatibility: older processors (pre-2011) lack AVX capability and thus cannot run AVX-compliant programs. But don't worry if you have an old processor that lacks AVX; the creator occasionally makes SSE4/SSE3-only releases for Linux and Windows.\n\nThis represents only the tip of the iceberg. If you're interested in learning more about Thorium's performance optimizations, click [here](https://thorium.rocks/optimizations).\n\n## Some Benchmarks\n\nDepending on your operating system and hardware, performance improvements may vary. Here are some results from tests on an old CPU, an FX-8370 clocked at 4.7GHz across all cores.\n\n### Chromium\n\n![[notes/assets/img/O_chromium_octane.png]]\n![[notes/assets/img/O_chromium_speedometer.png]]\n\n### Thorium\n\n![[notes/assets/img/O_thorium_octane.png]]\n![[notes/assets/img/O_thorium_speedometer.png]]\n\nThere are significant performance improvements, but they may not be as dramatic on your device. For example, on my Ryzen 5 5500U, I get a 105 on the chromium speedometer and a 175 on the Thorium speedometer. Not a 3x score difference but still very significant.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Transparent-Huge-Pages":{"title":"Transparent Huge Pages","content":"\nWhen the CPU assigns memory to processes that require it, it typically does so in 4 KB page chunks. Because the CPU's MMU unit actively needs to translate virtual memory to physical memory upon incoming I/O requests, going through all 4 KB pages is naturally an expensive operation. Fortunately, it has its own TLB cache (translation lookaside buffer), which reduces the potential amount of time required to access a specific memory address by caching the most recently used memory. The only issue is that TLB cache size is typically very limited, and when it comes to gaming, especially playing triple AAA games, the high memory entropy nature of those applications causes a huge potential bottleneck.\n\nIn terms of the overhead that TLB lookups will incur. This is due to the technically inherent inefficiency of having a large number of entries in the page table, all with very small sizes.\n\nTo enable automatic use of transparent hugepages, first ensure that they are enabled in your kernel by running `cat /sys/kernel/mm/transparent_hugepage/enabled`. If it says error: the file or directory cannot be found, it means your kernel was built without support for it, and you must either manually build and enable the feature before compiling it or use a different kernel.\n\nThere are 3 values you can choose for transparent huge pages:\n\n### always\n\nShould be self explanatory.\n\n### madvise\n\nOnly enabled inside MADV_HUGEPAGE regions (to avoid the risk of consuming more memory resources, relevant for embedded systems).\n\n### never\n\nEntirely disabled(mostly for debugging purposes).\n\nUse `echo 'always' | sudo tee /sys/kernel/mm/transparent_hugepage/enabled` to set the value to 'always'.\n\nIt may appear that `always` is the best option, but in some cases, such as database software, it degrades performance.\nFor example mongodb docs says:\n\n\u003e Transparent Huge Pages (THP) is a Linux memory management system that reduces the overhead of Translation Lookaside Buffer (TLB) lookups on machines with large amounts of memory by using larger memory pages.\n\u003e\n\u003e However, database workloads often perform poorly with THP enabled, because they tend to have sparse rather than contiguous memory access patterns. When running MongoDB on Linux, THP should be disabled for best performance.\n\nSo you should experiment with each value to see which one works best for your workload.\n\n# Additional sources\n\n\u003chttps://www.kernel.org/doc/html/latest/admin-guide/mm/transhuge.html\u003e\n\n\u003chttps://access.redhat.com/solutions/46111\u003e\n\n\u003chttps://www.mongodb.com/docs/manual/tutorial/transparent-huge-pages/#:~:text=Transparent%20Huge%20Pages%20(THP)%20is,by%20using%20larger%20memory%20pages.\u003e\n\n\u003chttps://www.reddit.com/r/linux_gaming/comments/uhfjyt/underrated_advice_for_improving_gaming/\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Trim":{"title":"Why do SSDs need trim","content":"\n## How does SSD store data\n\nLet's look at the structure of the SSD to understand the problems it faces and why we need TRIM operation to solve them. Data is typically stored in pages, which are groups of 4KB cells. For most SSDs, the pages are then grouped into clusters of 128 pages called Blocks, with each block containing 512KB.\n\nYou can read data from a page that contains some information or write data to clean pages (with no data from before in them). However, you cannot overwrite data on a previously written 4KB page without also overwriting the remaining 512KB.\n\nThis is because the voltages required to flip a 0 to 1 are frequently much higher than the reverse. Excess voltage has the potential to flip bits on adjacent cells and corrupt data.\n\n## File deletion\n\nWhen you delete a file the SSD simply marks all corresponding pages as invalid. Instead of being physically zeroed out, the sectors are marked as free. This significantly speeds up the deletion process.\n\nAssume you change a file, which corresponds to a single 4KB page change. When you try to modify a 4KB page in an SSD, the entire content of its block, all 512KB of it, must be read into a cache (which can be built into the SSD or use system's main memory), the block must be erased, and then you can write the new data to your target 4KB page. You will also need to restore the remaining unmodified 508KB of data from your cache.\n\n## So what does TRIM do?\n\nTRIM informs the drive that the blocks are no longer in use. That is, they can be deleted and used again for new data.\n\nAn SSD does not understand the file system that has been written to it. As a result, it has no idea how NTFS (For example) deletes files. Now TRIM comes into play. After a file is deleted, the operating system sends a TRIM command to the SSD, along with a list of sectors that should be marked free and erased.\n\nThe TRIM command reduces performance degradation by trimming invalid pages on a regular basis. Windows 10 for example TRIMs your SSD once a week. When that operation is run, the SSD controller cleans out all the data that has been marked as deleted by the OS from the memory cells. Yes, it still has to go through the read-modify-write operation, but it only happens once a week, so if all pages in a block are marked for deletion by the time trimming occurs, there will be no pages to copy to the cache therefore reducing writes and improving device lifespan.\n\nWhen you want to write to a page again, it will be empty and ready for a direct write operation!\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/VLAN":{"title":"VLAN","content":"\nA virtual LAN (VLAN) is a logical grouping of devices in a computer network that behaves as if they are part of the same LAN, despite the fact that the devices are physically connected to different switches or located in different parts of the network. VLANs are used to divide a network into smaller, more manageable segments, as well as to improve network performance and security. This is accomplished by allocating a VLAN to each device and configuring the switch to forward traffic between devices in the same VLAN.\n\nVLANs are commonly used to divide a network into different subnets or broadcast domains, which can be useful for distinguishing between different types of traffic, such as guest and corporate traffic, or for isolating different departments or teams within an organization. VLANs can also be used to improve network security by limiting the scope of broadcasts and limiting access to specific network areas.\n\nVLANs are implemented through VLAN tagging, which adds a VLAN identifier to the header of a packet as it travels across the network. This enables switches to determine which VLAN a packet belongs to and forward it to the appropriate devices. Most modern networking devices, including switches, routers, and network interface cards, support VLAN tagging (NICs).\n\n# VLAN interface types\n\nThere are several types of layer 2 interfaces that can be used in a virtual LAN (VLAN), including:\n\n1. Access ports: An access port is a layer 2 interfaces that are configured to belong to a single VLAN. All traffic sent or received on an access port is associated with the VLAN to which the port is assigned. Access ports are typically used to connect end devices to the network, such as computers and servers.\n\n2. Trunk ports: Trunk ports are layer 2 interfaces that are configured to carry traffic from multiple VLANs. Trunk ports use VLAN tagging to determine which VLAN each packet belongs to and to route the packet to the correct VLAN. Trunk ports are commonly used to connect switches to one another or to connect a switch to a router or other network device.\n\n3. Hybrid ports: A hybrid port is a layer 2 interface that, depending on the configuration, can function as either an access port or a trunk port. Hybrid ports are useful when the VLAN configuration needs to be changed or when a device needs to be connected to multiple VLANs at the same time.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/VS-Code-Server":{"title":"VS Code Server","content":"\nRun [VS Code](https://github.com/Microsoft/vscode) on any machine anywhere and access it in the browser.\n\nCompilations, downloads, and other similar tasks should not be done on your primary computer. To avoid straining your current device, you can perform all of these tasks on a remote machine. Extensions can also be run remotely, consuming fewer system resources.\n\nThe default bundled electron isn't very optimized; however, with VS Code server, you can use your local web browser without having to launch another browser (electron). You can also maximize resource efficiency by using an optimized browser, such as [[notes/Thorium]].\n\nI'm running code server on my Raspberry Pi, and I can also access the pi from anywhere using [[notes/ZeroTier]].\n\nVideo Demo:\n\u003chttps://xeome.github.io/notes/assets/img/code-server.mp4\u003e\n\nFor more information visit [here](https://github.com/coder/code-server)\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Valgrind":{"title":"Valgrind","content":"\n# Overview\n\nValgrind is a tool that aids in debugging and profiling programs written in C, C++, and other languages. It helps developers identify and fix issues such as memory leaks, buffer overflows, and other problems that can cause bugs and crashes.\n\nValgrind works by executing a program in a simulated environment and monitoring its behavior. It can identify a variety of problems, including:\n\n- Memory leaks: Valgrind can detect when a program fails to free memory that it has allocated, resulting in an accumulation of unused memory over time.\n\n- Memory errors: Valgrind can detect when a program accesses memory that it is not intended to, such as when it reads from or writes to uninitialized memory or memory that has already been freed.\n\n- Buffer overflows: Valgrind can detect when a program writes more data to a buffer than it is designed to hold, potentially causing a crash or introducing security vulnerabilities.\n\n- Race conditions: Valgrind can detect when multiple threads of a program access shared resources in an inconsistent or conflicting manner, leading to unpredictable or incorrect behavior.\n\n# Common paremeters\n\nValgrind has many options and parameters that can be used to customize its behavior and the types of problems it can detect. Here are a few of the more commonly used options:\n\n- `--leak-check=full`: This option enables Valgrind's memory leak detection features, and provides a detailed report of any memory that was allocated but not freed by the program.\n\n- `--track-origins=yes`: This option enables Valgrind's origin tracking feature, which can help identify the source of uninitialized memory reads and other errors.\n\n- `--tool=\u003ctoolname\u003e`: This option allows you to specify which tool Valgrind should use to analyze the program. Valgrind comes with a number of different tools, including `memcheck` for memory error detection, `cachegrind` for cache profiling, and `helgrind` for detecting threading errors.\n\n- `--log-file=\u003cfilename\u003e`: This option specifies a file to which Valgrind should write its output. By default, Valgrind writes its output to `stderr`, but this option allows you to redirect the output to a file for easier analysis.\n\n- `--suppressions=\u003cfilename\u003e`: This option specifies a file containing suppression rules that tell Valgrind to ignore certain errors or warnings. This can be useful if you are running Valgrind on a program that generates a lot of false positives or if you are only interested in certain types of errors.\n\nThese are just a few examples of the many options and parameters that are available in Valgrind.\n\n# More examples\n\nExample 1: How Valgrind can be used to detect a memory leak in a C program:\n\n```C\n#include \u003cstdlib.h\u003e\n\nint main(int argc, char** argv) {\n  char* ptr = (char*) malloc(100);\n  // Do something with ptr\n  return 0;\n}\n\n```\n\nIf we compile and run this program using Valgrind, it will report that there is a 100-byte memory leak, because the program allocated memory with `malloc` but did not release it with `free`.\n\n```bash\n$ valgrind --leak-check=full ./a.out\n==4410== Memcheck, a memory error detector\n==4410== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.\n==4410== Using Valgrind-3.19.0 and LibVEX; rerun with -h for copyright info\n==4410== Command: ./a.out\n==4410==\n==4410==\n==4410== HEAP SUMMARY:\n==4410==     in use at exit: 100 bytes in 1 blocks\n==4410==   total heap usage: 1 allocs, 0 frees, 100 bytes allocated\n==4410==\n==4410== 100 bytes in 1 blocks are definitely lost in loss record 1 of 1\n==4410==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==4410==    by 0x109151: main (mem_leak.c:4)\n==4410==\n==4410== LEAK SUMMARY:\n==4410==    definitely lost: 100 bytes in 1 blocks\n==4410==    indirectly lost: 0 bytes in 0 blocks\n==4410==      possibly lost: 0 bytes in 0 blocks\n==4410==    still reachable: 0 bytes in 0 blocks\n==4410==         suppressed: 0 bytes in 0 blocks\n==4410==\n==4410== For lists of detected and suppressed errors, rerun with: -s\n==4410== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)\n```\n\nExample 2: Detecting a buffer overflow:\n\n```C\n#include \u003cstdio.h\u003e\n\nint main(int argc, char** argv) {\n  char *buffer = malloc(10);\n  snprintf(buffer, 20, \"Hello, world!\"); // buffer is too small\n  printf(\"%s\\n\", buffer);\n  return 0;\n}\n```\n\nValgrind is not the best tool for detecting static buffer overflows, but because the code uses dynamically allocated buffers, it works fine.\nWhen we run this program through Valgrind, we get an error because the program tries to write more data to the buffer than it was designed to hold:\n\n```bash\n$ valgrind --leak-check=full ./a.out\n==6888== Memcheck, a memory error detector\n==6888== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.\n==6888== Using Valgrind-3.19.0 and LibVEX; rerun with -h for copyright info\n==6888== Command: ./a.out\n==6888==\n==6888== Invalid write of size 1\n==6888==    at 0x48FF7A5: _IO_default_xsputn (genops.c:394)\n==6888==    by 0x48FF7A5: _IO_default_xsputn (genops.c:370)\n==6888==    by 0x48D8932: outstring_func (vfprintf-internal.c:239)\n==6888==    by 0x48D8932: __vfprintf_internal (vfprintf-internal.c:767)\n==6888==    by 0x48FAA9D: __vsnprintf_internal (vsnprintf.c:114)\n==6888==    by 0x48D4FA5: snprintf (snprintf.c:31)\n==6888==    by 0x109192: main (buffer_overflow.c:6)\n==6888==  Address 0x4a6904a is 0 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== Invalid write of size 1\n==6888==    at 0x48FAAAA: __vsnprintf_internal (vsnprintf.c:117)\n==6888==    by 0x48D4FA5: snprintf (snprintf.c:31)\n==6888==    by 0x109192: main (buffer_overflow.c:6)\n==6888==  Address 0x4a6904d is 3 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== Invalid read of size 1\n==6888==    at 0x4847D14: strlen (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x48F3AB7: puts (ioputs.c:35)\n==6888==    by 0x10919E: main (buffer_overflow.c:7)\n==6888==  Address 0x4a6904a is 0 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== Invalid read of size 1\n==6888==    at 0x48FF713: _IO_default_xsputn (genops.c:399)\n==6888==    by 0x48FF713: _IO_default_xsputn (genops.c:370)\n==6888==    by 0x48FDB34: _IO_new_file_xsputn (fileops.c:1264)\n==6888==    by 0x48FDB34: _IO_file_xsputn@@GLIBC_2.2.5 (fileops.c:1196)\n==6888==    by 0x48F3B6B: puts (ioputs.c:40)\n==6888==    by 0x10919E: main (buffer_overflow.c:7)\n==6888==  Address 0x4a6904a is 0 bytes after a block of size 10 alloc'd\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\nHello, world!\n==6888==\n==6888== HEAP SUMMARY:\n==6888==     in use at exit: 10 bytes in 1 blocks\n==6888==   total heap usage: 2 allocs, 1 frees, 1,034 bytes allocated\n==6888==\n==6888== 10 bytes in 1 blocks are definitely lost in loss record 1 of 1\n==6888==    at 0x4841888: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==6888==    by 0x109171: main (buffer_overflow.c:5)\n==6888==\n==6888== LEAK SUMMARY:\n==6888==    definitely lost: 10 bytes in 1 blocks\n==6888==    indirectly lost: 0 bytes in 0 blocks\n==6888==      possibly lost: 0 bytes in 0 blocks\n==6888==    still reachable: 0 bytes in 0 blocks\n==6888==         suppressed: 0 bytes in 0 blocks\n==6888==\n==6888== For lists of detected and suppressed errors, rerun with: -s\n==6888== ERROR SUMMARY: 12 errors from 5 contexts (suppressed: 0 from 0)\n```\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/XDP-Tutorial":{"title":"XDP-Tutorial","content":"\n## Introduction\n\nXDP is an upstream Linux kernel component that allows users to install packet processing programs into the kernel. The programs are written in restricted C and compiled into eBPF byte code. Read the [the academic paper (pdf)](https://github.com/xdp-project/xdp-paper/blob/master/xdp-the-express-data-path.pdf) or the [Cilium BPF reference guide](https://cilium.readthedocs.io/en/latest/bpf/) for a general introduction to XDP.\n\nThis tutorial aims to provide a hands-on introduction to the various steps required to create useful programs with the XDP system. We assume you know the basics of Linux networking and how to configure it with the iproute2 suite of tools, but you have no prior experience with eBPF or XDP. All of the lessons are written in C, and they cover basic pointer arithmetic and aliasing. This tutorial is intended to be a hands-on introduction to the various steps required to successfully write useful programs using the XDP system.\n\nPlease keep in mind that this tutorial was written by a university first-year computer science student who has only recently begun learning XDP.\n\n## Dependencies\n\nFor basic dependencies refer to \u003chttps://github.com/xdp-project/xdp-tutorial/blob/master/setup_dependencies.org\u003e.\n\nYou will also need xdp-tools. If your distribution repositories lack xdp-tools, you can follow the build instructions from here \u003chttps://github.com/xdp-project/xdp-tools\u003e .\n\n## Examples\n\n### Example 1 - Writing a program to pass all packets\n\n```c\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n    return XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n#### Compiling and loading the example code\n\nThe LLVM+clang compiler turns this restricted-C code into BPF-byte-code and stores it in an ELF object file, named `xdp_pass.o`\n\n**Building:**\n\n`clang -O2 -g -Wall -target bpf -c xdp_pass.c -o xdp_pass.o`\n\n**Loading:**\n\n`sudo xdp-loader load -m skb -s prog interface_name xdp_pass.o`\n\nChange the interface_name to the name of your interface (for example, `eth0`, `wlan0`).\n\n**Unloading:**\n\n`sudo xdp-loader unload -a interface_name`\nAs previously described, change the interface name.\n\n### Example 2 - Blocking ICMP packets\n\n```C\n#include \u003cstdint.h\u003e\n#include \u003carpa/inet.h\u003e\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n#include \u003clinux/icmp.h\u003e\n#include \u003clinux/if_ether.h\u003e\n#include \u003clinux/ip.h\u003e\n#include \u003clinux/ipv6.h\u003e\n#include \u003clinux/tcp.h\u003e\n\n#define OVER(x, d) (x + 1 \u003e (typeof(x))d)\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n    /* data and data_end are pointers to the beginning and end of the packet’s raw\n    memory. Note that ctx-\u003edata and ctx-\u003edata_end are of type __u32, so we have\n    to perform the casts */\n    void *data_end = (void *)(uintptr_t)ctx-\u003edata_end;\n    void *data = (void *)(uintptr_t)ctx-\u003edata;\n    \n    struct ethhdr *eth = data;\n    struct iphdr *iph = (struct iphdr *)(eth + 1);\n    struct icmphdr *icmph = (struct icmphdr *)(iph + 1);\n\n    /* sanity check needed by the eBPF verifier\n    When accessing the data in struct ethhdr, we must make sure we don't\n    access invalid areas by checking whether data + sizeof(struct ethhdr) \u003e\n    data_end, and returning without further action if it's true. This check\n    is compulsory by the BPF verifer that verifies your program at runtime. */\n    if (OVER(eth, data_end))\n        return XDP_DROP;\n\n    if (eth-\u003eh_proto != ntohs(ETH_P_IP))\n        return XDP_PASS;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(iph, data_end))\n        return XDP_DROP;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(icmph, data_end))\n        return XDP_DROP;\n\n    /* \n\tstruct iphdr {\n\t#if defined(__LITTLE_ENDIAN_BITFIELD)\n\t\t__u8\tihl:4,\n\t\t\tversion:4;\n\t#elif defined (__BIG_ENDIAN_BITFIELD)\n\t\t__u8\tversion:4,\n  \t\t\tihl:4;\n\t#else\n\t#error\t\"Please fix \u003casm/byteorder.h\u003e\"\n\t#endif\n\t\t__u8\ttos;\n\t\t__be16\ttot_len;\n\t\t__be16\tid;\n\t\t__be16\tfrag_off;\n\t\t__u8\tttl;\n\t\t__u8\tprotocol;\n\t\t__sum16\tcheck;\n\t\t__be32\tsaddr;\n\t\t__be32\tdaddr;     \n\t}; \n\tThis is the ipheader structure from ip.h; we can see the elements we can access \n    and their types. We can use iph-\u003eprotocol to determine whether an incoming \n    packet is an ICMP packet or not. */\n    if (iph-\u003eprotocol != IPPROTO_ICMP)\n        return XDP_PASS;\n\n    /* drop icmp */\n    if (iph-\u003eprotocol == IPPROTO_ICMP)\n        return XDP_DROP;\n    \n    return XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n### Example 3 - Recording how many ICMP packets arrived\n\nIn this example, we count the number of ICMP packets received from each individual source address and block incoming packets after the first five. So each source address can only send 5 ICMP packets.\n\n![[notes/assets/img/O_BPF_internals.png]]\n\nAs shown in the image we can use **eBPF maps** (Map Storage) for storing the amount of packets received. Maps are a general-purpose data structure used to store various types of data. They allow data sharing between eBPF kernel programs as well as between kernel and user-space applications.\n\nEach map type has the following attributes:\n\n```ini\n   *  type\n\n   *  maximum number of elements\n\n   *  key size in bytes\n\n   *  value size in bytes\n```\n\nExample code:\n\n```C\n#include \u003cstdint.h\u003e\n#include \u003carpa/inet.h\u003e\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n#include \u003clinux/icmp.h\u003e\n#include \u003clinux/if_ether.h\u003e\n#include \u003clinux/ip.h\u003e\n#include \u003clinux/ipv6.h\u003e\n#include \u003clinux/tcp.h\u003e\n\n#define OVER(x, d) (x + 1 \u003e (typeof(x))d)\n\n/* Creating a BPF map for counting ICMP packets as described above */\nstruct bpf_map_def SEC(\"maps\") cnt = {\n    .type = BPF_MAP_TYPE_HASH,\n    .key_size = sizeof(__be32),\n    .value_size = sizeof(long),\n    .max_entries = 65536,\n};\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n\t/* data and data_end are pointers to the beginning and end of the packet’s raw\n    memory. Note that ctx-\u003edata and ctx-\u003edata_end are of type __u32, so we have\n    to perform the casts */\n\tvoid *data_end = (void *)(uintptr_t)ctx-\u003edata_end;\n\tvoid *data = (void *)(uintptr_t)ctx-\u003edata;\n\t\n    long *value;\n    \n    /* Define headers */\n\tstruct ethhdr *eth = data;\n\tstruct iphdr *iph = (struct iphdr *)(eth + 1);\n\tstruct icmphdr *icmph = (struct icmphdr *)(iph + 1);\n\n\t/* sanity check needed by the eBPF verifier\n    When accessing the data in struct ethhdr, we must make sure we don't\n    access invalid areas by checking whether data + sizeof(struct ethhdr) \u003e\n    data_end, and returning without further action if it's true. This check\n    is compulsory by the BPF verifer that verifies your program at runtime. */\n\n\tif (OVER(eth, data_end))\n\t\treturn XDP_DROP;\n\n\tif (eth-\u003eh_proto != ntohs(ETH_P_IP))\n\t\treturn XDP_PASS;\n\n\t/* sanity check needed by the eBPF verifier */\n\tif (OVER(iph, data_end))\n\t\treturn XDP_DROP;\n\n\t/* sanity check needed by the eBPF verifier */\n\tif (OVER(icmph, data_end))\n\t\treturn XDP_DROP;\n\n\t/* \n\tstruct iphdr {\n\t#if defined(__LITTLE_ENDIAN_BITFIELD)\n\t\t__u8\tihl:4,\n\t\t\tversion:4;\n\t#elif defined (__BIG_ENDIAN_BITFIELD)\n\t\t__u8\tversion:4,\n  \t\t\tihl:4;\n\t#else\n\t#error\t\"Please fix \u003casm/byteorder.h\u003e\"\n\t#endif\n\t\t__u8\ttos;\n\t\t__be16\ttot_len;\n\t\t__be16\tid;\n\t\t__be16\tfrag_off;\n\t\t__u8\tttl;\n\t\t__u8\tprotocol;\n\t\t__sum16\tcheck;\n\t\t__be32\tsaddr;\n\t\t__be32\tdaddr;     \n\t}; \n\tThis is the ipheader structure from ip.h; we can see the elements we can access \n    and their types. We can use iph-\u003eprotocol to determine whether an incoming \n    packet is an ICMP packet or not. */\n\n\tif (iph-\u003eprotocol != IPPROTO_ICMP)\n\t\treturn XDP_PASS;\n\n\t/* Check protocol of the packet */\n    if (iph-\u003eprotocol == IPPROTO_ICMP) {\n        /* Get source address */\n        __be32 source = iph-\u003esaddr;\n        /* Get value pointer address*/\n        value = bpf_map_lookup_elem(\u0026cnt, \u0026source);\n\n        if (value) {\n            *value += 1;\n        } else {\n            long temp = 1;\n            bpf_map_update_elem(\u0026cnt, \u0026source, \u0026temp, BPF_ANY);\n        }\n\n        if (value \u0026\u0026 *value \u003e 5)\n            return XDP_DROP;\n\n        return XDP_PASS;\n    }\n    \n\treturn XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n### Example 4 - Packet modification\n\nIn this example, we will set TTL to a pseudorandom number between 1-255.\n\n```C\n#include \u003cstdint.h\u003e\n#include \u003carpa/inet.h\u003e\n#include \u003clinux/bpf.h\u003e\n#include \u003cbpf/bpf_helpers.h\u003e\n#include \u003clinux/icmp.h\u003e\n#include \u003clinux/if_ether.h\u003e\n#include \u003clinux/ip.h\u003e\n#include \u003clinux/ipv6.h\u003e\n#include \u003clinux/tcp.h\u003e\n\n#define OVER(x, d) (x + 1 \u003e (typeof(x))d)\n\nstatic inline void csum_replace2(uint16_t *sum, uint16_t old, uint16_t new)\n{\n\tuint16_t csum = ~*sum;\n\n\tcsum += ~old;\n\tcsum += csum \u003c (uint16_t)~old;\n\n\tcsum += new;\n\tcsum += csum \u003c (uint16_t)new;\n\n\t*sum = ~csum;\n}\n\nSEC(\"prog\")\nint xdp_prog_simple(struct xdp_md *ctx)\n{\n    /* data and data_end are pointers to the beginning and end of the packet’s raw\n    memory. Note that ctx-\u003edata and ctx-\u003edata_end are of type __u32, so we have\n    to perform the casts */\n    void *data_end = (void *)(uintptr_t)ctx-\u003edata_end;\n    void *data = (void *)(uintptr_t)ctx-\u003edata;\n    uint8_t old_ttl;\n\n    struct ethhdr *eth = data;\n    struct iphdr *iph = (struct iphdr *)(eth + 1);\n    struct icmphdr *icmph = (struct icmphdr *)(iph + 1);\n\n    /* sanity check needed by the eBPF verifier\n    When accessing the data in struct ethhdr, we must make sure we don't\n    access invalid areas by checking whether data + sizeof(struct ethhdr) \u003e\n    data_end, and returning without further action if it's true. This check\n    is compulsory by the BPF verifer that verifies your program at runtime. */\n    if (OVER(eth, data_end))\n        return XDP_DROP;\n\n    if (eth-\u003eh_proto != ntohs(ETH_P_IP))\n        return XDP_PASS;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(iph, data_end))\n        return XDP_DROP;\n\n    /* sanity check needed by the eBPF verifier */\n    if (OVER(icmph, data_end))\n        return XDP_DROP;\n\n    /* set the TTL to a pseudorandom number 1..255 */\n    old_ttl = iph-\u003ettl;\n    iph-\u003ettl = bpf_get_prandom_u32() \u0026 0xff ?: 1;\n\n    /* recalculate the checksum, otherwise the IP stack will drop it */\n    csum_replace2(\u0026iph-\u003echeck, htons(old_ttl \u003c\u003c 8), htons(iph-\u003ettl \u003c\u003c 8));\n\n    return XDP_PASS;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n```\n\n## Sources\n\nMany sources have influenced this tutorial, including:\n\n- \u003chttps://github.com/xdp-project/xdp-tutorial/\u003e\n- \u003chttps://developers.redhat.com/blog/2021/04/01/get-started-with-xdp\u003e\n- \u003chttps://www.tigera.io/learn/guides/ebpf/ebpf-xdp/\u003e\n- \u003chttps://www.seekret.io/blog/a-gentle-introduction-to-xdp/\u003e\n- \u003chttps://man7.org/linux/man-pages/man2/bpf.2.html\u003e\n- \u003chttps://gist.github.com/teknoraver/b66115e3518bb1b7f3e79f52aa2c3424\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/ZeroTier":{"title":"ZeroTier","content":"\n[ZeroTier](https://www.zerotier.com/) is a secure virtual network backbone that allows multiple machines to communicate as if they were all connected to the same network. It is a peer-to-peer encrypted technology, which means that unlike traditional VPN solutions, messages are sent directly from host to host rather than via a central server or router.\n\nAll of the code is open source, and you can host the controller yourself or use the ZeroTierOne service, which has both free and paid plans. I'm currently on their free plan, which is solid, reliable, and consistent.\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null},"/notes/Zram":{"title":"Zram","content":"\n# Zram Performance Analysis\n\n## Introduction\n\nZram is a kernel module that utilizes a compressed virtual memory block device allowing for efficient memory management. In this document we will analyze the performance of various compression algorithms used in Zram and their impact on the system. We will also discuss the effects of different page-cluster values on the system's latencies and throughput.\n\n## Compression Algorithm Comparison\n\nThe following table compares the performance of different compression algorithms used in Zram, in terms of compression time, data size, compressed size, total size, and compression ratio.\n\nData from [Linux Reviews](https://linuxreviews.org/Zram):\n\n| Algorithm | Cp time | Data | Compressed |  Total | Ratio |\n| :-------: | :-----: | :--: | :--------: | :----: | :---: |\n|    lzo    |  4.571s | 1.1G |   387.8M   | 409.8M | 2.689 |\n|  lzo-rle  |  4.471s | 1.1G |    388M    |  410M  | 2.682 |\n|    lz4    |  4.467s | 1.1G |   403.4M   | 426.4M | 2.582 |\n|   lz4hc   | 14.584s | 1.1G |   362.8M   | 383.2M | 2.872 |\n|    842    | 22.574s | 1.1G |   538.6M   | 570.5M | 1.929 |\n|    zstd   |  7.897s | 1.1G |   285.3M   | 298.8M | 3.961 |\n\nData from u/VenditatioDelendaEst:\n\n| algo    | page-cluster | MiB/s |   IOPS  | Mean Latency (ns) | 99% Latency (ns) | comp_ratio |\n| ------- | :----------: | :---: | :-----: | :---------------: | :--------------: | :--------: |\n| lzo     |       0      |  5821 | 1490274 |        2428       |       7456       |    2.77    |\n| lzo     |       1      |  6668 |  853514 |        4436       |       11968      |    2.77    |\n| lzo     |       2      |  7193 |  460352 |        8438       |       21120      |    2.77    |\n| lzo     |       3      |  7496 |  239875 |       16426       |       39168      |    2.77    |\n| lzo-rle |       0      |  6264 | 1603776 |        2235       |       6304       |    2.74    |\n| lzo-rle |       1      |  7270 |  930642 |        4045       |       10560      |    2.74    |\n| lzo-rle |       2      |  7832 |  501248 |        7710       |       19584      |    2.74    |\n| lzo-rle |       3      |  8248 |  263963 |       14897       |       37120      |    2.74    |\n| lz4     |       0      |  7943 | 2033515 |        1708       |       3600       |    2.63    |\n| lz4     |       1      |  9628 | 1232494 |        2990       |       6304       |    2.63    |\n| lz4     |       2      | 10756 |  688430 |        5560       |       11456      |    2.63    |\n| lz4     |       3      | 11434 |  365893 |       10674       |       21376      |    2.63    |\n| zstd    |       0      |  2612 |  668715 |        5714       |       13120      |    3.37    |\n| zstd    |       1      |  2816 |  360533 |       10847       |       24960      |    3.37    |\n| zstd    |       2      |  2931 |  187608 |       21073       |       48896      |    3.37    |\n| zstd    |       3      |  3005 |  96181  |       41343       |       95744      |    3.37    |\n\nData from my raspberry pi 4, 2gb model:\n\n| algo    | page-cluster |  MiB/s  |    IOPS   | Mean Latency (ns) | 99% Latency (ns) | comp_ratio |\n| ------- | :----------: | :-----: | :-------: | :---------------: | :--------------: | :--------: |\n| lzo     |       0      | 1275.19 | 326448.93 |      9965.14      |     18816.00     |    1.62    |\n| lzo     |       1      | 1892.08 | 242186.68 |      14178.77     |     31104.00     |    1.62    |\n| lzo     |       2      | 2451.65 | 156905.52 |      23083.55     |     56064.00     |    1.62    |\n| lzo     |       3      | 2786.33 |  89162.46 |      42224.49     |     107008.00    |    1.62    |\n| lzo-rle |       0      | 1271.53 | 325511.42 |      9997.72      |     20096.00     |    1.62    |\n| lzo-rle |       1      | 1842.69 | 235863.95 |      14627.23     |     34048.00     |    1.62    |\n| lzo-rle |       2      | 2404.35 | 153878.65 |      23592.19     |     60160.00     |    1.62    |\n| lzo-rle |       3      | 2766.61 |  88531.46 |      42579.14     |     114176.00    |    1.62    |\n| lz4     |       0      | 1329.87 | 340447.83 |      9421.35      |     15936.00     |    1.59    |\n| lz4     |       1      | 2004.43 | 256567.19 |      13238.78     |     25216.00     |    1.59    |\n| lz4     |       2      | 2687.75 | 172015.93 |      20807.00     |     43264.00     |    1.59    |\n| lz4     |       3      | 3157.29 | 101033.42 |      36901.36     |     80384.00     |    1.59    |\n| zstd    |       0      |  818.88 | 209633.97 |      16672.13     |     38656.00     |    1.97    |\n| zstd    |       1      | 1069.07 | 136840.50 |      26777.05     |     69120.00     |    1.97    |\n| zstd    |       2      | 1286.17 |  82314.84 |      46059.39     |     127488.00    |    1.97    |\n| zstd    |       3      | 1427.75 |  45688.14 |      84876.56     |     246784.00    |    1.97    |\n\nThe table presents the performance metrics of different compression algorithms, including LZO, LZO-RLE, LZ4, and ZSTD. The metrics include throughput, compression ratio, and latency, which are important factors to consider for selecting the optimal compression algorithm.\n![[notes/assets/img/zram_weighed.png]]\nWe used a weighted sum to evaluate the performance of each algorithm and page cluster combination, with weights of 0.4 for latency, 0.4 for compression ratio, and 0.2 for throughput. The results show that LZ4 with page cluster 0 achieved the highest weighted sum, indicating that it is the optimal choice for this dataset. Overall, this evaluation provides valuable insights for selecting the most suitable compression algorithm for data storage and processing, balancing between compression ratio, throughput, and latency.\n\nCode used to calculate weighed sums:\n\n```py\ndata = {\n    ('lzo', 0): (5821, 2.77, 2428),\n    ('lzo', 1): (6668, 2.77, 4436),\n    ('lzo', 2): (7193, 2.77, 8438),\n    ('lzo', 3): (7496, 2.77, 16426),\n    ('lzo-rle', 0): (6264, 2.74, 2235),\n    ('lzo-rle', 1): (7270, 2.74, 4045),\n    ('lzo-rle', 2): (7832, 2.74, 7710),\n    ('lzo-rle', 3): (8248, 2.74, 14897),\n    ('lz4', 0): (7943, 2.63, 1708),\n    ('lz4', 1): (9628, 2.63, 2990),\n    ('lz4', 2): (10756, 2.63, 5560),\n    ('lz4', 3): (11434, 2.63, 10674),\n    ('zstd', 0): (2612, 3.37, 5714),\n    ('zstd', 1): (2816, 3.37, 10847),\n    ('zstd', 2): (2931, 3.37, 21073),\n    ('zstd', 3): (3005, 3.37, 41343),\n}\n\nweights = {'latency': 0.4, 'ratio': 0.4, 'throughput': 0.2}\n\n# Find the maximum value for each metric\nmax_throughput = max(x[0] for x in data.values())\nmax_ratio = max(x[1] for x in data.values())\nmax_latency = max(x[2] for x in data.values())\n\nbest_score = 0\nbest_algo = None\nbest_page_cluster = None\n\nfor (algo, page_cluster), (throughput, ratio, latency) in data.items():\n    throughput_norm = throughput / max_throughput\n    ratio_norm = ratio / max_ratio\n    latency_norm = latency / max_latency\n    score = weights['latency'] * (1 / latency_norm) + weights['ratio'] * ratio_norm + weights['throughput'] * throughput_norm\n    print(f\"{algo}, pagecluster {page_cluster}: {score:.4f}\")\n    if score \u003e best_score:\n        best_score = score\n        best_algo = algo\n        best_page_cluster = page_cluster\n\nprint(f\"Best algorithm: {best_algo}\")\nprint(f\"Best page cluster: {best_page_cluster}\")\n```\n\nData from me:\n\nCompiling memory intensive code ([vtm](https://github.com/netxs-group/vtm) ). Test was done on raspberry pi 4b, 2gb ram.\n\n| algo |   time  |\n| :--: | :-----: |\n|  lz4 | 433.63s |\n| zstd | 459.34s |\n\n### Page-cluster Values and Latency\n\nThe page-cluster value controls the number of pages that are read in from swap in a single attempt, similar to the page cache readahead. The consecutive pages are not based on virtual or physical addresses, but consecutive on swap space, meaning they were swapped out together.\n\nThe page-cluster value is a logarithmic value. Setting it to zero means one page, setting it to one means two pages, setting it to two means four pages, etc. A value of zero disables swap readahead completely.\n\nThe default value is 3 (8 pages at a time). However, tuning this value to a different value may provide small benefits if the workload is swap-intensive. Lower values mean lower latencies for initial faults, but at the same time, extra faults and I/O delays for following faults if they would have been part of that consecutive pages readahead would have brought in.\n\n![[notes/assets/img/O_benchmarks_zram_throughput.png]]\n\n![[notes/assets/img/O_benchmarks_zram_latency.png]]\n\n## Conclusion\n\nIn the analysis of Zram performance, it was determined that the zstd algorithm provides the highest compression ratio while still maintaining acceptable speeds. The high compression ratio allows more of the working set to fit in uncompressed memory, reducing the need for swap and ultimately improving performance.\n\nFor daily use (non latency sensitive), it is recommended to use zstd with `page-cluster=0` as the majority of swapped data is likely stale (old browser tabs). However, systems that require constant swapping may benefit from using the lz4 algorithm due to its higher throughput and lower latency.\n\nIt is important to note that the decompression of zstd is slow and results in a lack of throughput gain from readahead. Therefore, `page-cluster=0` should be used for zstd. This is the default setting on [ChromeOS](https://bugs.chromium.org/p/chromium/issues/detail?id=263561#c16=) and seems to be standard practice on [Android](https://cs.android.com/search?q=page-cluster\u0026start=21).\n\nThe default `page-cluster` value is set to 3, which is better suited for physical swap. This value dates back to 2005, when the kernel switched to git, and may have been used in a time before the widespread use of SSDs. It is recommended to consider the specific requirements of the system and workload when configuring Zram.\n\n# Sources and See Also\n\n\u003chttps://linuxreviews.org/Zram\u003e\n\n\u003chttps://docs.kernel.org/admin-guide/sysctl/vm.html\u003e\n\n\u003chttps://www.reddit.com/r/Fedora/comments/mzun99/new_zram_tuning_benchmarks/\u003e\n","lastmodified":"2023-03-16T10:37:39.776180881Z","tags":null}}